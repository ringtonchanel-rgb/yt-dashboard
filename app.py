# app.py ‚Äî YouTube Analytics Tools
# Dashboard + Group Analytics (Advanced mode + Year compare)
# –° –Ω—É–ª—è: Advanced mode –≤ —Å—Ç–∏–ª–µ YouTube Studio
# (c) 2025

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io, re, hashlib
from functools import reduce
from datetime import datetime

# ===========================
#   BASIC CONFIG
# ===========================
st.set_page_config(page_title="YouTube Analytics Tools", layout="wide")
USE_EMOJI = True
ICON_DASH  = "üìä " if USE_EMOJI else ""
ICON_GROUP = "üß© " if USE_EMOJI else ""
ICON_BRAND = "üì∫ " if USE_EMOJI else ""

def do_rerun():
    try:
        st.rerun()
    except Exception:
        try:
            st.experimental_rerun()
        except Exception:
            pass

# ===========================
#   SIDEBAR BRAND + NAV
# ===========================
st.sidebar.markdown(
    f"<div style='font-weight:700;font-size:1.05rem;letter-spacing:.1px;'>{ICON_BRAND}YouTube Analytics Tools</div>",
    unsafe_allow_html=True,
)
st.sidebar.divider()
nav = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", [f"{ICON_DASH}Dashboard", f"{ICON_GROUP}Group Analytics"])
st.sidebar.divider()

# ===========================
#   HELPERS: column detection / parsing
# ===========================
def _norm(s: str) -> str:
    return str(s).strip().lower()

MAP = {
    "publish_time": [
        "video publish time","publish time","publish date","upload date",
        "–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ","–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏","–¥–∞—Ç–∞"
    ],
    # real daily date columns (not publish date)
    "day": ["date","day","report date","–¥–∞—Ç–∞ –æ—Ç—á–µ—Ç–∞","–¥–µ–Ω—å","–¥–∞—Ç–∞ (–¥–µ–Ω—å)"],
    "views": ["views","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã","–ø—Ä–æ—Å–º—Ç–æ—Ä—ã","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã (views)"],
    "impressions": ["impressions","–ø–æ–∫–∞–∑—ã","–ø–æ–∫–∞–∑—ã –∑–Ω–∞—á–∫–æ–≤","–ø–æ–∫–∞–∑—ã –¥–ª—è –∑–Ω–∞—á–∫–æ–≤","–ø–æ–∫–∞–∑—ã –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ"],
    "ctr": ["impressions click-through rate","ctr","ctr (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ (%)","ctr –≤–∏–¥–µ–æ"],
    "avd": ["average view duration","avg view duration","—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
            "—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–∏–¥–µ–æ","average view duration (hh:mm:ss)"],
    "watch_hours": ["watch time (hours)","watch time hours","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (—á–∞—Å—ã)","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (—á–∞—Å–æ–≤)"],
    "watch_minutes":["watch time (minutes)","watch time (mins)","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–º–∏–Ω)","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–º–∏–Ω—É—Ç—ã)"],
    "unique_viewers":["unique viewers","—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑—Ä–∏—Ç–µ–ª–∏","—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"],
    "engaged_views":["engaged views","–≤–æ–≤–ª–µ—á–µ–Ω–Ω—ã–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã —Å –≤–æ–≤–ª–µ—á–µ–Ω–∏–µ–º"],
    "title": ["title","–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ","video title","–≤–∏–¥–µ–æ","–Ω–∞–∑–≤–∞–Ω–∏–µ","content","–∫–æ–Ω—Ç–µ–Ω—Ç"],
}

def find_col(df: pd.DataFrame, names) -> str | None:
    if isinstance(names, str):
        names = [names]
    by_norm = {_norm(c): c for c in df.columns}
    for n in names:
        nn = _norm(n)
        if nn in by_norm:
            return by_norm[nn]
    for n in names:
        nn = _norm(n)
        for c in df.columns:
            if nn in _norm(c):
                return c
    return None

def detect_columns(df: pd.DataFrame):
    return {k: find_col(df, v) for k, v in MAP.items()}

def to_number(x):
    if x is None:
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "" or s.lower() in {"nan", "none"}:
        return np.nan
    s = s.replace(" ", "").replace("\u202f","").replace("\xa0","")
    if s.endswith("%"):
        s = s[:-1]
    if "," in s and "." not in s:
        s = s.replace(",", ".")
    try:
        return float(s)
    except Exception:
        return np.nan

def parse_duration_to_seconds(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "":
        return np.nan
    m = re.match(r"^(\d+):(\d{2}):(\d{2})$", s)
    if m:
        h, m_, s_ = map(int, m.groups())
        return h*3600 + m_*60 + s_
    m = re.match(r"^(\d+):(\d{2})$", s)
    if m:
        m_, s_ = map(int, m.groups())
        return m_*60 + s_
    try:
        return float(s)
    except Exception:
        return np.nan

def seconds_to_hhmmss(sec):
    if pd.isna(sec):
        return "‚Äî"
    sec = int(round(sec))
    h = sec // 3600
    m = (sec % 3600) // 60
    s = sec % 60
    return f"{h}:{m:02d}:{s:02d}" if h else f"{m}:{s:02d}"

# ===========================
#   FILE LOADER
# ===========================
def load_uploaded_file(uploaded_file):
    raw = uploaded_file.getvalue() if hasattr(uploaded_file, "getvalue") else uploaded_file.read()
    h = hashlib.md5(raw).hexdigest()
    df = None
    for enc in (None, "utf-8-sig", "cp1251"):
        try:
            df = pd.read_csv(io.BytesIO(raw), encoding=enc) if enc else pd.read_csv(io.BytesIO(raw))
            break
        except Exception:
            df = None
    meta = "‚ùå –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV."
    if df is not None and not df.empty:
        df.columns = [c.strip() for c in df.columns]
        meta = f"‚úÖ {uploaded_file.name}: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫."
    return {"name": uploaded_file.name, "hash": h, "df": df, "meta": meta}

# ===========================
#   SESSION STORE
# ===========================
if "groups" not in st.session_state:
    st.session_state["groups"] = []  # [{name, files:[{name,hash,df,meta}]}]

# ===========================
#   METRIC HELPERS
# ===========================
def kpis_for_group(group):
    total_impr = 0.0
    total_views = 0.0
    ctr_vals, avd_vals = [], []
    for f in group["files"]:
        df = f["df"]
        if df is None or df.empty:
            continue
        C = detect_columns(df)
        if C["impressions"] and C["impressions"] in df.columns:
            total_impr += pd.to_numeric(df[C["impressions"]].apply(to_number), errors="coerce").fillna(0).sum()
        if C["views"] and C["views"] in df.columns:
            total_views += pd.to_numeric(df[C["views"]].apply(to_number), errors="coerce").fillna(0).sum()
        if C["ctr"] and C["ctr"] in df.columns:
            ctr_vals += list(df[C["ctr"]].apply(to_number).dropna().values)
        if C["avd"] and C["avd"] in df.columns:
            avd_vals += list(df[C["avd"]].apply(parse_duration_to_seconds).dropna().values)
    avg_ctr = float(np.nanmean(ctr_vals)) if ctr_vals else np.nan
    avg_avd = float(np.nanmean(avd_vals)) if avd_vals else np.nan
    return dict(impressions=int(total_impr), views=int(total_views), ctr=avg_ctr, avd_sec=avg_avd)

def df_with_core_cols(df: pd.DataFrame) -> pd.DataFrame:
    C = detect_columns(df)
    out = pd.DataFrame(index=range(len(df)))
    # daily date (if exists)
    if C["day"] and C["day"] in df.columns:
        out["day"] = pd.to_datetime(df[C["day"]], errors="coerce")
    # publish date
    if C["publish_time"] and C["publish_time"] in df.columns:
        out["publish_time"] = pd.to_datetime(df[C["publish_time"]], errors="coerce")
    if C["title"] and C["title"] in df.columns:
        out["title"] = df[C["title"]].astype(str)
    if C["impressions"] and C["impressions"] in df.columns:
        out["impressions"] = pd.to_numeric(df[C["impressions"]].apply(to_number), errors="coerce")
    if C["views"] and C["views"] in df.columns:
        out["views"] = pd.to_numeric(df[C["views"]].apply(to_number), errors="coerce")
    if C["ctr"] and C["ctr"] in df.columns:
        out["ctr"] = pd.to_numeric(df[C["ctr"]].apply(to_number), errors="coerce")
    if C["avd"] and C["avd"] in df.columns:
        out["avd_sec"] = df[C["avd"]].apply(parse_duration_to_seconds)
    if C["watch_hours"] and C["watch_hours"] in df.columns:
        out["watch_hours"] = pd.to_numeric(df[C["watch_hours"]].apply(to_number), errors="coerce")
    elif C["watch_minutes"] and C["watch_minutes"] in df.columns:
        out["watch_hours"] = pd.to_numeric(df[C["watch_minutes"]].apply(to_number), errors="coerce")/60.0
    if C["unique_viewers"] and C["unique_viewers"] in df.columns:
        out["unique_viewers"] = pd.to_numeric(df[C["unique_viewers"]].apply(to_number), errors="coerce")
    if C["engaged_views"] and C["engaged_views"] in df.columns:
        out["engaged_views"] = pd.to_numeric(df[C["engaged_views"]].apply(to_number), errors="coerce")
    return out

def timeseries_for_group(group: dict, freq: str = "M") -> pd.DataFrame:
    rows = []
    for f in group["files"]:
        if f["df"] is None or f["df"].empty:
            continue
        base = df_with_core_cols(f["df"])
        # prefer real daily date
        if "day" in base and base["day"].notna().any():
            tmp = base.dropna(subset=["day"]).copy()
            tmp["_period"] = tmp["day"].dt.to_period(freq).dt.to_timestamp()
        elif "publish_time" in base and base["publish_time"].notna().any():
            tmp = base.dropna(subset=["publish_time"]).copy()
            tmp["_period"] = tmp["publish_time"].dt.to_period(freq).dt.to_timestamp()
        else:
            continue
        cols = [c for c in ["impressions","views","ctr","avd_sec","watch_hours","unique_viewers","engaged_views"] if c in tmp.columns]
        rows.append(tmp[["_period"]+cols])
    if not rows:
        return pd.DataFrame(columns=["Date","Impressions","Views","CTR","AVD_sec","Watch_hours","Unique_viewers","Engaged_views"])
    all_df = pd.concat(rows, ignore_index=True)
    ag = (all_df.groupby("_period")
           .agg(**{
               "Impressions":("impressions","sum") if "impressions" in all_df.columns else ("_period","size"),
               "Views":("views","sum") if "views" in all_df.columns else ("_period","size"),
               "CTR":("ctr","mean") if "ctr" in all_df.columns else ("_period","size"),
               "AVD_sec":("avd_sec","mean") if "avd_sec" in all_df.columns else ("_period","size"),
               "Watch_hours":("watch_hours","sum") if "watch_hours" in all_df.columns else ("_period","size"),
               "Unique_viewers":("unique_viewers","sum") if "unique_viewers" in all_df.columns else ("_period","size"),
               "Engaged_views":("engaged_views","sum") if "engaged_views" in all_df.columns else ("_period","size"),
           }).reset_index()
           .rename(columns={"_period":"Date"})
           .sort_values("Date"))
    return ag

def by_year_for_group(group: dict) -> pd.DataFrame:
    rows = []
    for f in group["files"]:
        if f["df"] is None or f["df"].empty:
            continue
        base = df_with_core_cols(f["df"])
        dt_col = "publish_time" if "publish_time" in base else ("day" if "day" in base else None)
        if not dt_col:
            continue
        tmp = base.dropna(subset=[dt_col]).copy()
        tmp["_year"] = tmp[dt_col].dt.year
        rows.append(tmp[["_year","impressions","views","ctr","avd_sec"]])
    if not rows:
        return pd.DataFrame(columns=["–ì–æ–¥","–ü–æ–∫–∞–∑—ã","–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","CTR","AVD_sec","–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–∏–¥–µ–æ"])
    all_df = pd.concat(rows, ignore_index=True)
    out = (all_df.groupby("_year")
               .agg(–ü–æ–∫–∞–∑—ã=("impressions","sum"),
                    –ü—Ä–æ—Å–º–æ—Ç—Ä—ã=("views","sum"),
                    CTR=("ctr","mean"),
                    AVD_sec=("avd_sec","mean"),
                    –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–∏–¥–µ–æ=("views","count"))
               .reset_index()
               .rename(columns={"_year":"–ì–æ–¥"})
               .sort_values("–ì–æ–¥"))
    return out

# ===========================
#   DASHBOARD
# ===========================
if nav.endswith("Dashboard"):
    st.header("Dashboard")

    # ----- –¥–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É -----
    with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É –¥–∞–Ω–Ω—ã—Ö", expanded=True):
        group_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)", value=f"Group {len(st.session_state['groups'])+1}")
        files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV", type=["csv"], accept_multiple_files=True, key="add_group_files")
        if st.button("–î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É"):
            if not group_name.strip():
                st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã.")
            elif not files:
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
            else:
                new_files = []
                for uf in files:
                    pack = load_uploaded_file(uf)
                    if pack["df"] is None or pack["df"].empty:
                        continue
                    new_files.append(pack)
                if new_files:
                    st.session_state["groups"].append({"name": group_name.strip(), "files": new_files})
                    st.success(f"–ì—Ä—É–ø–ø–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞. –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(new_files)}.")
                    do_rerun()
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª—ã.")

    if not st.session_state["groups"]:
        st.info("–î–æ–±–∞–≤—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É –≤ —Å–∞–π–¥–±–∞—Ä–µ.")
    else:
        st.markdown("### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø–∞–º–∏")
        for gi, g in enumerate(st.session_state["groups"]):
            with st.expander(f"–ì—Ä—É–ø–ø–∞: {g['name']}", expanded=False):
                new_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ", value=g["name"], key=f"rename_{gi}")
                add_more = st.file_uploader("–î–æ–±–∞–≤–∏—Ç—å –æ—Ç—á—ë—Ç—ã –≤ —ç—Ç—É –≥—Ä—É–ø–ø—É", type=["csv"], accept_multiple_files=True, key=f"append_files_{gi}")
                if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", key=f"save_group_{gi}"):
                    changed = False
                    if new_name.strip() and new_name.strip()!=g["name"]:
                        g["name"] = new_name.strip(); changed=True
                    if add_more:
                        added=0
                        for uf in add_more:
                            pack = load_uploaded_file(uf)
                            if pack["df"] is None or pack["df"].empty: 
                                continue
                            g["files"].append(pack)  # –¥—É–±–ª–∏–∫–∞—Ç—ã –¥–æ–ø—É—Å—Ç–∏–º—ã
                            added+=1
                        if added:
                            st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {added}.")
                            changed=True
                    if changed: do_rerun()
                    else: st.info("–ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç.")

                st.markdown("**–§–∞–π–ª—ã –≥—Ä—É–ø–ø—ã:**")
                if not g["files"]:
                    st.write("‚Äî –ø–æ–∫–∞ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤.")
                else:
                    for fi, f in enumerate(g["files"]):
                        c1, c2 = st.columns([4,1])
                        with c1: st.write(f["meta"])
                        with c2:
                            if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"del_file_{gi}_{fi}"):
                                g["files"].pop(fi); do_rerun()

                st.divider()
                if st.button("–£–¥–∞–ª–∏—Ç—å –≥—Ä—É–ø–ø—É", key=f"del_group_{gi}"):
                    st.session_state["groups"].pop(gi); do_rerun()

        st.divider()

        # KPI + –ø–æ–º–µ—Å—è—á–Ω—ã–µ
        st.markdown("### –°–≤–æ–¥–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º")
        rows=[]
        for gi, g in enumerate(st.session_state["groups"]):
            kp = kpis_for_group(g)
            st.subheader(f"–ì—Ä—É–ø–ø–∞: {g['name']}")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("–ü–æ–∫–∞–∑—ã (—Å—É–º–º–∞)", f"{kp['impressions']:,}".replace(",", " "))
            c2.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã (—Å—É–º–º–∞)", f"{kp['views']:,}".replace(",", " "))
            c3.metric("–°—Ä–µ–¥–Ω–∏–π CTR –ø–æ –≤–∏–¥–µ–æ", "‚Äî" if np.isnan(kp["ctr"]) else f"{kp['ctr']:.2f}%")
            c4.metric("–°—Ä–µ–¥–Ω–∏–π AVD", seconds_to_hhmmss(kp["avd_sec"]))

            ts = timeseries_for_group(g, freq="M")
            if not ts.empty:
                with st.expander("üìÜ –ü—Ä–æ—Å–º–æ—Ç—Ä—ã –ø–æ –º–µ—Å—è—Ü–∞–º", expanded=False):
                    fig = px.line(ts, x="Date", y="Views", markers=True, template="simple_white")
                    fig.update_traces(line_color="#59a14f")
                    st.plotly_chart(fig, use_container_width=True, height=400)
            st.divider()
            rows.append({
                "–ì—Ä—É–ø–ø–∞": g["name"],
                "–ü–æ–∫–∞–∑—ã": kp["impressions"],
                "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": kp["views"],
                "CTR, % (—Å—Ä.)": None if np.isnan(kp["ctr"]) else round(kp["ctr"],2),
                "AVD (—Å—Ä.)": seconds_to_hhmmss(kp["avd_sec"])
            })
        if rows:
            st.markdown("### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø")
            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

# ===========================
#   GROUP ANALYTICS
# ===========================
else:
    st.header("Group Analytics")
    tool = st.sidebar.selectbox("–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞", ["Advanced mode (–∫–∞–∫ –≤ Studio)","–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º"])

    # -------------------- ADVANCED MODE --------------------
    if tool.startswith("Advanced"):
        if not st.session_state["groups"]:
            st.info("–ù–µ—Ç –≥—Ä—É–ø–ø. –î–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ Dashboard.")
            st.stop()

        names = [g["name"] for g in st.session_state["groups"]]
        gi = st.selectbox("–ì—Ä—É–ø–ø–∞ (Controls)", range(len(names)), format_func=lambda i: names[i])
        group = st.session_state["groups"][gi]

        # —Å–æ–±–µ—Ä—ë–º ¬´–ø–ª–æ—Å–∫–∏–π¬ª –¥–∞—Ç–∞—Å–µ—Ç –ø–æ —Ä–æ–ª–∏–∫–∞–º
        frames=[]
        daily_available=False
        min_day=None; max_day=None
        for f in group["files"]:
            df = f["df"]
            if df is None or df.empty: 
                continue
            base = df_with_core_cols(df)
            if "title" not in base: 
                continue
            d = base.copy()
            # –µ—Å—Ç—å –ª–∏ –¥–Ω–µ–≤–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞?
            if "day" in d and d["day"].notna().any():
                daily_available=True
                if min_day is None: 
                    min_day = d["day"].min()
                    max_day = d["day"].max()
                else:
                    min_day = min(min_day, d["day"].min())
                    max_day = max(max_day, d["day"].max())
            frames.append(d)

        if not frames:
            st.warning("–í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ –Ω–∞—à–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –≤–∏–¥–µ–æ.")
            st.stop()

        data = pd.concat(frames, ignore_index=True)

        # –§–∏–ª—å—Ç—Ä—ã (–∫–∞–∫ –≤ Studio)
        st.markdown("#### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ç–æ—Ä")
        colA, colB, colC, colD = st.columns([2,2,2,2])

        # –ø–µ—Ä–∏–æ–¥
        if daily_available:
            start, end = colA.date_input(
                "–ü–µ—Ä–∏–æ–¥ (Date range)",
                value=(min_day.date(), max_day.date()),
                min_value=min_day.date(), max_value=max_day.date()
            )
            # –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º
            mask = data["day"].notna() & (data["day"]>=pd.to_datetime(start)) & (data["day"]<=pd.to_datetime(end))
            data_f = data.loc[mask].copy()
            period_note = ""
        else:
            period_note = "‚ö†Ô∏è –í –∏—Å—Ç–æ—á–Ω–∏–∫–µ –Ω–µ—Ç –¥–Ω–µ–≤–Ω—ã—Ö –¥–∞—Ç. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∞ –ø–æ–º–µ—Å—è—á–Ω–æ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏."
            data_f = data.copy()

        # –º–µ—Ç—Ä–∏–∫–∏ ‚Äî —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ
        metric_candidates = [
            ("Views","views"),
            ("Engaged views","engaged_views"),
            ("Impressions","impressions"),
            ("CTR, %","ctr"),
            ("Watch time (hours)","watch_hours"),
            ("Unique viewers","unique_viewers"),
            ("AVD (sec)","avd_sec"),
        ]
        available_metrics = [ui for ui,col in metric_candidates if col in data_f.columns]
        picked_metrics = colB.multiselect("Metrics (—á—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –≤ —Ç–∞–±–ª–∏—Ü–µ)", available_metrics,
                                          default=[m for m in available_metrics if m.startswith("Views") or m.startswith("Impressions")][:2])

        # TopN –∏ –ø–æ–∏—Å–∫
        topN = int(colC.number_input("Top-N (–ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º)", min_value=3, max_value=500, value=50, step=1))
        search = colD.text_input("Filter (–ø–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é)")

        st.write(period_note)

        # Breakdown (–ø–æ–∫–∞ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ‚Äî Content)
        st.caption("Breakdown: **Content** (–≤–∏–¥–µ–æ)")

        # –ø—Ä–∏–º–µ–Ω–∏–º —Ñ–∏–ª—å—Ç—Ä –ø–æ–∏—Å–∫–∞ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
        if search.strip():
            mask = data_f["title"].str.contains(search.strip(), case=False, na=False)
            data_f = data_f.loc[mask].copy()

        # —Ç–∞–±–ª–∏—Ü–∞ –ø–æ –≤–∏–¥–µ–æ (–∞–≥—Ä–µ–≥–∞—Ü–∏—è –∑–∞ –ø–µ—Ä–∏–æ–¥)
        agg_cols = {}
        if "views" in data_f.columns: agg_cols["Views"]=("views","sum")
        if "engaged_views" in data_f.columns: agg_cols["Engaged views"]=("engaged_views","sum")
        if "impressions" in data_f.columns: agg_cols["Impressions"]=("impressions","sum")
        if "ctr" in data_f.columns: agg_cols["CTR, %"]=("ctr","mean")
        if "watch_hours" in data_f.columns: agg_cols["Watch time (hours)"]=("watch_hours","sum")
        if "unique_viewers" in data_f.columns: agg_cols["Unique viewers"]=("unique_viewers","sum")
        if "avd_sec" in data_f.columns: agg_cols["AVD (sec)"]=("avd_sec","mean")

        per_title = (data_f.groupby("title").agg(**agg_cols).reset_index())
        # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è TopN ‚Äì –ø–æ Views –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –ø–æ –ø–µ—Ä–≤–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ
        sort_col = "Views" if "Views" in per_title.columns else (picked_metrics[0] if picked_metrics else per_title.columns[1])
        per_title = per_title.sort_values(sort_col, ascending=False)
        top_titles = per_title["title"].head(topN).tolist()

        # –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å –≥—Ä–∞—Ñ–∏–∫–∞
        show_chart = st.toggle("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –≥—Ä–∞—Ñ–∏–∫", value=True)

        # –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä—è–¥–æ–≤ (–ø–æ –¥–Ω—è–º –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –ø–æ –º–µ—Å—è—Ü–∞–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏)
        if show_chart:
            if daily_available:
                # –ø–æ—Å—Ç—Ä–æ–∏–º –ø—Ä–æ—Å—Ç–æ –ª–∏–Ω–∏–∏: –¥–∞—Ç–∞ -> –º–µ—Ç—Ä–∏–∫–∞ Views, –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º
                # –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å, –∫–∞–∫—É—é –º–µ—Ç—Ä–∏–∫—É —Ä–∏—Å–æ–≤–∞—Ç—å –≤ –ª–∏–Ω–∏—è—Ö ‚Äî –≤–æ–∑—å–º—ë–º –ø–µ—Ä–≤—É—é –≤—ã–±—Ä–∞–Ω–Ω—É—é, –∏–Ω–∞—á–µ Views
                line_metric_label = picked_metrics[0] if picked_metrics else ("Views" if "views" in data_f.columns else available_metrics[0])
                line_metric_col = [c for (ui,c) in metric_candidates if ui==line_metric_label][0]

                # —Å–æ–±–µ—Ä—ë–º –¥–∞—Ç–∞-—Å–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è Top-N
                df_plot = data_f[data_f["title"].isin(top_titles)].copy()
                df_plot = df_plot.dropna(subset=["day"])
                if df_plot.empty:
                    st.info("–ù–µ—Ç –¥–Ω–µ–≤–Ω—ã—Ö —Ç–æ—á–µ–∫ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –≤–∏–¥–µ–æ.")
                else:
                    df_plot["_date"] = df_plot["day"].dt.floor("D")
                    y_label = line_metric_label
                    y_col = line_metric_col
                    dfp = (df_plot.groupby(["_date","title"])
                                  .agg(val=(y_col,"sum"))
                                  .reset_index()
                                  .rename(columns={"_date":"Date","title":"Content"}))
                    fig = px.line(dfp, x="Date", y="val", color="Content", template="simple_white")
                    fig.update_layout(height=420, xaxis_title="", yaxis_title=y_label, legend=dict(orientation="h", y=1.1))
                    st.plotly_chart(fig, use_container_width=True)
            else:
                # fallback: –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –ø–æ –º–µ—Å—è—Ü—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –∏ —Ä–∏—Å—É–µ–º
                df_plot = data[data["title"].isin(top_titles)].copy()
                if "publish_time" not in df_plot or df_plot["publish_time"].isna().all():
                    st.info("–ù–µ—Ç –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ ‚Äî –Ω–µ—á–µ–≥–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å.")
                else:
                    df_plot["_period"] = df_plot["publish_time"].dt.to_period("M").dt.to_timestamp()
                    line_metric_label = picked_metrics[0] if picked_metrics else ("Views" if "views" in df_plot.columns else available_metrics[0])
                    line_metric_col = [c for (ui,c) in metric_candidates if ui==line_metric_label][0]
                    dfp = (df_plot.groupby(["_period","title"])
                                   .agg(val=(line_metric_col,"sum"))
                                   .reset_index()
                                   .rename(columns={"_period":"Date","title":"Content"}))
                    fig = px.line(dfp, x="Date", y="val", color="Content", template="simple_white")
                    fig.update_layout(height=420, xaxis_title="", yaxis_title=line_metric_label, legend=dict(orientation="h", y=1.1))
                    st.plotly_chart(fig, use_container_width=True)

        # —Ç–∞–±–ª–∏—Ü–∞ –Ω–∏–∂–µ ‚Äî —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ (–∫–∞–∫ –≤ Studio)
        show_cols = ["title"] + [ui for ui in picked_metrics if ui in per_title.columns]
        table = per_title[show_cols].copy()
        table.rename(columns={"title":"Content"}, inplace=True)

        # —Å—Ç—Ä–æ–∫–∞ Total —Å–≤–µ—Ä—Ö—É
        totals = {}
        for c in table.columns:
            if c == "Content": continue
            if "CTR" in c or "AVD" in c:  # —Å—Ä–µ–¥–Ω–∏–µ
                totals[c] = round(per_title[c].mean(), 3)
            else:
                totals[c] = per_title[c].sum()
        total_row = pd.DataFrame([{"Content":"Total", **totals}])
        table = pd.concat([total_row, table], ignore_index=True)

        st.dataframe(table, use_container_width=True, hide_index=True)

    # -------------------- YEAR COMPARE --------------------
    else:
        st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º")
        if not st.session_state["groups"]:
            st.info("–ù–µ—Ç –≥—Ä—É–ø–ø. –î–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ Dashboard.")
            st.stop()
        names = [g["name"] for g in st.session_state["groups"]]
        gi = st.selectbox("–ì—Ä—É–ø–ø–∞", range(len(names)), format_func=lambda i: names[i])
        g = st.session_state["groups"][gi]
        y = by_year_for_group(g)
        if y.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –≥–æ–¥–∞–º.")
            st.stop()
        y = y.rename(columns={"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã":"Views", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ_–≤–∏–¥–µ–æ":"Count"})
        c1, c2 = st.columns(2)
        with c1:
            fig1 = px.bar(y, x="–ì–æ–¥", y="Views", template="simple_white", color_discrete_sequence=["#4e79a7"])
            fig1.update_layout(height=420, xaxis_title="–ì–æ–¥", yaxis_title="–°—É–º–º–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤")
            st.plotly_chart(fig1, use_container_width=True)
        with c2:
            fig2 = px.bar(y, x="–ì–æ–¥", y="Count", template="simple_white", color_discrete_sequence=["#59a14f"])
            fig2.update_layout(height=420, xaxis_title="–ì–æ–¥", yaxis_title="–ö–æ–ª-–≤–æ –≤–∏–¥–µ–æ")
            st.plotly_chart(fig2, use_container_width=True)
