# app.py ‚Äî YouTube Analytics Tools
# Dashboard (–≥—Ä—É–ø–ø—ã + —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ) –∏ Group Analytics (Year Mix, Timeseries Overlay)
# NEW: –ø–æ–º–µ—Å—è—á–Ω—ã–µ/–Ω–µ–¥–µ–ª—å–Ω—ã–µ/–∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –Ω–∞–ª–æ–∂–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
# –î—É–±–ª–∏–∫–∞—Ç—ã CSV –†–ê–ó–†–ï–®–ï–ù–´.

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import io, re, hashlib

# --------------------------- UI CONFIG ---------------------------
st.set_page_config(page_title="YouTube Analytics Tools", layout="wide")
USE_EMOJI = True
ICON_DASH  = "üìä " if USE_EMOJI else ""
ICON_GROUP = "üß© " if USE_EMOJI else ""
ICON_BRAND = "üì∫ " if USE_EMOJI else ""

st.sidebar.markdown(
    f"<div style='font-weight:700;font-size:1.05rem;letter-spacing:.1px;'>{ICON_BRAND}YouTube Analytics Tools</div>",
    unsafe_allow_html=True,
)
st.sidebar.divider()
nav = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", [f"{ICON_DASH}Dashboard", f"{ICON_GROUP}Group Analytics"])
st.sidebar.divider()

# --------------------------- HELPERS: columns / parsing ---------------------------
def _norm(s: str) -> str:
    return str(s).strip().lower()

MAP = {
    "publish_time": ["video publish time","publish time","–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ","–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏","publish date"],
    "views": ["views","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã","–ø—Ä–æ—Å–º—Ç–æ—Ä—ã","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã (views)"],
    "impressions": ["impressions","–ø–æ–∫–∞–∑—ã","–ø–æ–∫–∞–∑—ã (impressions)","–ø–æ–∫–∞–∑—ã –∑–Ω–∞—á–∫–æ–≤","–ø–æ–∫–∞–∑—ã –¥–ª—è –∑–Ω–∞—á–∫–æ–≤"],
    "ctr": ["impressions click-through rate","ctr","ctr (%)","ctr for thumbnails (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤",
            "ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ","ctr –≤–∏–¥–µ–æ"],
    "avd": ["average view duration","avg view duration","—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
            "—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–∏–¥–µ–æ","average view duration (hh:mm:ss)"],
    "title": ["title","–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ","video title","–≤–∏–¥–µ–æ","–Ω–∞–∑–≤–∞–Ω–∏–µ"],
}

def find_col(df: pd.DataFrame, names) -> str | None:
    if isinstance(names, str):
        names = [names]
    by_norm = {_norm(c): c for c in df.columns}
    for n in names:
        nn = _norm(n)
        if nn in by_norm:
            return by_norm[nn]
    for n in names:
        nn = _norm(n)
        for c in df.columns:
            if nn in _norm(c):
                return c
    return None

def detect_columns(df: pd.DataFrame):
    return {k: find_col(df, v) for k, v in MAP.items()}

def to_number(x):
    if x is None:
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "" or s.lower() in {"nan", "none"}:
        return np.nan
    s = s.replace(" ", "").replace("\u202f", "").replace("\xa0", "")
    is_percent = s.endswith("%")
    if is_percent:
        s = s[:-1]
    if "," in s and "." not in s:
        s = s.replace(",", ".")
    try:
        return float(s)
    except Exception:
        return np.nan

def parse_duration_to_seconds(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "":
        return np.nan
    m = re.match(r"^(\d+):(\d{2}):(\d{2})$", s)
    if m:
        h, m_, s_ = map(int, m.groups())
        return h * 3600 + m_ * 60 + s_
    m = re.match(r"^(\d+):(\d{2})$", s)
    if m:
        m_, s_ = map(int, m.groups())
        return m_ * 60 + s_
    try:
        return float(s)
    except Exception:
        return np.nan

def seconds_to_hhmmss(sec):
    if pd.isna(sec):
        return "‚Äî"
    sec = int(round(sec))
    h = sec // 3600
    m = (sec % 3600) // 60
    s = sec % 60
    return f"{h}:{m:02d}:{s:02d}" if h else f"{m}:{s:02d}"

# --------------------------- FILE LOADER ---------------------------
def load_uploaded_file(uploaded_file):
    raw = uploaded_file.getvalue() if hasattr(uploaded_file, "getvalue") else uploaded_file.read()
    h = hashlib.md5(raw).hexdigest()
    df = None
    for enc in (None, "utf-8-sig", "cp1251"):
        try:
            df = pd.read_csv(io.BytesIO(raw), encoding=enc) if enc else pd.read_csv(io.BytesIO(raw))
            break
        except Exception:
            df = None
    meta = "‚ùå –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV."
    if df is not None and not df.empty:
        df.columns = [c.strip() for c in df.columns]
        meta = f"‚úÖ {uploaded_file.name}: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫."
    return {"name": uploaded_file.name, "hash": h, "df": df, "meta": meta}

# --------------------------- STORAGE ---------------------------
if "groups" not in st.session_state:
    st.session_state["groups"] = []   # [{name: str, files: [{name, hash, df, meta}, ...]}]

def concat_groups(indices):
    frames = []
    for i in indices:
        if 0 <= i < len(st.session_state["groups"]):
            for f in st.session_state["groups"][i]["files"]:
                if f["df"] is not None and not f["df"].empty:
                    frames.append(f["df"])
    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()

def kpis_for_group(group):
    total_impr = 0.0
    total_views = 0.0
    ctr_vals = []
    avd_vals = []
    for f in group["files"]:
        df = f["df"]
        if df is None or df.empty:
            continue
        C = detect_columns(df)
        if C["impressions"] and C["impressions"] in df.columns:
            total_impr += pd.to_numeric(df[C["impressions"]].apply(to_number), errors="coerce").fillna(0).sum()
        if C["views"] and C["views"] in df.columns:
            total_views += pd.to_numeric(df[C["views"]].apply(to_number), errors="coerce").fillna(0).sum()
        if C["ctr"] and C["ctr"] in df.columns:
            ctr_vals += list(df[C["ctr"]].apply(to_number).dropna().values)
        if C["avd"] and C["avd"] in df.columns:
            avd_vals += list(df[C["avd"]].apply(parse_duration_to_seconds).dropna().values)
    avg_ctr = float(np.nanmean(ctr_vals)) if ctr_vals else np.nan
    avg_avd = float(np.nanmean(avd_vals)) if avd_vals else np.nan
    return dict(impressions=int(total_impr), views=int(total_views), ctr=avg_ctr, avd_sec=avg_avd)

# --------------------------- MONTHLY AGG FOR GROUP ---------------------------
def monthly_aggregate_for_group(group: dict) -> pd.DataFrame:
    rows = []
    for f in group["files"]:
        df = f["df"]
        if df is None or df.empty:
            continue
        C = detect_columns(df)
        pub_col = C["publish_time"]
        if not (pub_col and pub_col in df.columns):
            continue

        tmp = df.copy()
        tmp[pub_col] = pd.to_datetime(tmp[pub_col], errors="coerce")
        tmp = tmp[tmp[pub_col].notna()]
        if tmp.empty:
            continue

        imp = C["impressions"]; vws = C["views"]; avd = C["avd"]
        tmp["_impr"]    = pd.to_numeric(tmp[imp].apply(to_number), errors="coerce") if (imp and imp in tmp.columns) else np.nan
        tmp["_views"]   = pd.to_numeric(tmp[vws].apply(to_number), errors="coerce") if (vws and vws in tmp.columns) else np.nan
        tmp["_avd_sec"] = tmp[avd].apply(parse_duration_to_seconds)                 if (avd and avd in tmp.columns) else np.nan

        tmp["_month"] = tmp[pub_col].dt.to_period("M").dt.to_timestamp()
        rows.append(tmp[["_month", "_impr", "_views", "_avd_sec"]])

    if not rows:
        return pd.DataFrame(columns=["–ú–µ—Å—è—Ü","–ü–æ–∫–∞–∑—ã","–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","AVD_sec"])

    all_df = pd.concat(rows, ignore_index=True)
    ag = (
        all_df.groupby("_month")
              .agg(–ü–æ–∫–∞–∑—ã=("_impr","sum"), –ü—Ä–æ—Å–º–æ—Ç—Ä—ã=("_views","sum"), AVD_sec=("_avd_sec","mean"))
              .reset_index()
              .rename(columns={"_month":"–ú–µ—Å—è—Ü"})
              .sort_values("–ú–µ—Å—è—Ü")
    )
    ag["–ü–æ–∫–∞–∑—ã"] = ag["–ü–æ–∫–∞–∑—ã"].fillna(0)
    ag["–ü—Ä–æ—Å–º–æ—Ç—Ä—ã"] = ag["–ü—Ä–æ—Å–º–æ—Ç—Ä—ã"].fillna(0)
    return ag

# ---------- TIMESERIES for overlay ----------
def timeseries_for_group(group: dict, freq: str = "M") -> pd.DataFrame:
    """–ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å –∑–∞–¥–∞–Ω–Ω–æ–π —á–∞—Å—Ç–æ—Ç–æ–π.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: Date | Impressions | Views | CTR | AVD_sec
    –°—É–º–º—ã: Impressions, Views; –°—Ä–µ–¥–Ω–µ–µ: CTR, AVD_sec
    """
    rows = []
    for f in group["files"]:
        df = f["df"]
        if df is None or df.empty:
            continue
        C = detect_columns(df)
        pub_col = C["publish_time"]
        if not (pub_col and pub_col in df.columns):
            continue

        tmp = df.copy()
        tmp[pub_col] = pd.to_datetime(tmp[pub_col], errors="coerce")
        tmp = tmp[tmp[pub_col].notna()]
        if tmp.empty:
            continue

        imp = C["impressions"]; vws = C["views"]; avd = C["avd"]; ctr = C["ctr"]
        tmp["_impr"]    = pd.to_numeric(tmp[imp].apply(to_number), errors="coerce") if (imp and imp in tmp.columns) else np.nan
        tmp["_views"]   = pd.to_numeric(tmp[vws].apply(to_number), errors="coerce") if (vws and vws in tmp.columns) else np.nan
        tmp["_avd_sec"] = tmp[avd].apply(parse_duration_to_seconds)                 if (avd and avd in tmp.columns) else np.nan
        tmp["_ctr"]     = pd.to_numeric(tmp[ctr].apply(to_number), errors="coerce") if (ctr and ctr in tmp.columns) else np.nan

        tmp["_period"] = tmp[pub_col].dt.to_period(freq).dt.to_timestamp()
        rows.append(tmp[["_period","_impr","_views","_avd_sec","_ctr"]])

    if not rows:
        return pd.DataFrame(columns=["Date","Impressions","Views","CTR","AVD_sec"])

    all_df = pd.concat(rows, ignore_index=True)
    ag = (
        all_df.groupby("_period")
              .agg(Impressions=("_impr","sum"),
                   Views=("_views","sum"),
                   AVD_sec=("_avd_sec","mean"),
                   CTR=("_ctr","mean"))
              .reset_index()
              .rename(columns={"_period":"Date"})
              .sort_values("Date")
    )
    return ag

# --------------------------- DASHBOARD ---------------------------
if nav.endswith("Dashboard"):
    st.header("Dashboard")

    # --- –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
    with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É –¥–∞–Ω–Ω—ã—Ö", expanded=True):
        group_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)", value=f"Group {len(st.session_state['groups'])+1}")
        files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV", type=["csv"], accept_multiple_files=True, key="add_group_files")
        if st.button("–î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É"):
            if not group_name.strip():
                st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã.")
            elif not files:
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
            else:
                new_files = []
                for uf in files:
                    pack = load_uploaded_file(uf)
                    if pack["df"] is None or pack["df"].empty:
                        continue
                    # –î—É–±–ª–∏–∫–∞—Ç—ã –†–ê–ó–†–ï–®–ï–ù–´ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å—ë
                    new_files.append(pack)
                if new_files:
                    st.session_state["groups"].append({"name": group_name.strip(), "files": new_files})
                    st.success(f"–ì—Ä—É–ø–ø–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞. –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(new_files)}.")
                    st.rerun()
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª—ã (–≤–æ–∑–º–æ–∂–Ω–æ –ø—É—Å—Ç—ã–µ/–ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã).")

    if not st.session_state["groups"]:
        st.info("–î–æ–±–∞–≤—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É –≤ —Å–∞–π–¥–±–∞—Ä–µ.")
    else:
        # --- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø–∞–º–∏
        st.markdown("### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø–∞–º–∏")
        for gi, g in enumerate(st.session_state["groups"]):
            with st.expander(f"–ì—Ä—É–ø–ø–∞: {g['name']}", expanded=False):
                new_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ", value=g["name"], key=f"rename_{gi}")
                add_more = st.file_uploader(
                    "–î–æ–±–∞–≤–∏—Ç—å –æ—Ç—á—ë—Ç—ã –≤ —ç—Ç—É –≥—Ä—É–ø–ø—É",
                    type=["csv"], accept_multiple_files=True, key=f"append_files_{gi}"
                )

                if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", key=f"save_group_{gi}"):
                    changed = False
                    if new_name.strip() and new_name.strip() != g["name"]:
                        g["name"] = new_name.strip()
                        changed = True
                    if add_more:
                        added = 0
                        for uf in add_more:
                            pack = load_uploaded_file(uf)
                            if pack["df"] is None or pack["df"].empty:
                                continue
                            g["files"].append(pack)   # –¥—É–±–ª–∏–∫–∞—Ç—ã —Ä–∞–∑—Ä–µ—à–µ–Ω—ã
                            added += 1
                        if added:
                            st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {added}.")
                            changed = True
                    if changed:
                        st.rerun()
                    else:
                        st.info("–ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç ‚Äî –Ω–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å.")

                st.markdown("**–§–∞–π–ª—ã –≥—Ä—É–ø–ø—ã:**")
                if not g["files"]:
                    st.write("‚Äî –ø–æ–∫–∞ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤.")
                else:
                    for fi, f in enumerate(g["files"]):
                        c1, c2 = st.columns([4,1])
                        with c1:
                            st.write(f["meta"])
                        with c2:
                            if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"del_file_{gi}_{fi}"):
                                g["files"].pop(fi)
                                st.rerun()

                st.divider()
                if st.button("–£–¥–∞–ª–∏—Ç—å –≥—Ä—É–ø–ø—É", key=f"del_group_{gi}"):
                    st.session_state["groups"].pop(gi)
                    st.rerun()

        st.divider()

        # --- KPI –∏ –ü–û–ú–ï–°–Ø–ß–ù–´–ï –ì–†–ê–§–ò–ö–ò –ü–û –ö–ê–ñ–î–û–ô –ì–†–£–ü–ü–ï ---
        st.markdown("### –°–≤–æ–¥–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º")
        kpi_rows = []
        for gi, g in enumerate(st.session_state["groups"]):
            kp = kpis_for_group(g)
            st.subheader(f"–ì—Ä—É–ø–ø–∞: {g['name']}")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("–ü–æ–∫–∞–∑—ã (—Å—É–º–º–∞)", f"{kp['impressions']:,}".replace(",", " "))
            c2.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã (—Å—É–º–º–∞)", f"{kp['views']:,}".replace(",", " "))
            c3.metric("–°—Ä–µ–¥–Ω–∏–π CTR –ø–æ –≤–∏–¥–µ–æ", "‚Äî" if np.isnan(kp["ctr"]) else f"{kp['ctr']:.2f}%")
            c4.metric("–°—Ä–µ–¥–Ω–∏–π AVD", seconds_to_hhmmss(kp["avd_sec"]))

            monthly = monthly_aggregate_for_group(g)
            if monthly.empty:
                st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö (–Ω–µ—Ç –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏) –¥–ª—è –ø–æ–º–µ—Å—è—á–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤.")
            else:
                with st.expander("üìÜ –ü–æ–∫–∞–∑—ã –ø–æ –º–µ—Å—è—Ü–∞–º", expanded=False):
                    fig_imp = px.line(monthly, x="–ú–µ—Å—è—Ü", y="–ü–æ–∫–∞–∑—ã", markers=True, template="simple_white")
                    fig_imp.update_traces(line_color="#4e79a7")
                    fig_imp.update_layout(xaxis_title="–ú–µ—Å—è—Ü", yaxis_title="–ü–æ–∫–∞–∑—ã",
                                         margin=dict(l=10, r=10, t=30, b=10), height=400)
                    st.plotly_chart(fig_imp, use_container_width=True)

                with st.expander("üëÅ –ü—Ä–æ—Å–º–æ—Ç—Ä—ã –ø–æ –º–µ—Å—è—Ü–∞–º", expanded=False):
                    fig_view = px.line(monthly, x="–ú–µ—Å—è—Ü", y="–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", markers=True, template="simple_white")
                    fig_view.update_traces(line_color="#59a14f")
                    fig_view.update_layout(xaxis_title="–ú–µ—Å—è—Ü", yaxis_title="–ü—Ä–æ—Å–º–æ—Ç—Ä—ã",
                                           margin=dict(l=10, r=10, t=30, b=10), height=400)
                    st.plotly_chart(fig_view, use_container_width=True)

                with st.expander("‚è± AVD –ø–æ –º–µ—Å—è—Ü–∞–º", expanded=False):
                    tmp = monthly.copy()
                    tmp["AVD_text"] = tmp["AVD_sec"].apply(seconds_to_hhmmss)
                    fig_avd = px.line(tmp, x="–ú–µ—Å—è—Ü", y="AVD_sec", markers=True, template="simple_white",
                                      hover_data={"AVD_text": True, "AVD_sec": False})
                    fig_avd.update_traces(line_color="#e15759",
                                          hovertemplate="–ú–µ—Å—è—Ü=%{x|%Y-%m}<br>AVD=%{customdata[0]}")
                    fig_avd.update_layout(xaxis_title="–ú–µ—Å—è—Ü", yaxis_title="AVD, —Å–µ–∫ (—Å—Ä.)",
                                          margin=dict(l=10, r=10, t=30, b=10), height=400)
                    st.plotly_chart(fig_avd, use_container_width=True)

            st.divider()

            kpi_rows.append({
                "–ì—Ä—É–ø–ø–∞": g["name"],
                "–ü–æ–∫–∞–∑—ã": kp["impressions"],
                "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": kp["views"],
                "CTR, % (—Å—Ä–µ–¥–Ω–µ–µ)": None if np.isnan(kp["ctr"]) else round(kp["ctr"], 2),
                "AVD (—Å—Ä.)": seconds_to_hhmmss(kp["avd_sec"]),
            })

        if kpi_rows:
            st.markdown("### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø")
            comp_df = pd.DataFrame(kpi_rows)
            st.dataframe(comp_df, use_container_width=True, hide_index=True)

# --------------------------- GROUP ANALYTICS ---------------------------
else:
    st.header("Group Analytics")
    tool = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞",
        ["–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (Year Mix)", "–ù–∞–ª–æ–∂–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ (Timeseries)"]
    )

    # --------- Year Mix (–∫–∞–∫ —Ä–∞–Ω—å—à–µ) ---------
    if tool.startswith("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º"):
        # (–æ—Å—Ç–∞–≤–∏–ª –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ‚Äî –≤–∞—à –ø—Ä–µ–∂–Ω–∏–π –º–æ–¥—É–ª—å Year Mix)
        # ... –∏–∑-–∑–∞ –æ–±—ä—ë–º–∞ –∑–¥–µ—Å—å –±—ã–ª –±—ã –¥—É–±–ª—å ‚Äî —ç—Ç–æ—Ç –±–ª–æ–∫ –≤ –≤–∞—à–µ–π –≤–µ—Ä—Å–∏–∏ —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç ...
        st.info("Year Mix –æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–∫–∞–∫ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏ –∫–æ–¥–∞).")

    # --------- NEW: Timeseries Overlay ---------
    else:
        st.subheader("–ù–∞–ª–æ–∂–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ (Timeseries)")

        source_mode = st.sidebar.radio("–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö", ["–ì—Ä—É–ø–ø—ã –∏–∑ Dashboard", "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã"])
        if source_mode == "–ì—Ä—É–ø–ø—ã –∏–∑ Dashboard":
            if not st.session_state["groups"]:
                st.info("–ù–µ—Ç –≥—Ä—É–ø–ø –¥–∞–Ω–Ω—ã—Ö. –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ Dashboard.")
                st.stop()
            group_names = [g["name"] for g in st.session_state["groups"]]
        else:
            up = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)", type=["csv"], accept_multiple_files=True, key="ts_upload")
            if not up:
                st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
                st.stop()
            # –≤—Ä–µ–º–µ–Ω–Ω–∞—è –≥—Ä—É–ø–ø–∞ ¬´Uploaded¬ª
            temp_group = {"name":"Uploaded", "files":[load_uploaded_file(u) for u in up if load_uploaded_file(u)["df"] is not None]}
            st.session_state["__temp_ts_group"] = [temp_group]
            group_names = ["Uploaded"]

        mode = st.radio("–†–µ–∂–∏–º", ["–ú–µ—Ç—Ä–∏–∫–∏ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã", "–û–¥–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –≥—Ä—É–ø–ø–∞–º"], horizontal=True)

        freq_map = {"–ú–µ—Å—è—Ü":"M", "–ù–µ–¥–µ–ª—è":"W", "–ö–≤–∞—Ä—Ç–∞–ª":"Q"}
        freq_label = st.selectbox("–ß–∞—Å—Ç–æ—Ç–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏–∏", list(freq_map.keys()), index=0)
        freq = freq_map[freq_label]

        smooth = st.slider("–°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (—Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ), –ø–µ—Ä–∏–æ–¥–æ–≤", 1, 12, 1)
        index100 = st.checkbox("–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫ 100 (–ø–µ—Ä–≤—ã–π –Ω–µ–Ω—É–ª–µ–≤–æ–π –ø–µ—Ä–∏–æ–¥)", value=False)
        avd_minutes = st.checkbox("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å AVD –≤ –º–∏–Ω—É—Ç–∞—Ö", value=False)

        # ----- —Ä–µ–∂–∏–º 1: –º–µ—Ç—Ä–∏–∫–∏ –≤ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø–µ -----
        if mode == "–ú–µ—Ç—Ä–∏–∫–∏ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã":
            gi = st.selectbox("–ì—Ä—É–ø–ø–∞", range(len(group_names)), format_func=lambda i: group_names[i])
            if source_mode == "–ì—Ä—É–ø–ø—ã –∏–∑ Dashboard":
                group = st.session_state["groups"][gi]
            else:
                group = st.session_state["__temp_ts_group"][0]

            ts = timeseries_for_group(group, freq=freq)
            if ts.empty:
                st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Ä—è–¥–∞ (–Ω–µ—Ç –¥–∞—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏).")
                st.stop()

            metrics_all = ["Impressions","Views","CTR","AVD_sec"]
            metrics_show = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏", metrics_all, default=["Impressions","Views","AVD_sec"])

            # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
            df = ts.copy()
            if smooth > 1:
                for c in metrics_all:
                    if c in df.columns:
                        df[c] = df[c].rolling(smooth, min_periods=1).mean()

            # –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ—Ç 100
            if index100:
                for c in metrics_all:
                    if c in df.columns and c in metrics_show:
                        s = df[c].copy()
                        first = s[s > 0].iloc[0] if not s[s > 0].empty else np.nan
                        if not pd.isna(first) and first != 0:
                            df[c] = s / first * 100

            # –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è AVD –≤ –º–∏–Ω—É—Ç—ã (–¥–ª—è –ø–æ–Ω—è—Ç–Ω–æ—Å—Ç–∏)
            if avd_minutes and "AVD_sec" in df.columns and "AVD_sec" in metrics_show and not index100:
                df["AVD_sec"] = df["AVD_sec"] / 60.0

            # —Å—Ç—Ä–æ–∏–º –¥–≤–µ –æ—Å–∏: —Å–ª–µ–≤–∞ –±–æ–ª—å—à–∏–µ –º–µ—Ç—Ä–∏–∫–∏, —Å–ø—Ä–∞–≤–∞ ¬´–ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ/–≤—Ä–µ–º–µ–Ω–Ω—ã–µ¬ª
            left_metrics  = [m for m in metrics_show if m in ["Impressions","Views"]]
            right_metrics = [m for m in metrics_show if m in ["CTR","AVD_sec"]]

            fig = go.Figure()
            for m in left_metrics:
                fig.add_trace(go.Scatter(x=df["Date"], y=df[m], mode="lines+markers", name=m, yaxis="y1"))
            for m in right_metrics:
                fig.add_trace(go.Scatter(x=df["Date"], y=df[m], mode="lines+markers", name=m, yaxis="y2"))

            y2_title = "CTR, %" if ("CTR" in right_metrics and not index100) else ""
            if "AVD_sec" in right_metrics:
                y2_title = (y2_title + (" / " if y2_title else "")) + ("AVD, –º–∏–Ω" if avd_minutes and not index100 else ("AVD, —Å–µ–∫" if not index100 else "AVD (index)"))

            fig.update_layout(
                template="simple_white",
                margin=dict(l=10, r=10, t=10, b=10),
                height=480,
                xaxis=dict(title="–ü–µ—Ä–∏–æ–¥"),
                yaxis=dict(title="–ó–Ω–∞—á–µ–Ω–∏–µ", side="left"),
                yaxis2=dict(title=y2_title or "–ó–Ω–∞—á–µ–Ω–∏–µ", overlaying="y", side="right"),
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            st.plotly_chart(fig, use_container_width=True)

            st.caption("–ü–æ–¥—Å–∫–∞–∑–∫–∞: –≤–∫–ª—é—á–∏—Ç–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏—Ç—å –∏–º–µ–Ω–Ω–æ —Ñ–æ—Ä–º—É —Ç—Ä–µ–Ω–¥–æ–≤; AVD –º–æ–∂–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –≤ –º–∏–Ω—É—Ç—ã.")

        # ----- —Ä–µ–∂–∏–º 2: –æ–¥–Ω–∞ –º–µ—Ç—Ä–∏–∫–∞ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –≥—Ä—É–ø–ø–∞–º -----
        else:
            if source_mode == "–ì—Ä—É–ø–ø—ã –∏–∑ Dashboard":
                multi = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—ã", group_names, default=group_names[: min(3, len(group_names))])
                if not multi:
                    st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É.")
                    st.stop()
                groups = [st.session_state["groups"][group_names.index(n)] for n in multi]
            else:
                groups = [st.session_state["__temp_ts_group"][0]]
                multi = ["Uploaded"]

            metric = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞", ["Impressions","Views","CTR","AVD_sec"], index=1)

            series = []
            for g, name in zip(groups, multi):
                ts = timeseries_for_group(g, freq=freq)
                if ts.empty or metric not in ts.columns:
                    continue
                s = ts[["Date", metric]].copy().rename(columns={metric: name})
                if smooth > 1:
                    s[name] = s[name].rolling(smooth, min_periods=1).mean()
                if index100:
                    first = s[name][s[name] > 0].iloc[0] if not s[name][s[name] > 0].empty else np.nan
                    if not pd.isna(first) and first != 0:
                        s[name] = s[name] / first * 100
                series.append(s)

            if not series:
                st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏.")
                st.stop()

            from functools import reduce
            df = reduce(lambda l,r: pd.merge(l, r, on="Date", how="outer"), series).sort_values("Date")

            # AVD –≤ –º–∏–Ω—É—Ç—ã, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–∏ –Ω–µ –∏–Ω–¥–µ–∫—Å)
            y_title = metric
            if metric == "AVD_sec" and not index100 and avd_minutes:
                df.loc[:, df.columns != "Date"] = df.loc[:, df.columns != "Date"] / 60.0
                y_title = "AVD, –º–∏–Ω"
            elif metric == "AVD_sec" and not index100:
                y_title = "AVD, —Å–µ–∫"
            elif metric == "CTR" and not index100:
                y_title = "CTR, %"
            elif index100:
                y_title = f"{metric} (index=100)"

            fig = go.Figure()
            for c in df.columns:
                if c == "Date":
                    continue
                fig.add_trace(go.Scatter(x=df["Date"], y=df[c], mode="lines+markers", name=c))
            fig.update_layout(template="simple_white", height=480,
                              xaxis_title="–ü–µ—Ä–∏–æ–¥", yaxis_title=y_title,
                              margin=dict(l=10, r=10, t=10, b=10),
                              legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
            st.plotly_chart(fig, use_container_width=True)

            st.caption("–ü–æ–¥—Å–∫–∞–∑–∫–∞: –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫ 100 –ø–æ–º–æ–≥–∞–µ—Ç —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –∫–∞–Ω–∞–ª—ã —Å —Ä–∞–∑–Ω—ã–º –º–∞—Å—à—Ç–∞–±–æ–º.")
