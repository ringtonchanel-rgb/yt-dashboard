# app.py ‚Äî YouTube Analytics Tools + n8n Assistant (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∏ —É–ø—Ä–æ—â–µ–Ω–æ)

import io
import re
import os
import uuid
import hashlib
import base64
import json
import requests
import uuid
import os
import requests
import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

# =========================== UI / NAV ===========================
st.set_page_config(page_title="YouTube Analytics Tools", layout="wide")
USE_EMOJI = True
ICON_DASH  = "üìä " if USE_EMOJI else ""
ICON_GROUP = "üß© " if USE_EMOJI else ""
ICON_BRAND = "üì∫ " if USE_EMOJI else ""

st.sidebar.markdown(
    f"<div style='font-weight:700;font-size:1.05rem;letter-spacing:.1px;'>{ICON_BRAND}YouTube Analytics Tools</div>",
    unsafe_allow_html=True,
)
st.sidebar.divider()

# –í–ê–ñ–ù–û: nav —Å–æ–∑–¥–∞—ë–º –û–î–ò–ù —Ä–∞–∑
nav = st.sidebar.radio(
    "–ù–∞–≤–∏–≥–∞—Ü–∏—è",
    [f"{ICON_DASH}Dashboard", f"{ICON_GROUP}Group Analytics", "ü§ñ Assistant"],
    index=0
)
st.sidebar.divider()

# ===================== HELPERS: columns / parsing =====================
def _norm(s: str) -> str:
    return str(s).strip().lower()

MAP = {
    "publish_time": ["video publish time","publish time","–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ","–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏","publish date"],
    "views": ["views","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã","–ø—Ä–æ—Å–º—Ç–æ—Ä—ã","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã (views)"],
    "impressions": ["impressions","–ø–æ–∫–∞–∑—ã","–ø–æ–∫–∞–∑—ã (impressions)","–ø–æ–∫–∞–∑—ã –∑–Ω–∞—á–∫–æ–≤","–ø–æ–∫–∞–∑—ã –¥–ª—è –∑–Ω–∞—á–∫–æ–≤"],
    "ctr": ["impressions click-through rate","ctr","ctr (%)","ctr for thumbnails (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤",
            "ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ","ctr –≤–∏–¥–µ–æ"],
    "avd": ["average view duration","avg view duration","—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
            "—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–∏–¥–µ–æ","average view duration (hh:mm:ss)"],
    "title": ["title","–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ","video title","–≤–∏–¥–µ–æ","–Ω–∞–∑–≤–∞–Ω–∏–µ"],
}

def find_col(df: pd.DataFrame, names) -> str | None:
    if isinstance(names, str):
        names = [names]
    by_norm = {_norm(c): c for c in df.columns}
    # —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    for n in names:
        nn = _norm(n)
        if nn in by_norm:
            return by_norm[nn]
    # –ø–æ–¥—Å—Ç—Ä–æ–∫–∏
    for n in names:
        nn = _norm(n)
        for c in df.columns:
            if nn in _norm(c):
                return c
    return None

def detect_columns(df: pd.DataFrame):
    return {k: find_col(df, v) for k, v in MAP.items()}

def to_number(x):
    if x is None:
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "" or s.lower() in {"nan", "none"}:
        return np.nan
    s = s.replace(" ", "").replace("\u202f", "").replace("\xa0", "")
    if s.endswith("%"):
        s = s[:-1]
    if "," in s and "." not in s:
        s = s.replace(",", ".")
    try:
        return float(s)
    except Exception:
        return np.nan

def parse_duration_to_seconds(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "":
        return np.nan
    m = re.match(r"^(\d+):(\d{2}):(\d{2})$", s)
    if m:
        h, m_, s_ = map(int, m.groups())
        return h * 3600 + m_ * 60 + s_
    m = re.match(r"^(\d+):(\d{2})$", s)
    if m:
        m_, s_ = map(int, m.groups())
        return m_ * 60 + s_
    try:
        return float(s)
    except Exception:
        return np.nan

def seconds_to_hhmmss(sec):
    if pd.isna(sec):
        return "‚Äî"
    sec = int(round(sec))
    h = sec // 3600
    m = (sec % 3600) // 60
    s = sec % 60
    return f"{h}:{m:02d}:{s:02d}" if h else f"{m}:{s:02d}"

# =========================== FILE LOADER ===========================
def load_uploaded_file(uploaded_file):
    """–°—Ç–∞–±–∏–ª—å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ CSV (–±–∞–π—Ç–æ–≤—ã–π –±—É—Ñ–µ—Ä + –ø—Ä–æ–±–∞ –∫–æ–¥–∏—Ä–æ–≤–æ–∫). –î—É–±–ª–∏–∫–∞—Ç—ã —Ä–∞–∑—Ä–µ—à–µ–Ω—ã."""
    raw = uploaded_file.getvalue() if hasattr(uploaded_file, "getvalue") else uploaded_file.read()
    _ = hashlib.md5(raw).hexdigest()  # –∏–Ω—Ñ–æ-—Ö—ç—à (–¥–ª—è –Ω–∞—Å –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω)

    df = None
    for enc in (None, "utf-8-sig", "cp1251"):
        try:
            df = pd.read_csv(io.BytesIO(raw), encoding=enc) if enc else pd.read_csv(io.BytesIO(raw))
            break
        except Exception:
            df = None

    meta = "‚ùå –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV."
    if df is not None and not df.empty:
        df.columns = [c.strip() for c in df.columns]
        meta = f"‚úÖ {uploaded_file.name}: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫."
    return {"name": uploaded_file.name, "df": df, "meta": meta}

# ============================ STORAGE ============================
if "groups" not in st.session_state:
    st.session_state["groups"] = []   # [{name: str, files: [{name, df, meta}, ...]}]

def concat_groups(indices):
    frames = []
    for i in indices:
        if 0 <= i < len(st.session_state["groups"]):
            for f in st.session_state["groups"][i]["files"]:
                if f["df"] is not None and not f["df"].empty:
                    frames.append(f["df"])
    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()

def kpis_for_group(group):
    total_impr = 0.0
    total_views = 0.0
    ctr_vals = []
    avd_vals = []
    for f in group["files"]:
        df = f["df"]
        if df is None or df.empty:
            continue
        C = detect_columns(df)
        if C["impressions"] and C["impressions"] in df.columns:
            total_impr += pd.to_numeric(df[C["impressions"]].apply(to_number), errors="coerce").fillna(0).sum()
        if C["views"] and C["views"] in df.columns:
            total_views += pd.to_numeric(df[C["views"]].apply(to_number), errors="coerce").fillna(0).sum()
        if C["ctr"] and C["ctr"] in df.columns:
            ctr_vals += list(df[C["ctr"]].apply(to_number).dropna().values)
        if C["avd"] and C["avd"] in df.columns:
            avd_vals += list(df[C["avd"]].apply(parse_duration_to_seconds).dropna().values)
    avg_ctr = float(np.nanmean(ctr_vals)) if ctr_vals else np.nan
    avg_avd = float(np.nanmean(avd_vals)) if avd_vals else np.nan
    return dict(impressions=int(total_impr), views=int(total_views), ctr=avg_ctr, avd_sec=avg_avd)

# ============================ n8n CHAT ============================
def _get_n8n_urls_and_headers():
    """–ë–µ—Ä—ë–º URL –∏–∑ Secrets / ENV –∏ –≥–æ—Ç–æ–≤–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∏."""
    n8n_url = (st.secrets.get("N8N_CHAT_URL") if hasattr(st, "secrets") else None) or os.getenv("N8N_CHAT_URL")
    headers = {"Content-Type": "application/json"}
    token = (st.secrets.get("N8N_TOKEN") if hasattr(st, "secrets") else None) or os.getenv("N8N_TOKEN")
    if token:
        headers["Authorization"] = f"Bearer {token}"
    return n8n_url, headers

def ask_n8n(question: str, history: list[dict] | None = None, user_id: str | None = None) -> dict:
    """POST ‚Üí —Ç–≤–æ–π n8n webhook. –û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç: {'answer': '...'}"""
    n8n_url, headers = _get_n8n_urls_and_headers()
    if not n8n_url:
        return {"answer": "N8N_CHAT_URL –Ω–µ –∑–∞–¥–∞–Ω –≤ Secrets / ENV."}
    payload = {"question": question, "history": history or [], "user_id": user_id or str(uuid.uuid4())}
    try:
        resp = requests.post(n8n_url, json=payload, headers=headers, timeout=60)
        resp.raise_for_status()
        if resp.headers.get("content-type", "").startswith("application/json"):
            return resp.json()
        return {"answer": resp.text}
    except requests.HTTPError as e:
        return {"answer": f"HTTP error: {e} ‚Äî {getattr(e.response, 'text', '')}"}
    except requests.RequestException as e:
        return {"answer": f"Network error: {e}"}
    except Exception as e:
        return {"answer": f"Unexpected error: {e}"}

def render_chat_page():
    st.title("ü§ñ Assistant")
    st.caption("–ß–∞—Ç –∏–¥—ë—Ç —á–µ—Ä–µ–∑ n8n ‚Üí OpenAI.")

    if "chat_msgs" not in st.session_state:
        st.session_state.chat_msgs = []
    if "user_id" not in st.session_state:
        st.session_state.user_id = str(uuid.uuid4())

    # –∏—Å—Ç–æ—Ä–∏—è
    for m in st.session_state.chat_msgs:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # –≤–≤–æ–¥
    user_text = st.chat_input("–ù–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å‚Ä¶")
    if user_text:
        st.session_state.chat_msgs.append({"role": "user", "content": user_text})
        with st.chat_message("user"):
            st.markdown(user_text)

        with st.chat_message("assistant"):
            with st.spinner("–î—É–º–∞—é‚Ä¶"):
                resp = ask_n8n(
                    question=user_text,
                    history=st.session_state.chat_msgs,
                    user_id=st.session_state.user_id,
                )
                answer = resp.get("answer", "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç ü§ñ")
                st.markdown(answer)
        st.session_state.chat_msgs.append({"role": "assistant", "content": answer})

    # –æ—á–∏—Å—Ç–∫–∞
    col_clear, _ = st.columns([1, 8])
    with col_clear:
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –¥–∏–∞–ª–æ–≥"):
            st.session_state.chat_msgs = []
            st.rerun()

# ============================== PAGES ==============================
if nav.endswith("Dashboard"):
    st.header("Dashboard")

    # –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
    with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É –¥–∞–Ω–Ω—ã—Ö", expanded=True):
        group_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)", value=f"Group {len(st.session_state['groups'])+1}")
        files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV", type=["csv"], accept_multiple_files=True, key="add_group_files")
        if st.button("–î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É"):
            if not group_name.strip():
                st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã.")
            elif not files:
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
            else:
                new_files = []
                for uf in files:
                    pack = load_uploaded_file(uf)
                    if pack["df"] is None or pack["df"].empty:
                        continue
                    new_files.append(pack)  # –¥—É–±–ª–∏–∫–∞—Ç—ã —Ä–∞–∑—Ä–µ—à–µ–Ω—ã
                if new_files:
                    st.session_state["groups"].append({"name": group_name.strip(), "files": new_files})
                    st.success(f"–ì—Ä—É–ø–ø–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞. –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(new_files)}.")
                    st.rerun()
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª—ã (–ø—É—Å—Ç—ã–µ/–ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã).")

    if not st.session_state["groups"]:
        st.info("–î–æ–±–∞–≤—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É –≤ —Å–∞–π–¥–±–∞—Ä–µ.")
    else:
        st.markdown("### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø–∞–º–∏")
        for gi, g in enumerate(st.session_state["groups"]):
            with st.expander(f"–ì—Ä—É–ø–ø–∞: {g['name']}", expanded=False):
                new_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ", value=g["name"], key=f"rename_{gi}")
                add_more = st.file_uploader(
                    "–î–æ–±–∞–≤–∏—Ç—å –æ—Ç—á—ë—Ç—ã –≤ —ç—Ç—É –≥—Ä—É–ø–ø—É",
                    type=["csv"], accept_multiple_files=True, key=f"append_files_{gi}"
                )

                if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", key=f"save_group_{gi}"):
                    changed = False
                    if new_name.strip() and new_name.strip() != g["name"]:
                        g["name"] = new_name.strip()
                        changed = True
                    if add_more:
                        added = 0
                        for uf in add_more:
                            pack = load_uploaded_file(uf)
                            if pack["df"] is None or pack["df"].empty:
                                continue
                            g["files"].append(pack)  # –¥—É–±–ª–∏–∫–∞—Ç—ã –º–æ–∂–Ω–æ
                            added += 1
                        if added:
                            st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {added}.")
                            changed = True
                    if changed:
                        st.rerun()
                    else:
                        st.info("–ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç ‚Äî –Ω–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å.")

                st.markdown("**–§–∞–π–ª—ã –≥—Ä—É–ø–ø—ã:**")
                if not g["files"]:
                    st.write("‚Äî –ø–æ–∫–∞ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤.")
                else:
                    for fi, f in enumerate(g["files"]):
                        c1, c2 = st.columns([4,1])
                        with c1:
                            st.write(f["meta"])
                        with c2:
                            if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"del_file_{gi}_{fi}"):
                                g["files"].pop(fi)
                                st.rerun()

                st.divider()
                if st.button("–£–¥–∞–ª–∏—Ç—å –≥—Ä—É–ø–ø—É", key=f"del_group_{gi}"):
                    st.session_state["groups"].pop(gi)
                    st.rerun()

        st.divider()
        st.markdown("### –°–≤–æ–¥–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º")
        kpi_rows = []
        for g in st.session_state["groups"]:
            kp = kpis_for_group(g)
            st.subheader(f"–ì—Ä—É–ø–ø–∞: {g['name']}")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("–ü–æ–∫–∞–∑—ã (—Å—É–º–º–∞)", f"{kp['impressions']:,}".replace(",", " "))
            c2.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã (—Å—É–º–º–∞)", f"{kp['views']:,}".replace(",", " "))
            c3.metric("–°—Ä–µ–¥–Ω–∏–π CTR –ø–æ –≤–∏–¥–µ–æ", "‚Äî" if np.isnan(kp["ctr"]) else f"{kp['ctr']:.2f}%")
            c4.metric("–°—Ä–µ–¥–Ω–∏–π AVD", seconds_to_hhmmss(kp["avd_sec"]))
            kpi_rows.append({
                "–ì—Ä—É–ø–ø–∞": g["name"],
                "–ü–æ–∫–∞–∑—ã": kp["impressions"],
                "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": kp["views"],
                "CTR, % (—Å—Ä–µ–¥–Ω–µ–µ)": None if np.isnan(kp["ctr"]) else round(kp["ctr"], 2),
                "AVD (—Å—Ä.)": seconds_to_hhmmss(kp["avd_sec"]),
            })
            st.divider()

        if kpi_rows:
            st.markdown("### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø")
            comp_df = pd.DataFrame(kpi_rows)
            st.dataframe(comp_df, use_container_width=True, hide_index=True)

elif nav.endswith("Group Analytics"):
    st.header("Group Analytics")
    tool = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞", ["–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (Year Mix)"])

    if tool.startswith("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º"):
        st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (Year Mix)")
        source_mode = st.sidebar.radio("–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö", ["–ì—Ä—É–ø–ø—ã –∏–∑ Dashboard", "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã"])

        # –ò—Å—Ç–æ—á–Ω–∏–∫: –≥—Ä—É–ø–ø—ã
        if source_mode == "–ì—Ä—É–ø–ø—ã –∏–∑ Dashboard":
            if not st.session_state["groups"]:
                st.info("–ù–µ—Ç –≥—Ä—É–ø–ø –¥–∞–Ω–Ω—ã—Ö. –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ Dashboard.")
                st.stop()
            names = [g["name"] for g in st.session_state["groups"]]
            selected = st.sidebar.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—ã", names, default=names[:1])
            if not selected:
                st.info("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É.")
                st.stop()
            idxs = [names.index(n) for n in selected]
            df = concat_groups(idxs)

        # –ò—Å—Ç–æ—á–Ω–∏–∫: –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã (—Å –æ–ø—Ü–∏–µ–π —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –≥—Ä—É–ø–ø—É, –¥—É–±–ª–∏–∫–∞—Ç—ã —Ä–∞–∑—Ä–µ—à–µ–Ω—ã)
        else:
            up_files = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)", type=["csv"], accept_multiple_files=True, key="ga_upload")
            df_list = []
            if up_files:
                for uf in up_files:
                    pack = load_uploaded_file(uf)
                    if pack["df"] is not None and not pack["df"].empty:
                        df_list.append(pack["df"])
            if not df_list:
                st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
                st.stop()
            df = pd.concat(df_list, ignore_index=True)

            if st.sidebar.checkbox("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç–∏ —Ñ–∞–π–ª—ã –≤ –≥—Ä—É–ø–ø—É"):
                mode = st.sidebar.radio("–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å", ["–í —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≥—Ä—É–ø–ø—É", "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é"])
                if mode == "–í —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≥—Ä—É–ø–ø—É":
                    if not st.session_state["groups"]:
                        st.warning("–ù–µ—Ç –≥—Ä—É–ø–ø. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—É—é –Ω–∏–∂–µ.")
                    else:
                        names = [g["name"] for g in st.session_state["groups"]]
                        gi = st.sidebar.selectbox("–ì—Ä—É–ø–ø–∞", list(range(len(names))), format_func=lambda i: names[i])
                        if st.sidebar.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å"):
                            added = 0
                            for uf in up_files:
                                pack = load_uploaded_file(uf)
                                if pack["df"] is None or pack["df"].empty:
                                    continue
                                st.session_state["groups"][gi]["files"].append(pack)
                                added += 1
                            if added:
                                st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {added}.")
                                st.rerun()
                            else:
                                st.info("–ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã (–ø—É—Å—Ç—ã–µ/–ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã).")
                else:
                    new_name = st.sidebar.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≥—Ä—É–ø–ø—ã", value=f"GA Group {len(st.session_state['groups'])+1}")
                    if st.sidebar.button("–°–æ–∑–¥–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å"):
                        new_files = []
                        for uf in up_files:
                            pack = load_uploaded_file(uf)
                            if pack["df"] is None or pack["df"].empty:
                                continue
                            new_files.append(pack)
                        if new_files:
                            st.session_state["groups"].append({"name": new_name.strip() or "New Group", "files": new_files})
                            st.success("–ì—Ä—É–ø–ø–∞ —Å–æ–∑–¥–∞–Ω–∞.")
                            st.rerun()
                        else:
                            st.info("–ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã (–ø—É—Å—Ç—ã–µ/–ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã).")

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫ ¬´–ò–¢–û–ì–û¬ª
        try:
            df = df[~df.apply(lambda r: r.astype(str).str.contains("–∏—Ç–æ–≥", case=False).any(), axis=1)]
        except Exception:
            pass

        C = detect_columns(df)
        pub_col = C["publish_time"]
        views_col = C["views"]
        missing = []
        if not (pub_col and pub_col in df.columns):
            missing.append("–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
        if not (views_col and views_col in df.columns):
            missing.append("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã")
        if missing:
            st.error("–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: " + ", ".join(missing))
            st.stop()

        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        df[pub_col] = pd.to_datetime(df[pub_col], errors="coerce")
        df = df[df[pub_col].notna()].copy()
        df["_views_num"] = pd.to_numeric(df[views_col].apply(to_number), errors="coerce")
        df["_year"] = df[pub_col].dt.year

        # –ê–≥—Ä–µ–≥–∞—Ü–∏–∏
        views_year = (
            df.groupby("_year", as_index=False)["_views_num"].sum()
              .rename(columns={"_year":"–ì–æ–¥","_views_num":"–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤"})
              .sort_values("–ì–æ–¥")
        )
        count_year = (
            df.groupby("_year", as_index=False).size()
              .rename(columns={"_year":"–ì–æ–¥","size":"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ"})
              .sort_values("–ì–æ–¥")
        )

        if views_year.empty or count_year.empty:
            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø–æ –≥–æ–¥–∞–º.")
            st.stop()

        years_list = sorted(views_year["–ì–æ–¥"].dropna().astype(int).unique())
        default_ref = 2024 if 2024 in years_list else int(max(years_list))
        ref_year = st.selectbox("–û–ø–æ—Ä–Ω—ã–π –≥–æ–¥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏", years_list, index=years_list.index(default_ref))

        # –ì—Ä–∞—Ñ–∏–∫–∏
        c1, c2 = st.columns(2)
        fig1 = px.bar(
            views_year, x="–ì–æ–¥", y="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤",
            text="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤", template="simple_white"
        )
        fig1.update_traces(marker_color="#4e79a7", texttemplate="%{text:,}", textposition="outside")
        fig1.update_layout(
            title="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø–æ –≥–æ–¥–∞–º",
            xaxis_title="–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", yaxis_title="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤",
            showlegend=False, margin=dict(l=10, r=10, t=50, b=10), height=430
        )
        fig1.update_xaxes(type="category", categoryorder="category ascending")
        c1.plotly_chart(fig1, use_container_width=True)

        fig2 = px.bar(
            count_year, x="–ì–æ–¥", y="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ", text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ", template="simple_white"
        )
        fig2.update_traces(marker_color="#4e79a7", texttemplate="%{text}", textposition="outside")
        fig2.update_layout(
            title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ –ø–æ –≥–æ–¥–∞–º",
            xaxis_title="–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", yaxis_title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ",
            showlegend=False, margin=dict(l=10, r=10, t=50, b=10), height=430
        )
        fig2.update_xaxes(type="category", categoryorder="category ascending")
        c2.plotly_chart(fig2, use_container_width=True)

        # –ê–≤—Ç–æ—Ç–µ–∫—Å—Ç
        st.markdown("### üß† –ê–≤—Ç–æ–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π")
        vy = dict(zip(views_year["–ì–æ–¥"], views_year["–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤"]))
        cy = dict(zip(count_year["–ì–æ–¥"], count_year["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ"]))
        ranking = sorted(vy.items(), key=lambda x: x[1], reverse=True)
        ranking_years = [str(int(y)) for y, _ in ranking[:5]]
        older_sum = sum(v for y, v in vy.items() if y < ref_year)
        ref_sum = vy.get(ref_year, np.nan)
        prev_year = ref_year - 1 if (ref_year - 1) in vy else None
        views_ref = vy.get(ref_year, np.nan)
        views_prev = vy.get(prev_year, np.nan) if prev_year else np.nan
        cnt_ref = cy.get(ref_year, np.nan)
        cnt_prev = cy.get(prev_year, np.nan) if prev_year else np.nan

        def close_enough(a, b, tol=0.12):
            if pd.isna(a) or pd.isna(b):
                return False
            return abs(a - b) / max(abs(b), 1e-9) <= tol

        parts = [f"–û–ø–æ—Ä–Ω–∞—è —Ç–æ—á–∫–∞ ‚Äî **{ref_year}**."]
        if ranking_years:
            parts.append("–õ–∏–¥–∏—Ä—É—é—Ç –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º: **" + " ‚Üí ".join(ranking_years) + "**.")
        if not pd.isna(ref_sum) and older_sum > ref_sum:
            total_pair = older_sum + ref_sum
            share_old = f" (‚âà{older_sum/total_pair*100:.0f}% –æ—Ç ¬´—Å—Ç–∞—Ä—ã–π+{ref_year}¬ª)" if total_pair > 0 else ""
            parts.append(f"**–°—Ç–∞—Ä—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç** (–¥–æ {ref_year}) —Å–æ–±—Ä–∞–ª –±–æ–ª—å—à–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, —á–µ–º {ref_year}-–π –≥–æ–¥{share_old}.")
        frame = [y for y in [2022, 2023, 2024] if y in vy]
        if len(frame) >= 2:
            vals = [vy[y] for y in frame]
            mx = max(vals); mn = min(vals)
            if mx > 0 and (mx - mn) / mx <= 0.15:
                parts.append("–í **2022‚Äì2024** —Å—É–º–º–∞—Ä–Ω—ã–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –¥–µ—Ä–∂–∞–ª–∏—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ (¬±15%).")
        if prev_year and not any(pd.isna(x) for x in [views_ref, views_prev, cnt_ref, cnt_prev]):
            if close_enough(views_ref, views_prev, 0.12) and cnt_ref > cnt_prev:
                times = cnt_ref / max(cnt_prev, 1)
                parts.append(
                    f"–ü—Ä–∏ –±–ª–∏–∑–∫–∏—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–∞—Ö —É {prev_year} –∏ {ref_year} –≤ {ref_year}-–º –ø–æ–Ω–∞–¥–æ–±–∏–ª–æ—Å—å –±–æ–ª—å—à–µ –≤–∏–¥–µ–æ (‚âà√ó{times:.1f})."
                )
        for s in parts:
            st.markdown("‚Ä¢ " + s)

elif nav == "ü§ñ Assistant":
    render_chat_page()

# --------------------------- ü§ñ ASSISTANT (n8n chat) ---------------------------
elif nav == "ü§ñ Assistant":
    st.title("ü§ñ Assistant")
    st.caption("–ß–∞—Ç –∏–¥—ë—Ç —á–µ—Ä–µ–∑ n8n ‚Üí OpenAI.")

    # ---------- helpers ----------
    def _get_n8n_urls_and_headers():
        url = (st.secrets.get("N8N_CHAT_URL") if hasattr(st, "secrets") else None) or os.getenv("N8N_CHAT_URL")
        if not url:
            st.error("–ù–µ –∑–∞–¥–∞–Ω N8N_CHAT_URL –≤ Secrets / ENV.")
            st.stop()
        headers = {"Content-Type": "application/json"}
        token = (st.secrets.get("N8N_TOKEN") if hasattr(st, "secrets") else None) or os.getenv("N8N_TOKEN")
        if token:
            headers["Authorization"] = f"Bearer {token}"
        return url, headers

    def _text_from_answer(resp):
        """–ë–µ—Ä—ë–º —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ n8n."""
        ans = resp.get("answer", resp) if isinstance(resp, dict) else resp
        if isinstance(ans, dict):
            return ans.get("content") or ans.get("text") or json.dumps(ans, ensure_ascii=False)
        if isinstance(ans, str) and ans.strip().startswith("{"):
            try:
                j = json.loads(ans)
                if isinstance(j, dict):
                    return j.get("content") or j.get("text") or ans
            except Exception:
                pass
        return str(ans)

    def _files_payload(files):
        items = []
        if not files:
            return items
        for f in files:
            raw = f.getvalue() if hasattr(f, "getvalue") else f.read()
            if len(raw) > 8 * 1024 * 1024:  # –ª–∏–º–∏—Ç 8MB –Ω–∞ —Ñ–∞–π–ª
                st.warning(f"–§–∞–π–ª {f.name}: —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (>8MB) ‚Äî –ø—Ä–æ–ø—É—â–µ–Ω.")
                continue
            items.append({
                "filename": f.name,
                "mimetype": f.type or "text/csv",
                "content_b64": base64.b64encode(raw).decode("utf-8"),
            })
        return items

    def ask_n8n(question, history=None, user_id=None, files=None):
        url, headers = _get_n8n_urls_and_headers()
        payload = {
            "question": question,
            "history": history or [],
            "user_id": user_id or str(uuid.uuid4()),
            "files": files or [],
        }
        try:
            r = requests.post(url, json=payload, headers=headers, timeout=60)
            ct = r.headers.get("content-type", "")
            if not (200 <= r.status_code < 300):
                return {"answer": f"HTTP {r.status_code}. –¢–µ–ª–æ: {r.text[:500]}"}
            if ct.startswith("application/json"):
                try:
                    return r.json()
                except Exception as e:
                    return {"answer": f"–û—à–∏–±–∫–∞ JSON: {e}. –¢–µ–ª–æ: {r.text[:500]}"}
            return {"answer": r.text}
        except requests.RequestException as e:
            return {"answer": f"Network error: {e}"}
        except Exception as e:
            return {"answer": f"Unexpected error: {e}"}

    # ---------- session ----------
    if "chat_msgs" not in st.session_state:
        st.session_state.chat_msgs = []
    if "user_id" not in st.session_state:
        st.session_state.user_id = str(uuid.uuid4())

    # ---------- –∏—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ ----------
    for m in st.session_state.chat_msgs:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # ---------- uploader (–ø–æ –∂–µ–ª–∞–Ω–∏—é) ----------
    with st.expander("üìé –ü—Ä–∏–∫—Ä–µ–ø–∏—Ç—å –æ—Ç—á—ë—Ç (CSV)", expanded=False):
        up_files = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV",
            type=["csv"], accept_multiple_files=True, key="chat_csvs"
        )
        send_files_now = st.button("–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Ñ–∞–π–ª—ã –≤ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç")

    # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤ (–±–µ–∑ —Ç–µ–∫—Å—Ç–∞)
    if send_files_now and up_files:
        files_payload = _files_payload(up_files)
        with st.chat_message("assistant"):
            with st.spinner("–ü–µ—Ä–µ–¥–∞—é —Ñ–∞–π–ª—ã –≤ n8n‚Ä¶"):
                resp = ask_n8n(
                    question="FILES_ONLY",
                    history=st.session_state.chat_msgs,
                    user_id=st.session_state.user_id,
                    files=files_payload,
                )
                answer_text = _text_from_answer(resp)
                st.markdown(answer_text)
        st.session_state.chat_msgs.append({"role": "assistant", "content": answer_text})

    # ---------- –ø–æ–ª–µ –≤–≤–æ–¥–∞ ----------
    user_text = st.chat_input("–ù–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å‚Ä¶")
    if user_text:
        # –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        st.session_state.chat_msgs.append({"role": "user", "content": user_text})
        with st.chat_message("user"):
            st.markdown(user_text)

        # –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (—Ç–µ–∫—Å—Ç + –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã)
        files_payload = _files_payload(up_files) if up_files else []
        with st.chat_message("assistant"):
            with st.spinner("–î—É–º–∞—é‚Ä¶"):
                resp = ask_n8n(
                    question=user_text,
                    history=st.session_state.chat_msgs,
                    user_id=st.session_state.user_id,
                    files=files_payload,
                )
                answer_text = _text_from_answer(resp)
                st.markdown(answer_text)
        st.session_state.chat_msgs.append({"role": "assistant", "content": answer_text})

    # ---------- –æ—á–∏—Å—Ç–∫–∞ ----------
    col_clear, _ = st.columns([1, 8])
    with col_clear:
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –¥–∏–∞–ª–æ–≥"):
            st.session_state.chat_msgs = []
            st.rerun()
