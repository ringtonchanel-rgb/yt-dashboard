import streamlit as st
import pandas as pd
import numpy as np
import io, re
import plotly.express as px

st.set_page_config(page_title="YouTube Channelytics", layout="wide")

# ============================
# –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø STATE
# ============================
if "groups" not in st.session_state or not isinstance(st.session_state.get("groups"), dict):
    st.session_state["groups"] = {}          # –∏–º—è_–≥—Ä—É–ø–ø—ã -> {"df": DataFrame, "allow_dups": bool}

def reset_state():
    st.session_state["groups"] = {}
    st.success("–°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–±—Ä–æ—à–µ–Ω–æ.")

# ============================
# –£—Ç–∏–ª–∏—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–ª–æ–Ω–æ–∫
# ============================
def _norm(s: str) -> str:
    return str(s).strip().lower()

COLMAP = {
    "publish_time": [
        "video publish time","publish time","publish date","upload date",
        "–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ","–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏","–¥–∞—Ç–∞"
    ],
    "title": ["title","video title","–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ","–Ω–∞–∑–≤–∞–Ω–∏–µ","content","–∫–æ–Ω—Ç–µ–Ω—Ç"],
    "video_id": ["video id","id","–∫–æ–Ω—Ç–µ–Ω—Ç","–∏–¥ –≤–∏–¥–µ–æ","–∏–¥"],
    "video_link": ["youtube link","link","—Å—Å—ã–ª–∫–∞","url"],
    "views": ["views","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã","–ø—Ä–æ—Å–º—Ç–æ—Ä—ã"],
    "impressions": ["impressions","–ø–æ–∫–∞–∑—ã","–ø–æ–∫–∞–∑—ã –¥–ª—è –∑–Ω–∞—á–∫–æ–≤"],
    "ctr": ["impressions click-through rate","ctr","ctr (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤","ctr –≤–∏–¥–µ–æ"],
    "watch_hours": ["watch time (hours)","watch time hours","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (—á–∞—Å—ã)","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (—á–∞—Å–æ–≤)"],
    "watch_minutes":["watch time (minutes)","watch time (mins)","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–º–∏–Ω)","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–º–∏–Ω—É—Ç—ã)"],
}

def find_col(df, names):
    if isinstance(names, str): names=[names]
    pool = {_norm(c): c for c in df.columns}
    # —Ç–æ—á–Ω–æ–µ
    for n in names:
        nn=_norm(n)
        if nn in pool: return pool[nn]
    # —á–∞—Å—Ç–∏—á–Ω–æ–µ
    for n in names:
        nn=_norm(n)
        for c in df.columns:
            if nn in _norm(c): return c
    return None

def detect_columns(df):
    return {k: find_col(df, v) for k,v in COLMAP.items()}

def to_number(x):
    if x is None: return np.nan
    if isinstance(x,(int,float,np.number)): return float(x)
    s = str(x).strip()
    if s=="" or s.lower() in {"nan","none"}: return np.nan
    s = s.replace(" ", "").replace("\u202f","").replace("\xa0","")
    if s.endswith("%"): s = s[:-1]
    if "," in s and "." not in s:
        s = s.replace(",", ".")
    try: return float(s)
    except: return np.nan

def fmt_int(n):
    try:
        n = int(round(float(n)))
        return f"{n:,}".replace(",", " ")
    except:
        return "‚Äî"

def fmt_time_from_hours(hours):
    if pd.isna(hours) or hours<=0: return "‚Äî"
    sec = int(hours*3600)
    m, s = divmod(sec, 60)
    h, m = divmod(m, 60)
    if h>0: return f"{h:d}:{m:02d}:{s:02d}"
    return f"{m:d}:{s:02d}"

def yt_link(row):
    link = row.get("video_link")
    if isinstance(link,str) and link.strip():
        return link.strip()
    vid  = row.get("video_id")
    if isinstance(vid,str) and vid.strip():
        return f"https://www.youtube.com/watch?v={vid.strip()}"
    return None

# ============================
# –ü–∞—Ä—Å–µ—Ä CSV (–º—É–ª—å—Ç–∏—Ñ–∞–π–ª—ã)
# ============================
def parse_many(files, allow_dups=True):
    dfs=[]
    meta=[]
    for uf in files:
        raw = uf.getvalue()
        df=None
        for enc in (None,"utf-8-sig","cp1251"):
            try:
                df = pd.read_csv(io.BytesIO(raw), encoding=enc) if enc else pd.read_csv(io.BytesIO(raw))
                break
            except Exception:
                pass
        if df is None or df.empty:
            meta.append(f"‚ùå {uf.name}: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV")
            continue

        df.columns=[c.strip() for c in df.columns]
        cols = detect_columns(df)

        if not cols["publish_time"]:
            meta.append(f"‚ö†Ô∏è {uf.name}: –Ω–µ—Ç –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞—é.")
            continue

        out = pd.DataFrame()
        out["publish_time"] = pd.to_datetime(df[cols["publish_time"]], errors="coerce")
        out = out.dropna(subset=["publish_time"])

        if cols["title"]: out["title"] = df[cols["title"]].astype(str)
        if cols["video_id"]: out["video_id"] = df[cols["video_id"]].astype(str)
        if cols["video_link"]: out["video_link"] = df[cols["video_link"]].astype(str)

        if cols["views"]: out["views"] = pd.to_numeric(df[cols["views"]].apply(to_number), errors="coerce")
        if cols["impressions"]: out["impressions"] = pd.to_numeric(df[cols["impressions"]].apply(to_number), errors="coerce")
        if cols["ctr"]: out["ctr"] = pd.to_numeric(df[cols["ctr"]].apply(to_number), errors="coerce")
        if cols["watch_hours"]:
            out["watch_hours"] = pd.to_numeric(df[cols["watch_hours"]].apply(to_number), errors="coerce")
        elif cols["watch_minutes"]:
            out["watch_hours"] = pd.to_numeric(df[cols["watch_minutes"]].apply(to_number), errors="coerce")/60.0

        out["pub_year"] = out["publish_time"].dt.year
        out["pub_month"] = out["publish_time"].dt.month
        dfs.append(out)
        meta.append(f"‚úÖ {uf.name}: {out.shape[0]} —Å—Ç—Ä–æ–∫")

    if not dfs:
        return None, meta

    big = pd.concat(dfs, ignore_index=True)
    if not allow_dups and "title" in big:
        before = len(big)
        big = big.drop_duplicates(subset=["title","publish_time"])
        meta.append(f"‚Ü™Ô∏è —É–¥–∞–ª–µ–Ω—ã –¥—É–±–ª–∏–∫–∞—Ç—ã: {before-len(big)}")
    return big, meta

# ============================
# Sidebar: –Ω–∞–≤–∏–≥–∞—Ü–∏—è + –≥—Ä—É–ø–ø—ã
# ============================
st.sidebar.markdown("### üì∫ YouTube Analytics Tools")
page = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", ["Dashboard","Channel Explorer","Compare Groups","Manage Groups"], index=0)

st.sidebar.markdown("---")
with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –≥—Ä—É–ø–ø—É", expanded=(page=="Manage Groups")):
    with st.form("add_group_form", clear_on_submit=False):
        gname = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)", value="")
        uploaded = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV", type=["csv"], accept_multiple_files=True)
        allow_dups = st.checkbox("–†–∞–∑—Ä–µ—à–∞—Ç—å –¥—É–±–ª–∏ —Å—Ç—Ä–æ–∫", value=False)
        submitted = st.form_submit_button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –≥—Ä—É–ø–ø—É")
    if submitted:
        if not gname.strip():
            st.warning("–î–∞–π—Ç–µ –∏–º—è –≥—Ä—É–ø–ø–µ.")
        elif not uploaded:
            st.warning("–ü—Ä–∏–∫—Ä–µ–ø–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
        else:
            df_parsed, notes = parse_many(uploaded, allow_dups=allow_dups)
            for n in notes: st.write(n)
            if df_parsed is not None and not df_parsed.empty:
                st.session_state["groups"][gname] = {"df": df_parsed, "allow_dups": allow_dups}
                st.success(f"–ì—Ä—É–ø–ø–∞ ¬´{gname}¬ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {df_parsed.shape[0]} —Å—Ç—Ä–æ–∫.")

# –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø
groups = st.session_state.get("groups", {})
group_names = sorted(list(groups.keys()))

if groups:
    st.sidebar.markdown("#### –í–∞—à–∏ –≥—Ä—É–ø–ø—ã:")
    # –ë–ï–ó –ø—Ä—è–º–æ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–º (—Ç–æ–ª—å–∫–æ —Å–ª–æ–≤–∞—Ä—å)
    for k in list(groups.keys()):
        colA, colB = st.sidebar.columns([3,1])
        colA.write(k)
        if colB.button("‚úñ", key=f"del_{k}"):
            groups.pop(k, None)
            st.session_state["groups"] = groups
            st.experimental_rerun()

    if st.sidebar.button("–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã"):
        reset_state()
        st.experimental_rerun()

# ======================
# KPI helpers
# ======================
def kpi_for_df(dff):
    views = dff["views"].sum() if "views" in dff else np.nan
    impr  = dff["impressions"].sum() if "impressions" in dff else np.nan
    ctr   = dff["ctr"].dropna().mean() if "ctr" in dff else np.nan
    wh    = dff["watch_hours"].sum() if "watch_hours" in dff else np.nan
    avd   = np.nan
    if "views" in dff and "watch_hours" in dff:
        safe_views = dff["views"].replace(0,np.nan)
        avd = (dff["watch_hours"]*3600).sum() / safe_views.sum()
    return views, impr, ctr, avd

def monthly_agg(dff, metric):
    if metric not in dff.columns: return pd.DataFrame(columns=["ym","value"])
    agg = (dff.groupby([dff["publish_time"].dt.to_period("M")])[metric]
           .sum()
           .reset_index(name="value"))
    agg["ym"] = agg["publish_time"].astype(str)
    return agg[["ym","value"]]

def by_year_agg(dff, metric):
    if metric not in dff.columns: return pd.DataFrame(columns=["–ì–æ–¥","value"])
    a = dff.groupby("pub_year")[metric].sum().reset_index().rename(columns={"pub_year":"–ì–æ–¥","value":metric})
    return a

# ======================
# DASHBOARD
# ======================
if page=="Dashboard":
    st.title("üìä Dashboard")
    if not group_names:
        st.info("–°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤—å—Ç–µ –≥—Ä—É–ø–ø—É –≤–æ –≤–∫–ª–∞–¥–∫–µ **Manage Groups**.")
        st.stop()

    g = st.selectbox("–ì—Ä—É–ø–ø–∞", group_names, index=0)
    df_g = groups[g]["df"].copy()

    years_sorted = sorted(df_g["pub_year"].dropna().unique())
    y_from, y_to = st.select_slider("–î–∏–∞–ø–∞–∑–æ–Ω –ª–µ—Ç –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", options=years_sorted, value=(years_sorted[0], years_sorted[-1]))
    mask = (df_g["pub_year"]>=y_from) & (df_g["pub_year"]<=y_to)
    df_g = df_g.loc[mask].copy()

    v, imp, ctr, avd = kpi_for_df(df_g)
    c1,c2,c3,c4 = st.columns(4)
    c1.metric("–ü–æ–∫–∞–∑—ã (—Å—É–º–º–∞)", fmt_int(imp))
    c2.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã (—Å—É–º–º–∞)", fmt_int(v))
    c3.metric("–°—Ä–µ–¥–Ω–∏–π CTR", f"{round(ctr,2)}%" if pd.notna(ctr) else "‚Äî")
    c4.metric("–°—Ä–µ–¥–Ω–∏–π AVD", fmt_time_from_hours(avd/3600) if pd.notna(avd) else "‚Äî")

    st.markdown("### –¢—Ä–µ–Ω–¥ –ø–æ –º–µ—Å—è—Ü–∞–º")
    metric = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ç—Ä–µ–Ω–¥–∞", [m for m in ["views","impressions","watch_hours","ctr"] if m in df_g.columns],
                          format_func=lambda x: {"views":"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","impressions":"–ü–æ–∫–∞–∑—ã","watch_hours":"–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞","ctr":"CTR"}[x])
    chart_type = st.radio("–¢–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞", ["line","bar","area"], horizontal=True)
    smooth = st.slider("–°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (rolling, –º–µ—Å—è—Ü–µ–≤)", 1, 6, 1)
    logy = st.checkbox("–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è —à–∫–∞–ª–∞", value=False)

    ma = monthly_agg(df_g, metric)
    if ma.empty:
        st.warning("–≠—Ç–∞ –º–µ—Ç—Ä–∏–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö.")
    else:
        ma["value_smooth"] = ma["value"].rolling(smooth, min_periods=1).mean()
        y_col = "value_smooth" if smooth>1 else "value"
        if chart_type=="line":
            fig = px.line(ma, x="ym", y=y_col, markers=True, template="simple_white")
        elif chart_type=="bar":
            fig = px.bar(ma, x="ym", y=y_col, template="simple_white")
        else:
            fig = px.area(ma, x="ym", y=y_col, template="simple_white")
        fig.update_layout(height=420, xaxis_title="–ú–µ—Å—è—Ü –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", yaxis_title=metric)
        if logy: fig.update_yaxes(type="log")
        st.plotly_chart(fig, use_container_width=True)

    st.markdown("### –¢–æ–ø-–≤–∏–¥–µ–æ")
    kw = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é", value="")
    sort_by = st.selectbox("–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞", [c for c in ["views","impressions","ctr","watch_hours"] if c in df_g.columns],
                           format_func=lambda x: {"views":"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","impressions":"–ü–æ–∫–∞–∑—ã","ctr":"CTR","watch_hours":"–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞"}[x])
    topn = st.slider("–°–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –ø–æ–∫–∞–∑–∞—Ç—å", 5, 50, 15)
    df_top = df_g.copy()
    if kw.strip():
        df_top = df_top[df_top["title"].str.contains(kw, case=False, na=False)]
    df_top = df_top.sort_values(sort_by, ascending=False).head(topn)

    df_view = df_top.copy()
    df_view["YouTube"] = df_view.apply(yt_link, axis=1)
    if "ctr" in df_view: df_view["CTR"] = df_view["ctr"].round(2).astype(str)+"%"
    if "watch_hours" in df_view and "views" in df_view:
        safe_v = df_view["views"].replace(0,np.nan)
        df_view["AVD"] = ((df_view["watch_hours"]*3600)/safe_v).apply(lambda s: fmt_time_from_hours(s/3600))
    cols_show = [c for c in ["title","views","impressions","CTR","AVD","YouTube","publish_time"] if c in df_view.columns]
    st.dataframe(df_view[cols_show].rename(columns={
        "title":"–ù–∞–∑–≤–∞–Ω–∏–µ","views":"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","impressions":"–ü–æ–∫–∞–∑—ã","publish_time":"–ü—É–±–ª–∏–∫–∞—Ü–∏—è"
    }), use_container_width=True)

# ======================
# CHANNEL EXPLORER
# ======================
elif page=="Channel Explorer":
    st.title("üîé Channel Explorer")
    if not group_names:
        st.info("–î–æ–±–∞–≤—å—Ç–µ –≥—Ä—É–ø–ø—É –≤–æ –≤–∫–ª–∞–¥–∫–µ **Manage Groups**.")
        st.stop()
    g = st.selectbox("–ì—Ä—É–ø–ø–∞", group_names, index=0)
    df_g = groups[g]["df"].copy()

    metric = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞", [m for m in ["views","impressions","watch_hours","ctr"] if m in df_g.columns],
                          format_func=lambda x: {"views":"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","impressions":"–ü–æ–∫–∞–∑—ã","watch_hours":"–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞","ctr":"CTR"}[x])
    years_sorted = sorted(df_g["pub_year"].dropna().unique())
    y_from, y_to = st.select_slider("–ì–æ–¥–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", options=years_sorted, value=(years_sorted[0], years_sorted[-1]))
    mask = (df_g["pub_year"]>=y_from) & (df_g["pub_year"]<=y_to)
    df_g = df_g.loc[mask].copy()

    st.subheader("–ü–æ –≥–æ–¥–∞–º –≤—ã–ø—É—Å–∫–∞")
    byyear = by_year_agg(df_g, metric)
    if byyear.empty:
        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —ç—Ç–æ–π –º–µ—Ç—Ä–∏–∫–∏.")
    else:
        fig = px.bar(byyear.rename(columns={metric:"value"}), x="–ì–æ–¥", y="value", template="simple_white",
                     color_discrete_sequence=["#4e79a7"])
        fig.update_layout(height=420, yaxis_title=metric)
        st.plotly_chart(fig, use_container_width=True)

# ======================
# COMPARE GROUPS
# ======================
elif page=="Compare Groups":
    st.title("üÜö Compare Groups")
    if len(group_names)<2:
        st.info("–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º –¥–≤–µ –≥—Ä—É–ø–ø—ã.")
        st.stop()
    selected = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—ã", group_names, default=group_names[:2])
    if not selected: st.stop()

    records=[]
    for g in selected:
        d = groups[g]["df"]
        v, imp, ctr, avd = kpi_for_df(d)
        records.append({
            "–ì—Ä—É–ø–ø–∞": g,
            "–ü–æ–∫–∞–∑—ã": imp,
            "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": v,
            "CTR (—Å—Ä.)": ctr,
            "AVD (—Å—Ä.)": avd
        })
    table = pd.DataFrame(records)
    if "CTR (—Å—Ä.)" in table: table["CTR (—Å—Ä.)"] = table["CTR (—Å—Ä.)"].apply(lambda x: f"{round(x,2)}%" if pd.notna(x) else "‚Äî")
    if "AVD (—Å—Ä.)" in table: table["AVD (—Å—Ä.)"] = table["AVD (—Å—Ä.)"].apply(lambda s: fmt_time_from_hours(s/3600) if pd.notna(s) else "‚Äî")
    if "–ü–æ–∫–∞–∑—ã" in table: table["–ü–æ–∫–∞–∑—ã"] = table["–ü–æ–∫–∞–∑—ã"].apply(fmt_int)
    if "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã" in table: table["–ü—Ä–æ—Å–º–æ—Ç—Ä—ã"] = table["–ü—Ä–æ—Å–º–æ—Ç—Ä—ã"].apply(fmt_int)
    st.dataframe(table, use_container_width=True)

# ======================
# MANAGE GROUPS
# ======================
elif page=="Manage Groups":
    st.title("üß∞ Manage Groups")
    st.button("–°–±—Ä–æ—Å–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–æ—á–∏—Å—Ç–∏—Ç—å –≤—Å—ë)", on_click=reset_state, type="secondary")
    if not group_names:
        st.info("–ü–æ–∫–∞ –Ω–µ—Ç –≥—Ä—É–ø–ø. –î–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ —Å–∞–π–¥–±–∞—Ä–µ (–≤–≤–µ—Ä—Ö—É).")
    else:
        for g in group_names:
            with st.expander(f"–ì—Ä—É–ø–ø–∞: {g}", expanded=False):
                df_g = groups[g]["df"]
                allow_dups = groups[g]["allow_dups"]
                st.write(f"–°—Ç—Ä–æ–∫: **{len(df_g)}**, –∫–æ–ª–æ–Ω–æ–∫: **{df_g.shape[1]}**, –¥—É–±–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã: **{allow_dups}**")
                st.dataframe(df_g.head(20), use_container_width=True)
