# app.py ‚Äî YouTube Analytics Tools (stable UI)
# Features:
# - –ì—Ä—É–ø–ø—ã –∫–∞–Ω–∞–ª–æ–≤ -> –≤–Ω—É—Ç—Ä–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV-–æ—Ç—á—ë—Ç–æ–≤ (–ù–ï —Å—É–º–º–∏—Ä—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é)
# - –û—Ç–¥–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV —Å –¥–æ—Ö–æ–¥–∞–º–∏ (–ø—Ä–∏–≤—è–∑–∫–∞ –ø–æ video_id –∏–ª–∏ –ø–æ –¥–∞—Ç–µ)
# - –§–∏–ª—å—Ç—Ä –≤–µ—Ä—Ç–∏–∫–∞–ª/–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª (Shorts/Format/<=60s)
# - –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ groups[] (—É—Å—Ç—Ä–∞–Ω—è–µ—Ç TypeError –ø—Ä–∏ pack["df"])
# - –ê–∫–∫—É—Ä–∞—Ç–Ω—ã–π UI (CSS skin + –∫–∞—Ä—Ç–æ—á–∫–∏ –º–µ—Ç—Ä–∏–∫)
# - –°—Ç—Ä–∞–Ω–∏—Ü—ã: Dashboard / Channel Explorer / Compare Groups / Manage Groups

import io
import re
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st

# -------------------------------------------------
#                BASE UI / THEME
# -------------------------------------------------
st.set_page_config(page_title="YouTube Analytics Tools", layout="wide")

# –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è ¬´—à–∫—É—Ä–∫–∞¬ª + –∫–∞—Ä—Ç–æ—á–∫–∏ –º–µ—Ç—Ä–∏–∫ + —Ñ–∏–∫—Å —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
st.markdown("""
<style>
/* –æ–±—â–∏–π —Ä–∏—Ç–º */
.block-container { padding-top: 0.8rem; padding-bottom: 2rem; }

/* —Ñ–∏–∫—Å –º–µ–ª–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —É —Ä–∞–¥–∏–æ/–∫–Ω–æ–ø–æ–∫ –Ω–∞ 100% –º–∞—Å—à—Ç–∞–±–µ */
[data-testid="stRadio"] label, .sidebar-content label { font-size: 0.95rem !important; }

/* –∫–∞—Ä—Ç–æ—á–∫–∏ –º–µ—Ç—Ä–∏–∫ */
.metric-card {
  border: 1px solid #e7e7e9; border-radius: 12px; padding: 14px 16px;
  background: #fff; box-shadow: 0 1px 2px rgba(0,0,0,0.03);
}
.metric-title { color:#6b7280; font-size: 0.85rem; margin-bottom:6px; }
.metric-value { font-weight: 800; font-size: 1.35rem; line-height:1.2; }
.metric-sub   { color:#9ca3af; font-size: 0.8rem; }

/* —Å–µ–∫—Ü–∏–∏ */
.section { padding: 6px 0 10px 0; }
.section h3 { margin: 6px 0 12px 0; }

/* —Ç–∞–±–ª–∏—Ü–∞–º —á—É—Ç—å –±–æ–ª—å—à–µ –≤–æ–∑–¥—É—Ö–∞ */
[data-testid="stDataFrame"] { border-radius: 10px; }
</style>
""", unsafe_allow_html=True)

def render_metric_card(title: str, value: str, sub: str = ""):
    st.markdown(
        f"""
        <div class="metric-card">
          <div class="metric-title">{title}</div>
          <div class="metric-value">{value}</div>
          <div class="metric-sub">{sub}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

# -------------------------------------------------
#                  HELPERS
# -------------------------------------------------
def _num(x):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ float (–ø–æ–¥–¥–µ—Ä–∂–∫–∞ '1 234,5' –∏ '%')."""
    if pd.isna(x): return np.nan
    try:
        if isinstance(x, str):
            s = x.strip().replace("\u202f","").replace("\xa0","").replace(" ","")
            if s.endswith("%"): s = s[:-1]
            if "," in s and "." not in s: s = s.replace(",", ".")
            return float(s)
        return float(x)
    except Exception:
        return np.nan

def parse_duration_to_seconds(val) -> Optional[int]:
    """–ü–æ–¥–¥–µ—Ä–∂–∫–∞ 'MM:SS', 'H:MM:SS', '12m 3s', '605' (—Å–µ–∫)."""
    if pd.isna(val): return None
    s = str(val).strip()
    if s.isdigit(): return int(s)
    m = re.match(r'(?:(\d+)\s*h)?\s*(?:(\d+)\s*m)?\s*(?:(\d+)\s*s)?', s, re.I)
    if m and any(m.groups()):
        h = int(m.group(1)) if m.group(1) else 0
        mm = int(m.group(2)) if m.group(2) else 0
        ss = int(m.group(3)) if m.group(3) else 0
        return h*3600 + mm*60 + ss
    parts = s.split(":")
    try:
        if len(parts) == 3:
            h, mm, ss = map(int, parts); return h*3600 + mm*60 + ss
        if len(parts) == 2:
            mm, ss = map(int, parts);    return mm*60 + ss
    except Exception:
        pass
    return None

def seconds_to_hms(x: float) -> str:
    if pd.isna(x): return "‚Äî"
    x = int(round(x))
    h = x // 3600; m = (x % 3600) // 60; s = x % 60
    return f"{h}:{m:02d}:{s:02d}" if h else f"{m}:{s:02d}"

def human_int(x: float) -> str:
    if pd.isna(x): return "‚Äî"
    x = float(x)
    for unit in ["", "K", "M", "B", "T"]:
        if abs(x) < 1000:
            return f"{x:,.0f}{unit}".replace(",", " ")
        x /= 1000.0
    return f"{x:.1f}P"

def detect_delimiter(buf: bytes) -> str:
    head = buf[:4000].decode("utf-8", errors="ignore")
    return ";" if head.count(";") > head.count(",") else ","

# —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∏–º—ë–Ω
COLUMN_ALIASES: Dict[str, str] = {
    # id
    "video id":"video_id","–∏–¥ –≤–∏–¥–µ–æ":"video_id","id –≤–∏–¥–µ–æ":"video_id","content id":"video_id",
    # title
    "title":"title","video title":"title","–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ":"title","–Ω–∞–∑–≤–∞–Ω–∏–µ":"title","content":"title","–∫–æ–Ω—Ç–µ–Ω—Ç":"title",
    # publish time / daily
    "video publish time":"publish_time","publish time":"publish_time","publish date":"publish_time",
    "upload date":"publish_time","–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ":"publish_time","–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏":"publish_time","–¥–∞—Ç–∞":"publish_time",
    "date":"date","day":"date","report date":"date","–¥–∞—Ç–∞ –æ—Ç—á–µ—Ç–∞":"date",
    # metrics
    "views":"views","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã":"views",
    "impressions":"impressions","–ø–æ–∫–∞–∑—ã":"impressions","–ø–æ–∫–∞–∑—ã –¥–ª—è –∑–Ω–∞—á–∫–æ–≤":"impressions",
    "impressions click-through rate":"ctr","ctr":"ctr","ctr (%)":"ctr","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤":"ctr","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ (%)":"ctr",
    "watch time (hours)":"watch_hours","watch time hours":"watch_hours","—á–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞":"watch_hours","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (—á–∞—Å—ã)":"watch_hours",
    "watch time (minutes)":"watch_minutes","–≤—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–º–∏–Ω)":"watch_minutes",
    "average view duration":"avd","avg view duration":"avd","—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞":"avd",
    "estimated revenue":"revenue","estimated partner revenue":"revenue","–¥–æ—Ö–æ–¥":"revenue",
    # duration / format
    "duration":"duration","–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å":"duration",
    "format":"format","—Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞":"format",
    "shorts":"shorts","is shorts":"shorts"
}

def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    return df.rename(columns={c: COLUMN_ALIASES.get(str(c).strip().lower(), c) for c in df.columns})

def read_csv_smart(file) -> pd.DataFrame:
    raw = file.read()
    delim = detect_delimiter(raw)
    df = pd.read_csv(io.BytesIO(raw), sep=delim, encoding="utf-8", engine="python")
    df = standardize_columns(df)

    # —á–∏—Å–ª–æ–≤—ã–µ
    for col in ["views","impressions","watch_hours","watch_minutes","ctr","revenue"]:
        if col in df.columns: df[col] = df[col].map(_num)

    # CTR: –µ—Å–ª–∏ –≤—Å–µ <=1, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ —ç—Ç–æ –¥–æ–ª—è -> –≤ %
    if "ctr" in df.columns and df["ctr"].dropna().max() <= 1.0:
        df["ctr"] = df["ctr"] * 100.0

    # –≤—Ä–µ–º—è
    if "publish_time" in df.columns:
        df["publish_time"] = pd.to_datetime(df["publish_time"], errors="coerce")
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

    # AVD (—Å–µ–∫) ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    if "avd" in df.columns and "avd_sec" not in df.columns:
        df["avd_sec"] = df["avd"].apply(parse_duration_to_seconds)
    # duration_sec
    if "duration" in df.columns:
        df["duration_sec"] = df["duration"].apply(parse_duration_to_seconds)
    elif "duration_sec" not in df.columns:
        df["duration_sec"] = np.nan

    # format detect
    if "format" not in df.columns:
        df["format"] = np.nan
    if "shorts" in df.columns:
        df.loc[df["shorts"].astype(str).str.lower().isin(["1","true","–¥–∞","yes"]), "format"] = "vertical"
    # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    df.loc[df["format"].isna() & (df["duration_sec"] <= 60), "format"] = "vertical"
    df["format"] = df["format"].fillna("horizontal")

    # watch_minutes -> watch_hours
    if "watch_minutes" in df.columns and "watch_hours" not in df.columns:
        df["watch_hours"] = df["watch_minutes"] / 60.0

    # id
    if "video_id" in df.columns:
        df["video_id"] = df["video_id"].astype(str).str.strip()

    return df

# –¥–æ—Ö–æ–¥—ã
def attach_revenue(base_df: pd.DataFrame, revenue_packs: Optional[List[Dict]]) -> pd.DataFrame:
    """–ü–æ–¥–º–µ—à–∞—Ç—å –¥–æ—Ö–æ–¥ –∏–∑ revenue CSV (–ø–æ video_id –∏–ª–∏ –ø–æ date). –ë–µ–∑–æ–ø–∞—Å–Ω–æ –∫ –ª—é–±—ã–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∞–º."""
    if not revenue_packs: return base_df
    df = base_df.copy()
    df["revenue_ext"] = np.nan

    for pack in revenue_packs:
        r = pack.get("df") if isinstance(pack, dict) else None
        if r is None or not isinstance(r, pd.DataFrame): continue

        cols = [c.lower() for c in r.columns]
        # –≤–∞—Ä–∏–∞–Ω—Ç 1: video_id, revenue
        if "video_id" in cols and "revenue" in cols:
            r2 = r.rename(columns={r.columns[cols.index("video_id")]: "video_id",
                                   r.columns[cols.index("revenue")]: "revenue"}).copy()
            r2["video_id"] = r2["video_id"].astype(str).str.strip()
            r2["revenue"] = r2["revenue"].map(_num)
            df = df.merge(r2[["video_id","revenue"]], on="video_id", how="left", suffixes=("", "_ext"))
            df["revenue_ext"] = df["revenue_ext"].fillna(df["revenue_ext"])
        # –≤–∞—Ä–∏–∞–Ω—Ç 2: date, revenue ‚Äî —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º –≥—Ä—É–±–æ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        elif "date" in cols and "revenue" in cols:
            r2 = r.rename(columns={r.columns[cols.index("date")]: "date",
                                   r.columns[cols.index("revenue")]: "revenue"}).copy()
            r2["date"] = pd.to_datetime(r2["date"], errors="coerce")
            daily = r2.groupby("date", as_index=False)["revenue"].sum()
            if "publish_time" in df.columns:
                df["pub_date"] = df["publish_time"].dt.floor("D")
                df = df.merge(daily, left_on="pub_date", right_on="date", how="left", suffixes=("", "_rday"))
                df["revenue_ext"] = df["revenue_ext"].fillna(df["revenue_rday"])
                df.drop(columns=["date","pub_date","revenue_rday"], inplace=True, errors="ignore")

    # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ –¥–æ—Ö–æ–¥–∞
    if "revenue" in df.columns:
        df["revenue_final"] = df["revenue"].fillna(df["revenue_ext"])
    else:
        df["revenue_final"] = df["revenue_ext"]
    return df

# —Å–≤–æ–¥–∫–∞ –ø–æ –æ–¥–Ω–æ–º—É df (—Å —Ñ–∏–ª—å—Ç—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–∞)
def summarize_one_file(df: pd.DataFrame, only_format: str="all") -> Dict[str, float]:
    d = df.copy()
    if only_format in ("vertical","horizontal"):
        d = d.loc[d["format"] == only_format]
    return {
        "videos": len(d),
        "views": d["views"].sum(skipna=True) if "views" in d.columns else np.nan,
        "impressions": d["impressions"].sum(skipna=True) if "impressions" in d.columns else np.nan,
        "ctr": d["ctr"].mean(skipna=True) if "ctr" in d.columns else np.nan,
        "avd_sec": d["avd_sec"].mean(skipna=True) if "avd_sec" in d.columns else np.nan,
        "watch_hours": d["watch_hours"].sum(skipna=True) if "watch_hours" in d.columns else np.nan,
        "revenue": d["revenue_final"].sum(skipna=True) if "revenue_final" in d.columns else np.nan,
    }

# –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–ª—è –æ–±—â–µ–≥–æ –≥—Ä–∞—Ñ–∏–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
def combine_files(files: List[Dict], only_format: str="all") -> pd.DataFrame:
    if not files: return pd.DataFrame()
    dfs = []
    for p in files:
        df = p["df"].copy()
        if only_format in ("vertical","horizontal"):
            df = df.loc[df["format"] == only_format]
        df["__file__"] = p["name"]
        dfs.append(df)
    return pd.concat(dfs, ignore_index=True)

# –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ groups[group] -> List[{"name":..., "df":...}]
def normalize_packs(packs_raw) -> List[Dict]:
    norm = []
    if not isinstance(packs_raw, list): return norm
    for i, item in enumerate(packs_raw):
        if isinstance(item, dict) and "df" in item and "name" in item and isinstance(item["df"], pd.DataFrame):
            norm.append(item)
        elif isinstance(item, pd.DataFrame):
            norm.append({"name": f"report_{i}.csv", "df": item})
        else:
            continue
    return norm

# -------------------------------------------------
#              SESSION STORAGE
# -------------------------------------------------
if "groups" not in st.session_state or not isinstance(st.session_state.get("groups"), dict):
    st.session_state["groups"] = {}   # { group_name: [ {"name": str, "df": DataFrame}, ... ] }
if "revenues" not in st.session_state or not isinstance(st.session_state.get("revenues"), dict):
    st.session_state["revenues"] = {} # { group_name: [ {"name": str, "df": DataFrame}, ... ] }

# -------------------------------------------------
#                   SIDEBAR
# -------------------------------------------------
st.sidebar.title("üì∫ YouTube Analytics Tools")
page = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", ["Dashboard","Channel Explorer","Compare Groups","Manage Groups"], index=0)

with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –≥—Ä—É–ø–ø—É", expanded=True):
    gname = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)")
    add_files = st.file_uploader("CSV –æ—Ç—á—ë—Ç—ã (1..N)", type=["csv"], accept_multiple_files=True)
    rev_files = st.file_uploader("CSV —Å –¥–æ—Ö–æ–¥–∞–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", type=["csv"], accept_multiple_files=True)
    c1, c2 = st.columns(2)
    with c1:
        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å"):
            if not gname.strip():
                st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã.")
            elif not add_files and not rev_files:
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV (–æ—Ç—á—ë—Ç –∏–ª–∏ –¥–æ—Ö–æ–¥—ã).")
            else:
                st.session_state["groups"].setdefault(gname, [])
                # –æ—Ç—á—ë—Ç—ã
                for f in add_files or []:
                    df = read_csv_smart(f)
                    # –ø–æ–¥–º–µ—à–∞–µ–º –¥–æ—Ö–æ–¥—ã, –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å
                    df = attach_revenue(df, st.session_state["revenues"].get(gname, []))
                    st.session_state["groups"][gname].append({"name": f.name, "df": df})
                # –¥–æ—Ö–æ–¥—ã
                if rev_files:
                    st.session_state["revenues"].setdefault(gname, [])
                    for rf in rev_files:
                        r_df = read_csv_smart(rf)
                        st.session_state["revenues"][gname].append({"name": rf.name, "df": r_df})
                st.success(f"–ì—Ä—É–ø–ø–∞ ¬´{gname}¬ª –æ–±–Ω–æ–≤–ª–µ–Ω–∞.")
    with c2:
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã"):
            st.session_state["groups"] = {}
            st.session_state["revenues"] = {}
            st.experimental_rerun()

# —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø
st.sidebar.markdown("### –í–∞—à–∏ –≥—Ä—É–ø–ø—ã:")
if not st.session_state["groups"]:
    st.sidebar.info("–ü–æ–∫–∞ –Ω–µ—Ç –≥—Ä—É–ø–ø.")
else:
    for name, packs in st.session_state["groups"].items():
        st.sidebar.write(f"‚Ä¢ **{name}** ({len(packs)} –æ—Ç—á.)")

# -------------------------------------------------
#                    PAGES
# -------------------------------------------------
if page == "Dashboard":
    st.title("üìä Dashboard")
    if not st.session_state["groups"]:
        st.info("–î–æ–±–∞–≤—å—Ç–µ –≥—Ä—É–ø–ø—É —Å–ª–µ–≤–∞."); st.stop()

    g = st.selectbox("–ì—Ä—É–ø–ø–∞", list(st.session_state["groups"].keys()))
    files_raw = st.session_state["groups"].get(g, [])
    files = normalize_packs(files_raw)
    rev_packs = st.session_state["revenues"].get(g, [])

    if not files:
        st.warning("–í –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤."); st.stop()

    fmt = st.radio("–§–æ—Ä–º–∞—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞", ["all","horizontal","vertical"], horizontal=True)

    # –ï—â—ë —Ä–∞–∑ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –ø–æ–¥–º–µ—à–∞–µ–º –¥–æ—Ö–æ–¥—ã –∫ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É (–Ω–∞ —Å–ª—É—á–∞–π –Ω–æ–≤—ã—Ö revenue CSV)
    files = [{"name": p["name"], "df": attach_revenue(p["df"], rev_packs)} for p in files]

    # --- –°–≤–æ–¥–∫–∞ –ø–æ –∫–∞–∂–¥–æ–º—É –æ—Ç—á—ë—Ç—É (–°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø, –±–µ–∑ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è) ---
    st.subheader("–°–≤–æ–¥–∫–∞ –ø–æ –æ—Ç—á—ë—Ç–∞–º (—Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è, –±–µ–∑ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è)")
    rows = []
    for p in files:
        s = summarize_one_file(p["df"], only_format=fmt)
        rows.append({
            "–û—Ç—á—ë—Ç": p["name"],
            "–í–∏–¥–µ–æ": s["videos"],
            "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": s["views"],
            "–ü–æ–∫–∞–∑—ã": s["impressions"],
            "CTR, %": s["ctr"],
            "AVD (—Å—Ä.)": seconds_to_hms(s["avd_sec"]),
            "–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": s["watch_hours"],
            "–î–æ—Ö–æ–¥": s["revenue"],
        })
    seg_df = pd.DataFrame(rows)
    # —Å–∫—Ä—ã—Ç—å –¥–æ—Ö–æ–¥, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –Ω–∏ –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ
    if "–î–æ—Ö–æ–¥" in seg_df and seg_df["–î–æ—Ö–æ–¥"].notna().sum() == 0:
        seg_df.drop(columns=["–î–æ—Ö–æ–¥"], inplace=True)

    st.dataframe(
        seg_df.style.format({
            "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã":"{:,.0f}", "–ü–æ–∫–∞–∑—ã":"{:,.0f}", "CTR, %":"{:.2f}", "–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞":"{:,.1f}"
        }).hide(axis="index"),
        use_container_width=True, height=320
    )

    if not seg_df.empty and "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã" in seg_df.columns:
        st.plotly_chart(
            px.bar(seg_df, x="–û—Ç—á—ë—Ç", y="–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", title="–ü—Ä–æ—Å–º–æ—Ç—Ä—ã –ø–æ –æ—Ç—á—ë—Ç–∞–º (—Å —É—á—ë—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞ —Ñ–æ—Ä–º–∞—Ç–∞)",
                   template="simple_white"),
            use_container_width=True
        )

    st.divider()
    # --- –ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—â–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è (–ø–æ –∂–µ–ª–∞–Ω–∏—é) ---
    combine = st.toggle("–ü–æ–∫–∞–∑–∞—Ç—å –æ–±—â–∏–π –æ–±–∑–æ—Ä –ø–æ –í–°–ï–ú –æ—Ç—á—ë—Ç–∞–º (–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–æ, —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)", value=False)
    if combine:
        comb = combine_files(files, only_format=fmt)
        if comb.empty:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—â–µ–≥–æ –æ–±–∑–æ—Ä–∞.")
        else:
            # KPI-–∫–∞—Ä—Ç–æ—á–∫–∏ –ø–æ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º (—Ç–æ–ª—å–∫–æ –≤–∏–∑—É–∞–ª—å–Ω–æ)
            s = summarize_one_file(comb, only_format="all")
            c1,c2,c3,c4 = st.columns(4)
            with c1: render_metric_card("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã (—Å—É–º–º–∞)", human_int(s.get("views", np.nan)))
            with c2: render_metric_card("–ü–æ–∫–∞–∑—ã (—Å—É–º–º–∞)",   human_int(s.get("impressions", np.nan)))
            with c3: render_metric_card("CTR, % (—Å—Ä.)",     f"{s.get('ctr',np.nan):.2f}%" if not pd.isna(s.get('ctr',np.nan)) else "‚Äî")
            with c4: render_metric_card("AVD (—Å—Ä.)",        seconds_to_hms(s.get("avd_sec", np.nan)))

            # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤
            st.plotly_chart(
                px.histogram(comb, x="views", color="__file__", nbins=30,
                             title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (–≤—Å–µ —Ñ–∞–π–ª—ã)", template="simple_white"),
                use_container_width=True
            )
            # —Ç–æ–ø-10 –≤–∏–¥–µ–æ
            if {"title","views"}.issubset(comb.columns):
                top10 = comb.sort_values("views", ascending=False).head(10)[["title","views","__file__"]]
                st.dataframe(top10.rename(columns={"title":"–ù–∞–∑–≤–∞–Ω–∏–µ","views":"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","__file__":"–û—Ç—á—ë—Ç"}),
                             use_container_width=True)

elif page == "Channel Explorer":
    st.title("üîé Channel Explorer")
    if not st.session_state["groups"]:
        st.info("–î–æ–±–∞–≤—å—Ç–µ –≥—Ä—É–ø–ø—É —Å–ª–µ–≤–∞."); st.stop()

    g = st.selectbox("–ì—Ä—É–ø–ø–∞", list(st.session_state["groups"].keys()), key="expl_g")
    files = normalize_packs(st.session_state["groups"].get(g, []))
    rev_packs = st.session_state["revenues"].get(g, [])

    if not files:
        st.warning("–í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤."); st.stop()

    file_names = [p["name"] for p in files]
    fname = st.selectbox("–û—Ç—á—ë—Ç", file_names)
    pack = files[file_names.index(fname)] if file_names else None
    if not (isinstance(pack, dict) and "df" in pack and isinstance(pack["df"], pd.DataFrame)):
        st.error("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á—ë—Ç–∞ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞. –£–¥–∞–ª–∏—Ç–µ –∏ –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –∑–∞–Ω–æ–≤–æ."); st.stop()

    df = attach_revenue(pack["df"], rev_packs)

    fmt = st.radio("–§–æ—Ä–º–∞—Ç", ["all","horizontal","vertical"], horizontal=True, key="expl_fmt")
    if fmt in ("horizontal","vertical"):
        df = df.loc[df["format"] == fmt]
    st.caption(f"–°—Ç—Ä–æ–∫ –≤ –æ—Ç—á—ë—Ç–µ: {len(df)}")

    # –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    metrics = [m for m in ["views","impressions","ctr","watch_hours","revenue_final"] if m in df.columns]
    if not metrics:
        st.warning("–ù–µ –Ω–∞—à—ë–ª –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏."); st.stop()

    m = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞", metrics, index=0)
    chart_type = st.selectbox("–¢–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞", ["Bar","Scatter","Histogram"], index=0)

    xcol = "title" if "title" in df.columns else df.columns[0]
    if chart_type == "Bar":
        fig = px.bar(df.nlargest(30, m), x=xcol, y=m, title=f"Top-30 –ø–æ {m}", template="simple_white")
        fig.update_layout(xaxis_title="", yaxis_title=m)
        st.plotly_chart(fig, use_container_width=True)
    elif chart_type == "Scatter":
        ycand = [i for i in ["impressions","ctr","watch_hours","revenue_final"] if i in df.columns and i != m]
        yaxis = st.selectbox("–û—Å—å Y", ycand) if ycand else m
        st.plotly_chart(px.scatter(df, x=m, y=yaxis, hover_data=[xcol], title=f"{m} vs {yaxis}", template="simple_white"),
                        use_container_width=True)
    else:
        st.plotly_chart(px.histogram(df, x=m, nbins=40, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {m}", template="simple_white"),
                        use_container_width=True)

    st.divider()
    # —Ç–∞–±–ª–∏—Ü–∞ (—Å –∫–ª–∏–∫–∞–±–µ–ª—å–Ω–æ–π —Å—Å—ã–ª–∫–æ–π, –µ—Å–ª–∏ –µ—Å—Ç—å video_id/link)
    def yt_link(row):
        link = row.get("video_link") if "video_link" in row else None
        if isinstance(link, str) and link.strip(): return link.strip()
        vid = row.get("video_id") if "video_id" in row else None
        if isinstance(vid, str) and vid.strip():  return f"https://www.youtube.com/watch?v={vid.strip()}"
        return None

    view = df.copy()
    if "ctr" in view: view["CTR, %"] = view["ctr"].round(2)
    if "revenue_final" in view: view["–î–æ—Ö–æ–¥"] = view["revenue_final"]
    if {"watch_hours","views"}.issubset(view.columns):
        safe_v = view["views"].replace(0,np.nan)
        view["AVD"] = ((view["watch_hours"]*3600)/safe_v).apply(lambda s: seconds_to_hms(s) if pd.notna(s) else "‚Äî")
    view["YouTube"] = view.apply(yt_link, axis=1)
    show_cols = [c for c in ["title","views","impressions","CTR, %","watch_hours","–î–æ—Ö–æ–¥","format","YouTube","publish_time"] if c in view.columns]
    st.dataframe(view[show_cols].rename(columns={
        "title":"–ù–∞–∑–≤–∞–Ω–∏–µ","views":"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","impressions":"–ü–æ–∫–∞–∑—ã","watch_hours":"–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
        "format":"–§–æ—Ä–º–∞—Ç","publish_time":"–ü—É–±–ª–∏–∫–∞—Ü–∏—è"
    }), use_container_width=True)

elif page == "Compare Groups":
    st.title("üÜö Compare Groups")
    if len(st.session_state["groups"]) < 2:
        st.info("–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º –¥–≤–µ –≥—Ä—É–ø–ø—ã."); st.stop()

    glist = list(st.session_state["groups"].keys())
    a = st.selectbox("–ì—Ä—É–ø–ø–∞ A", glist, key="cmp_a")
    b = st.selectbox("–ì—Ä—É–ø–ø–∞ B", [x for x in glist if x != a], key="cmp_b")
    fmt = st.radio("–§–æ—Ä–º–∞—Ç", ["all","horizontal","vertical"], horizontal=True, key="cmp_fmt")

    def group_summary(gname: str) -> Dict[str, float]:
        files = normalize_packs(st.session_state["groups"].get(gname, []))
        rev = st.session_state["revenues"].get(gname, [])
        # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –°–£–ú–ú–ò–†–£–ï–ú –í–ù–£–¢–†–ò –≥—Ä—É–ø–ø—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è ¬´–∫–∞–Ω–∞–ª vs –∫–∞–Ω–∞–ª¬ª
        comb = combine_files(files, only_format=fmt)
        comb = attach_revenue(comb, rev) if not comb.empty else comb
        return summarize_one_file(comb, only_format="all")

    sA, sB = group_summary(a), group_summary(b)
    c1,c2,c3,c4 = st.columns(4)
    with c1: render_metric_card(f"{a}: –ü—Ä–æ—Å–º–æ—Ç—Ä—ã", human_int(sA.get("views", np.nan)))
    with c2: render_metric_card(f"{a}: CTR, %",    f"{sA.get('ctr',np.nan):.2f}%" if not pd.isna(sA.get('ctr',np.nan)) else "‚Äî")
    with c3: render_metric_card(f"{b}: –ü—Ä–æ—Å–º–æ—Ç—Ä—ã", human_int(sB.get("views", np.nan)))
    with c4: render_metric_card(f"{b}: CTR, %",    f"{sB.get('ctr',np.nan):.2f}%" if not pd.isna(sB.get('ctr',np.nan)) else "‚Äî")

    # –ø—Ä–æ—Å—Ç–∞—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    table = pd.DataFrame([
        {"–ì—Ä—É–ø–ø–∞": a, "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": sA.get("views", np.nan),
         "–ü–æ–∫–∞–∑—ã": sA.get("impressions", np.nan), "CTR, %": sA.get("ctr", np.nan),
         "AVD": seconds_to_hms(sA.get("avd_sec", np.nan)),
         "–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": sA.get("watch_hours", np.nan),
         "–î–æ—Ö–æ–¥": sA.get("revenue", np.nan)},
        {"–ì—Ä—É–ø–ø–∞": b, "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": sB.get("views", np.nan),
         "–ü–æ–∫–∞–∑—ã": sB.get("impressions", np.nan), "CTR, %": sB.get("ctr", np.nan),
         "AVD": seconds_to_hms(sB.get("avd_sec", np.nan)),
         "–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": sB.get("watch_hours", np.nan),
         "–î–æ—Ö–æ–¥": sB.get("revenue", np.nan)},
    ])
    # —É–±—Ä–∞—Ç—å ¬´–î–æ—Ö–æ–¥¬ª, –µ—Å–ª–∏ –ø—É—Å—Ç–æ
    if table["–î–æ—Ö–æ–¥"].notna().sum() == 0:
        table.drop(columns=["–î–æ—Ö–æ–¥"], inplace=True)

    st.dataframe(table.style.format({"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã":"{:,.0f}","–ü–æ–∫–∞–∑—ã":"{:,.0f}","CTR, %":"{:.2f}","–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞":"{:,.1f}"}).hide(axis="index"),
                 use_container_width=True)

elif page == "Manage Groups":
    st.title("üß∞ Manage Groups")
    if not st.session_state["groups"]:
        st.info("–ù–µ—Ç –≥—Ä—É–ø–ø."); st.stop()

    g = st.selectbox("–ì—Ä—É–ø–ø–∞", list(st.session_state["groups"].keys()), key="mgmt_g")
    packs = normalize_packs(st.session_state["groups"].get(g, []))
    st.write(f"–í–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: **{len(packs)}**")
    if not packs:
        st.info("–î–æ–±–∞–≤—å—Ç–µ –æ—Ç—á—ë—Ç—ã –≤ —Å–∞–π–¥–±–∞—Ä–µ –≤—ã—à–µ."); st.stop()

    for i, pack in enumerate(list(packs)):
        with st.expander(f"–û—Ç—á—ë—Ç: {pack['name']}", expanded=False):
            st.write(f"–°—Ç—Ä–æ–∫: {len(pack['df'])}")
            c1, c2 = st.columns([1,1])
            with c1:
                if st.button("–£–¥–∞–ª–∏—Ç—å —ç—Ç–æ—Ç –æ—Ç—á—ë—Ç", key=f"del_{g}_{i}"):
                    raw = st.session_state["groups"][g]
                    # —É–¥–∞–ª–∏—Ç—å –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∏–º–µ–Ω–∏ (–∏–ª–∏ –ø–æ–∑–∏—Ü–∏–∏)
                    idx_to_del = None
                    for j, item in enumerate(raw):
                        if isinstance(item, dict) and item.get("name") == pack["name"]:
                            idx_to_del = j; break
                    if idx_to_del is None and i < len(raw):
                        idx_to_del = i
                    if idx_to_del is not None:
                        st.session_state["groups"][g].pop(idx_to_del)
                    st.experimental_rerun()
            with c2:
                st.download_button("–°–∫–∞—á–∞—Ç—å CSV (–Ω–æ—Ä–º–∞–ª–∏–∑.)",
                                   data=pack["df"].to_csv(index=False).encode("utf-8"),
                                   file_name=f"{pack['name']}_normalized.csv",
                                   mime="text/csv")

    if st.button("–£–¥–∞–ª–∏—Ç—å –≤—Å—é –≥—Ä—É–ø–ø—É"):
        st.session_state["groups"].pop(g, None)
        st.session_state["revenues"].pop(g, None)
        st.experimental_rerun()
