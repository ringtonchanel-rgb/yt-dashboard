import io
import re
import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st


# ------------------------- #
# ------- Utilities -------- #
# ------------------------- #

st.set_page_config(page_title="YouTube Analytics Tools", layout="wide")

def _num(x):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —á–∏—Å–ª—É (float)."""
    if pd.isna(x):
        return np.nan
    try:
        if isinstance(x, str):
            x = x.replace(" ", "").replace(",", ".")
        return float(x)
    except Exception:
        return np.nan

def parse_duration_to_seconds(val) -> Optional[int]:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ–æ—Ä–º–∞—Ç–æ–≤:
      - 'MM:SS'
      - 'H:MM:SS'
      - '00:01:23'
      - '123' (—Å–µ–∫—É–Ω–¥—ã)
      - '12m 3s' (—Å–ª—É—á–∞–π–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã - –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏)
    """
    if pd.isna(val):
        return None
    s = str(val).strip()

    # —á–∏—Å—Ç—ã–π int?
    if s.isdigit():
        return int(s)

    # 12m 3s / 2m / 45s
    m = re.match(r'(?:(\d+)\s*h)?\s*(?:(\d+)\s*m)?\s*(?:(\d+)\s*s)?', s, re.I)
    if m and any(m.groups()):
        h = int(m.group(1)) if m.group(1) else 0
        m_ = int(m.group(2)) if m.group(2) else 0
        sec = int(m.group(3)) if m.group(3) else 0
        if h or m_ or sec:
            return h * 3600 + m_ * 60 + sec

    # H:MM:SS –∏–ª–∏ MM:SS
    parts = s.split(":")
    try:
        if len(parts) == 3:
            h, m_, sec = map(int, parts)
            return h * 3600 + m_ * 60 + sec
        elif len(parts) == 2:
            m_, sec = map(int, parts)
            return m_ * 60 + sec
    except Exception:
        pass

    return None

def seconds_to_hms(x: float) -> str:
    if pd.isna(x):
        return "‚Äî"
    x = int(round(x))
    h = x // 3600
    m = (x % 3600) // 60
    s = x % 60
    return f"{h:d}:{m:02d}:{s:02d}" if h else f"{m:d}:{s:02d}"

def detect_delimiter(buffer: bytes) -> str:
    """–ì—Ä—É–±—ã–π –¥–µ—Ç–µ–∫—Ç —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è."""
    head = buffer[:4000].decode("utf-8", errors="ignore")
    if head.count(";") > head.count(","):
        return ";"
    return ","


# –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω —Å—Ç–æ–ª–±—Ü–æ–≤: –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã -> –µ–¥–∏–Ω–æ–º—É –∏–º–µ–Ω–∏
COLUMN_ALIASES: Dict[str, str] = {
    # id
    "video id": "video_id",
    "–∏–¥ –≤–∏–¥–µ–æ": "video_id",
    "id –≤–∏–¥–µ–æ": "video_id",
    "content id": "video_id",

    # title
    "title": "title",
    "–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ": "title",
    "name": "title",

    # publish time
    "publish time": "publish_time",
    "–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ": "publish_time",
    "–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ": "publish_time",
    "publish date": "publish_time",
    "date": "date",  # –µ—Å–ª–∏ –¥–Ω–µ–≤–Ω–æ–π –æ—Ç—á—ë—Ç

    # metrics
    "views": "views",
    "–ø—Ä–æ—Å–º–æ—Ç—Ä—ã": "views",

    "impressions": "impressions",
    "–ø–æ–∫–∞–∑—ã": "impressions",

    "ctr": "ctr",
    "ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ (%)": "ctr",
    "impressions click-through rate": "ctr",

    "avg view duration": "avd",
    "average view duration": "avd",
    "—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": "avd",

    "watch time (hours)": "watch_hours",
    "watch time hours": "watch_hours",
    "—á–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": "watch_hours",

    "duration": "duration",
    "–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å": "duration",

    "format": "format",
    "—Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞": "format",
    "shorts": "shorts",
    "is shorts": "shorts",

    "estimated revenue": "revenue",
    "estimated partner revenue": "revenue",
    "–¥–æ—Ö–æ–¥": "revenue",
}

def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    new_cols = {}
    for c in df.columns:
        key = str(c).strip().lower()
        new_cols[c] = COLUMN_ALIASES.get(key, c)
    return df.rename(columns=new_cols)

def read_csv_smart(file) -> pd.DataFrame:
    data = file.read()
    delim = detect_delimiter(data)
    df = pd.read_csv(io.BytesIO(data), sep=delim, encoding="utf-8", engine="python")
    df = standardize_columns(df)

    # –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
    if "views" in df.columns:
        df["views"] = df["views"].map(_num)
    if "impressions" in df.columns:
        df["impressions"] = df["impressions"].map(_num)
    if "ctr" in df.columns:
        # CTR –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—Ü–µ–Ω—Ç—ã (5.3) –∏–ª–∏ 0.053 ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ %
        df["ctr"] = df["ctr"].map(_num)
        # –µ—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è <=1 –∏ –µ—Å—Ç—å >= 1, –Ω–µ —Ç—Ä–æ–≥–∞–µ–º; –µ—Å–ª–∏ –≤—Å—ë <=1 ‚Äî —É–º–Ω–æ–∂–∏–º –Ω–∞ 100
        if df["ctr"].dropna().max() <= 1.0:
            df["ctr"] = df["ctr"] * 100.0

    if "watch_hours" in df.columns:
        df["watch_hours"] = df["watch_hours"].map(_num)

    # publish_time/date –∫–∞–∫ datetime, –µ—Å–ª–∏ –µ—Å—Ç—å
    if "publish_time" in df.columns:
        df["publish_time"] = pd.to_datetime(df["publish_time"], errors="coerce")
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

    # –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å ‚Üí —Å–µ–∫—É–Ω–¥—ã
    if "duration" in df.columns:
        df["duration_sec"] = df["duration"].apply(parse_duration_to_seconds)
    else:
        df["duration_sec"] = np.nan

    # —Ñ–æ—Ä–º–∞—Ç: vertical/horizontal
    df["format"] = df.get("format")  # –≤–æ–∑–º–æ–∂–Ω–æ —É–∂–µ –µ—Å—Ç—å
    # –ï—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–π —Ñ–ª–∞–≥ —à–æ—Ä—Ç–æ–≤
    if "shorts" in df.columns:
        df.loc[df["shorts"].astype(str).str.lower().isin(["1", "true", "–¥–∞", "yes"]), "format"] = "vertical"
    # –ï—Å–ª–∏ –Ω–µ—Ç, —Ç–æ —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    df.loc[df["format"].isna() & (df["duration_sec"] <= 60), "format"] = "vertical"
    df["format"] = df["format"].fillna("horizontal")

    # revenue –µ—Å–ª–∏ –µ—Å—Ç—å
    if "revenue" in df.columns:
        df["revenue"] = df["revenue"].map(_num)

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º id
    if "video_id" in df.columns:
        df["video_id"] = df["video_id"].astype(str).str.strip()

    return df


# ------------------------- #
# ---- Session storage ----- #
# ------------------------- #

if "groups" not in st.session_state:
    # groups: { group_name: [ {"name": filename, "df": DataFrame}, ... ] }
    st.session_state.groups: Dict[str, List[Dict]] = {}

if "revenues" not in st.session_state:
    # –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–æ—Ö–æ–¥–æ–≤ (–ø–æ video_id –∏–ª–∏ –ø–æ –¥–∞—Ç–µ), –ø—Ä–∏–∞—Ç—Ç–∞—á–∏–≤–∞—é—Ç—Å—è –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π –≥—Ä—É–ø–ø–µ
    # revenues[group_name] = [ {"name": filename, "df": df}, ... ]
    st.session_state.revenues: Dict[str, List[Dict]] = {}


# ------------------------- #
# ---- Helper metrics ------ #
# ------------------------- #

def human_int(x: float) -> str:
    if pd.isna(x):
        return "‚Äî"
    x = float(x)
    for unit in ["", "K", "M", "B"]:
        if abs(x) < 1000:
            return f"{x:,.0f}{unit}".replace(",", " ")
        x /= 1000.0
    return f"{x:.1f}T"

def attach_revenue(base_df: pd.DataFrame, revenue_packs: List[Dict]) -> pd.DataFrame:
    """
    –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å –¥–æ—Ö–æ–¥—ã, –µ—Å–ª–∏ –∏—Ö –∑–∞–≥—Ä—É–∑–∏–ª–∏ –æ—Ç–¥–µ–ª—å–Ω–æ.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º 2 —Ç–∏–ø–∞:
      - –ø–æ video_id: [video_id, revenue]
      - –ø–æ date: [date, revenue] (—Ç–æ–≥–¥–∞ –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–æ—Ö–æ–¥ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏)
    """
    if not revenue_packs:
        return base_df

    df = base_df.copy()
    df["revenue_ext"] = np.nan

    # –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ video_id
    for pack in revenue_packs:
        r = pack["df"]
        cols = [c.lower() for c in r.columns]
        if "video_id" in cols and "revenue" in cols:
            r2 = r.rename(columns={r.columns[cols.index("video_id")]: "video_id",
                                   r.columns[cols.index("revenue")]: "revenue"}).copy()
            r2["video_id"] = r2["video_id"].astype(str).str.strip()
            r2["revenue"] = r2["revenue"].map(_num)
            df = df.merge(r2[["video_id", "revenue"]], on="video_id", how="left", suffixes=("", "_extjoin"))
            df["revenue_ext"] = df["revenue_ext"].fillna(df["revenue_extjoin"])
            df.drop(columns=[c for c in df.columns if c.endswith("_extjoin")], inplace=True)
        elif "date" in cols and "revenue" in cols:
            r2 = r.rename(columns={r.columns[cols.index("date")]: "date",
                                   r.columns[cols.index("revenue")]: "revenue"}).copy()
            r2["date"] = pd.to_datetime(r2["date"], errors="coerce")
            daily = r2.groupby("date", as_index=False)["revenue"].sum()
            # —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º –¥–æ—Ö–æ–¥ –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–≥—Ä—É–±–æ)
            if "publish_time" in df.columns:
                df["pub_date"] = df["publish_time"].dt.floor("d")
                df = df.merge(daily, left_on="pub_date", right_on="date", how="left", suffixes=("", "_rday"))
                df["revenue_ext"] = df["revenue_ext"].fillna(df["revenue_rday"])
                df.drop(columns=["date", "pub_date", "revenue_rday"], inplace=True, errors="ignore")

    # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ revenue_final
    if "revenue" in df.columns:
        df["revenue_final"] = df["revenue"].fillna(df["revenue_ext"])
    else:
        df["revenue_final"] = df["revenue_ext"]

    return df


def summarize_one_file(df: pd.DataFrame, only_format: str = "all") -> Dict[str, float]:
    """
    –°–≤–æ–¥–∫–∞ –ø–æ –æ–¥–Ω–æ–º—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É.
    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ù–ï —Å—É–º–º–∏—Ä—É–µ–º —Å —á–µ–º-—Ç–æ –µ—â—ë ‚Äî –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞.
    """
    d = df.copy()

    # —Ñ–∏–ª—å—Ç—Ä –≤–µ—Ä—Ç–∏–∫–∞–ª/–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª/–≤—Å–µ
    if only_format in ("vertical", "horizontal"):
        d = d.loc[d["format"] == only_format]

    out = {
        "videos": len(d),
        "views": d["views"].sum(skipna=True) if "views" in d.columns else np.nan,
        "impressions": d["impressions"].sum(skipna=True) if "impressions" in d.columns else np.nan,
        "ctr": d["ctr"].mean(skipna=True) if "ctr" in d.columns else np.nan,
        "avd_sec": d["duration_sec"].mean(skipna=True) if "duration_sec" in d.columns else np.nan,
        "watch_hours": d["watch_hours"].sum(skipna=True) if "watch_hours" in d.columns else np.nan,
        "revenue": d["revenue_final"].sum(skipna=True) if "revenue_final" in d.columns else np.nan,
    }
    return out


def combine_files(files: List[Dict], only_format: str = "all") -> pd.DataFrame:
    """
    –ï—Å–ª–∏ –≤—Å—ë-—Ç–∞–∫–∏ –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã ‚Äî –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–æ–µ–¥–∏–Ω—è–µ–º (–±–µ–∑ –¥–µ–¥—É–ø–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é),
    —Ç–æ–ª—å–∫–æ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏.
    """
    if not files:
        return pd.DataFrame()
    dfs = []
    for pack in files:
        df = pack["df"].copy()
        if only_format in ("vertical", "horizontal"):
            df = df.loc[df["format"] == only_format]
        df["__file__"] = pack["name"]
        dfs.append(df)
    return pd.concat(dfs, ignore_index=True)


# ------------------------- #
# --------- UI ------------- #
# ------------------------- #

st.sidebar.title("üñ•Ô∏è YouTube Analytics Tools")

page = st.sidebar.radio(
    "–ù–∞–≤–∏–≥–∞—Ü–∏—è",
    ["Dashboard", "Channel Explorer", "Compare Groups", "Manage Groups"],
    index=0
)

# --- –±–ª–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≥—Ä—É–ø–ø—ã/–æ—Ç—á—ë—Ç–æ–≤
with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –≥—Ä—É–ø–ø—É", expanded=True):
    new_group_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)")
    add_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV", type=["csv"], accept_multiple_files=True)
    rev_files = st.file_uploader("–û—Ç–¥–µ–ª—å–Ω—ã–µ CSV —Å –¥–æ—Ö–æ–¥–æ–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)", type=["csv"], accept_multiple_files=True)

    col_btn1, col_btn2 = st.columns(2)
    with col_btn1:
        if st.button("–î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É"):
            if new_group_name:
                if new_group_name not in st.session_state.groups:
                    st.session_state.groups[new_group_name] = []
                # –¥–æ–±–∞–≤–∏–º –æ—Ç—á–µ—Ç—ã
                for f in add_files or []:
                    df = read_csv_smart(f)
                    # –ø—Ä–∏–∫—Ä—É—Ç–∏–º –≤–Ω–µ—à–Ω–∏–π –¥–æ—Ö–æ–¥, –µ—Å–ª–∏ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω —Ä–∞–Ω–µ–µ
                    df = attach_revenue(df, st.session_state.revenues.get(new_group_name, []))
                    st.session_state.groups[new_group_name].append({"name": f.name, "df": df})
                # –¥–æ—Ö–æ–¥—ã –æ—Ç–¥–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
                if rev_files:
                    st.session_state.revenues.setdefault(new_group_name, [])
                    for rf in rev_files:
                        r_df = read_csv_smart(rf)
                        st.session_state.revenues[new_group_name].append({"name": rf.name, "df": r_df})
                st.success("–ì—Ä—É–ø–ø–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞/–æ–±–Ω–æ–≤–ª–µ–Ω–∞")
            else:
                st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã")

    with col_btn2:
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã"):
            st.session_state.groups = {}
            st.session_state.revenues = {}
            st.experimental_rerun()

# —Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø
st.sidebar.markdown("### –í–∞—à–∏ –≥—Ä—É–ø–ø—ã:")
if not st.session_state.groups:
    st.sidebar.info("–ü–æ–∫–∞ –Ω–µ—Ç –≥—Ä—É–ø–ø")
else:
    for gname in st.session_state.groups.keys():
        st.sidebar.write(f"‚Ä¢ **{gname}** ({len(st.session_state.groups[gname])} –æ—Ç—á.)")


# ------------------------- #
# ------- DASHBOARD -------- #
# ------------------------- #

if page == "Dashboard":
    st.title("Dashboard")

    if not st.session_state.groups:
        st.info("–î–æ–±–∞–≤—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É –∏ –æ—Ç—á—ë—Ç—ã –≤ –Ω–µ—ë ‚Äî –≤ –ª–µ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        st.stop()

    gname = st.selectbox("–í—ã–±–µ—Ä–∏ –≥—Ä—É–ø–ø—É", list(st.session_state.groups.keys()))
    files = st.session_state.groups.get(gname, [])
    rev_packs = st.session_state.revenues.get(gname, [])

    st.caption(f"–§–∞–π–ª–æ–≤ –≤ –≥—Ä—É–ø–ø–µ **{gname}**: {len(files)}")

    # —Ñ–æ—Ä–º–∞—Ç —Ñ–∏–ª—å—Ç—Ä
    fmt = st.radio("–§–∏–ª—å—Ç—Ä —Ñ–æ—Ä–º–∞—Ç–∞", ["all", "horizontal", "vertical"], horizontal=True)

    # –ø—Ä–∏–∫—Ä—É—Ç–∏—Ç—å –≤–Ω–µ—à–Ω–∏–π –¥–æ—Ö–æ–¥ –∫ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É (—Å–≤–µ–∂–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è)
    updated_files = []
    for pack in files:
        df = attach_revenue(pack["df"], rev_packs)
        updated_files.append({"name": pack["name"], "df": df})
    files = updated_files

    # —Ä–µ–∂–∏–º –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
    combine_toggle = st.toggle("–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ –æ—Ç—á—ë—Ç—ã –¥–ª—è –æ–±—â–µ–π –¥–∏–∞–≥—Ä–∞–º–º—ã (–≤ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)", value=False)

    st.subheader("–°–≤–æ–¥–∫–∞ –ø–æ –∫–∞–∂–¥–æ–º—É –æ—Ç—á—ë—Ç—É (—Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è)")

    rows = []
    for pack in files:
        s = summarize_one_file(pack["df"], only_format=fmt)
        rows.append({
            "–û—Ç—á—ë—Ç": pack["name"],
            "–í–∏–¥–µ–æ": s["videos"],
            "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": s["views"],
            "–ü–æ–∫–∞–∑—ã": s["impressions"],
            "CTR, %": s["ctr"],
            "AVD": seconds_to_hms(s["avd_sec"]),
            "–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": s["watch_hours"],
            "–î–æ—Ö–æ–¥": s["revenue"],
        })

    seg_df = pd.DataFrame(rows)
    # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Ö–æ–¥ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å –æ–¥–Ω–æ –Ω–µ–Ω—É–ª–µ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    if "–î–æ—Ö–æ–¥" in seg_df.columns and seg_df["–î–æ—Ö–æ–¥"].notna().sum() == 0:
        seg_df = seg_df.drop(columns=["–î–æ—Ö–æ–¥"])

    st.dataframe(
        seg_df.style.format({
            "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": "{:,.0f}",
            "–ü–æ–∫–∞–∑—ã": "{:,.0f}",
            "CTR, %": "{:.2f}",
            "–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": "{:,.1f}",
            "–î–æ—Ö–æ–¥": "{:,.2f}",
        }).hide(axis="index"),
        use_container_width=True,
        height=300
    )

    # –º–∏–Ω–∏-–≥—Ä–∞—Ñ–∏–∫ –ø–æ –æ—Ç—á—ë—Ç–∞–º: –∫—Ç–æ –¥–∞–ª –±–æ–ª—å—à–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤
    if not seg_df.empty and "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã" in seg_df.columns:
        st.plotly_chart(
            px.bar(seg_df, x="–û—Ç—á—ë—Ç", y="–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", title="–ü—Ä–æ—Å–º–æ—Ç—Ä—ã –ø–æ –æ—Ç—á—ë—Ç–∞–º (—Å —É—á—ë—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞ —Ñ–æ—Ä–º–∞—Ç–∞)"),
            use_container_width=True
        )

    st.divider()

    if combine_toggle:
        st.subheader("–û–±—â–∏–π –≥—Ä–∞—Ñ–∏–∫ –ø–æ –≤—Å–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –æ—Ç—á—ë—Ç–∞–º (–Ω–µ –≤–º–µ—Å—Ç–æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –∞ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ)")
        comb = combine_files(files, only_format=fmt)
        if comb.empty:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
        else:
            # –ø—Ä–æ—Å—Ç–∞—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø–æ —Ñ–∞–π–ª–∞–º
            fig = px.histogram(comb, x="views", color="__file__", nbins=30, title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (–≤—Å–µ —Ñ–∞–π–ª—ã)")
            st.plotly_chart(fig, use_container_width=True)

            # –¢–æ–ø-10 –≤–∏–¥–µ–æ –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º
            if "title" in comb.columns and "views" in comb.columns:
                top10 = comb.sort_values("views", ascending=False).head(10)[["title", "views", "__file__"]]
                st.dataframe(top10.rename(columns={"title": "–ù–∞–∑–≤–∞–Ω–∏–µ", "views": "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", "__file__": "–û—Ç—á—ë—Ç"}),
                             use_container_width=True)


# ------------------------- #
# ---- Channel Explorer ---- #
# ------------------------- #

elif page == "Channel Explorer":
    st.title("Channel Explorer")
    if not st.session_state.groups:
        st.info("–î–æ–±–∞–≤—å –≥—Ä—É–ø–ø—É —Å–ª–µ–≤–∞.")
        st.stop()

    gname = st.selectbox("–ì—Ä—É–ø–ø–∞", list(st.session_state.groups.keys()), key="expl_g")
    files = st.session_state.groups.get(gname, [])
    rev_packs = st.session_state.revenues.get(gname, [])

    if not files:
        st.info("–í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤.")
        st.stop()

    file_names = [f["name"] for f in files]
    fname = st.selectbox("–í—ã–±–µ—Ä–∏ –æ—Ç—á—ë—Ç", file_names)
    pack = files[file_names.index(fname)]
    df = attach_revenue(pack["df"], rev_packs)

    fmt = st.radio("–§–æ—Ä–º–∞—Ç", ["all", "horizontal", "vertical"], horizontal=True, key="expl_fmt")
    if fmt in ("horizontal", "vertical"):
        df = df.loc[df["format"] == fmt]

    st.caption(f"–°—Ç—Ä–æ–∫: {len(df)}")

    # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –ø—Ä–æ—Å—Ç—ã—Ö —Å—Ä–µ–∑–æ–≤: –º–µ—Ç—Ä–∏–∫–∞ –∏ –≤–∏–¥ –≥—Ä–∞—Ñ–∏–∫–∞
    metrics = []
    if "views" in df.columns:
        metrics.append("views")
    if "impressions" in df.columns:
        metrics.append("impressions")
    if "ctr" in df.columns:
        metrics.append("ctr")
    if "watch_hours" in df.columns:
        metrics.append("watch_hours")
    if "revenue_final" in df.columns:
        metrics.append("revenue_final")

    if not metrics:
        st.warning("–ù–µ –Ω–∞—à—ë–ª –Ω–∏ –æ–¥–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ (views/impressions/ctr/watch_hours/revenue).")
        st.stop()

    m = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞", metrics, index=0)
    chart_type = st.selectbox("–¢–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞", ["Bar", "Scatter", "Histogram"], index=0)

    # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
    if "title" in df.columns:
        xcol = "title"
    else:
        # fallback
        xcol = df.columns[0]

    if chart_type == "Bar":
        fig = px.bar(df.nlargest(30, m), x=xcol, y=m, title=f"Top-30 –ø–æ {m}")
        fig.update_layout(xaxis_title="", yaxis_title=m)
        st.plotly_chart(fig, use_container_width=True)
    elif chart_type == "Scatter":
        # Scatter views vs impressions (–µ—Å–ª–∏ –µ—Å—Ç—å)
        ycand = [i for i in ["impressions", "ctr", "watch_hours", "revenue_final"] if i in df.columns and i != m]
        yaxis = st.selectbox("–í—Ç–æ—Ä–∞—è –æ—Å—å (Y)", ycand) if ycand else m
        fig = px.scatter(df, x=m, y=yaxis, hover_data=[xcol], title=f"{m} vs {yaxis}")
        st.plotly_chart(fig, use_container_width=True)
    else:
        fig = px.histogram(df, x=m, nbins=40, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {m}")
        st.plotly_chart(fig, use_container_width=True)

    st.divider()
    st.subheader("–¢–∞–±–ª–∏—Ü–∞")
    show_cols = [c for c in ["title", "views", "impressions", "ctr", "watch_hours", "revenue_final", "format"] if c in df.columns]
    st.dataframe(df[show_cols].rename(columns={
        "title": "–ù–∞–∑–≤–∞–Ω–∏–µ",
        "views": "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã",
        "impressions": "–ü–æ–∫–∞–∑—ã",
        "ctr": "CTR, %",
        "watch_hours": "–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
        "revenue_final": "–î–æ—Ö–æ–¥",
        "format": "–§–æ—Ä–º–∞—Ç",
    }), use_container_width=True)


# ------------------------- #
# ---- Compare Groups -------#
# ------------------------- #

elif page == "Compare Groups":
    st.title("Compare Groups")
    if len(st.session_state.groups) < 2:
        st.info("–ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º –¥–≤–µ –≥—Ä—É–ø–ø—ã.")
        st.stop()

    g1, g2 = st.columns(2)
    with g1:
        a = st.selectbox("–ì—Ä—É–ø–ø–∞ A", list(st.session_state.groups.keys()), key="cmp_a")
    with g2:
        b = st.selectbox("–ì—Ä—É–ø–ø–∞ B", [x for x in st.session_state.groups.keys() if x != a], key="cmp_b")

    fmt = st.radio("–§–æ—Ä–º–∞—Ç", ["all", "horizontal", "vertical"], horizontal=True, key="cmp_fmt")

    def sum_group(group_name: str) -> Dict[str, float]:
        files = st.session_state.groups[group_name]
        rev = st.session_state.revenues.get(group_name, [])
        # –ù–ï —Å—É–º–º–∏—Ä—É–µ–º –ø–æ —Ñ–∞–π–ª–∞–º –º–µ–∂–¥—É —Å–æ–±–æ–π? ‚Äì –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –≥—Ä—É–ø–ø —á–∞—â–µ –Ω—É–∂–µ–Ω –∏–º–µ–Ω–Ω–æ –æ–±—â–∏–π –∏—Ç–æ–≥.
        # –°–¥–µ–ª–∞–µ–º —Å–≤–∏—Ç—á:
        if st.toggle(f"–û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã –¥–ª—è {group_name}", key=f"merge_{group_name}", value=True):
            comb = combine_files(files, only_format=fmt)
            comb = attach_revenue(comb, rev) if not comb.empty else comb
            return summarize_one_file(comb, only_format="all")
        else:
            # –µ—Å–ª–∏ –æ—Ç–∫–ª—é—á–∏–ª–∏ ‚Äî —Å—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –ø–æ —Ñ–∞–π–ª–∞–º (–∫–∞–∫ "—Å—Ä–µ–¥–Ω—è—è –≥—Ä—É–ø–ø–∞")
            acc = []
            for pack in files:
                df = attach_revenue(pack["df"], rev)
                acc.append(summarize_one_file(df, only_format=fmt))
            if not acc:
                return {}
            tmp = pd.DataFrame(acc).mean(numeric_only=True).to_dict()
            tmp["videos"] = np.mean([x["videos"] for x in acc]) if acc else np.nan
            return tmp

    sA = sum_group(a)
    sB = sum_group(b)

    colA, colB = st.columns(2)
    with colA:
        st.markdown(f"### {a}")
        st.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", human_int(sA.get("views", np.nan)))
        st.metric("–ü–æ–∫–∞–∑—ã", human_int(sA.get("impressions", np.nan)))
        st.metric("CTR, %", f"{sA.get('ctr', np.nan):.2f}" if not pd.isna(sA.get("ctr", np.nan)) else "‚Äî")
        st.metric("AVD", seconds_to_hms(sA.get("avd_sec", np.nan)))
        if not pd.isna(sA.get("revenue", np.nan)):
            st.metric("–î–æ—Ö–æ–¥", human_int(sA.get("revenue", np.nan)))

    with colB:
        st.markdown(f"### {b}")
        st.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", human_int(sB.get("views", np.nan)))
        st.metric("–ü–æ–∫–∞–∑—ã", human_int(sB.get("impressions", np.nan)))
        st.metric("CTR, %", f"{sB.get('ctr', np.nan):.2f}" if not pd.isna(sB.get("ctr", np.nan)) else "‚Äî")
        st.metric("AVD", seconds_to_hms(sB.get("avd_sec", np.nan)))
        if not pd.isna(sB.get("revenue", np.nan)):
            st.metric("–î–æ—Ö–æ–¥", human_int(sB.get("revenue", np.nan)))


# ------------------------- #
# ----- Manage Groups ------ #
# ------------------------- #

elif page == "Manage Groups":
    st.title("Manage Groups")
    if not st.session_state.groups:
        st.info("–ù–µ—Ç –≥—Ä—É–ø–ø")
        st.stop()

    gname = st.selectbox("–í—ã–±–µ—Ä–∏ –≥—Ä—É–ø–ø—É", list(st.session_state.groups.keys()), key="mgmt_g")
    packs = st.session_state.groups[gname]

    st.write(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(packs)}")
    for i, pack in enumerate(list(packs)):
        with st.expander(f"–û—Ç—á—ë—Ç: {pack['name']}", expanded=False):
            st.write(f"–°—Ç—Ä–æ–∫: {len(pack['df'])}")
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("–£–¥–∞–ª–∏—Ç—å —ç—Ç–æ—Ç –æ—Ç—á—ë—Ç", key=f"del_{gname}_{i}"):
                    st.session_state.groups[gname].pop(i)
                    st.experimental_rerun()
            with col2:
                st.download_button("–°–∫–∞—á–∞—Ç—å –∫–∞–∫ CSV", data=pack["df"].to_csv(index=False).encode("utf-8"),
                                   file_name=f"{pack['name']}_normalized.csv", mime="text/csv")

    if st.button("–£–¥–∞–ª–∏—Ç—å –≤—Å—é –≥—Ä—É–ø–ø—É"):
        st.session_state.groups.pop(gname, None)
        st.session_state.revenues.pop(gname, None)
        st.experimental_rerun()
