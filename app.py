# app.py ‚Äî YouTube Analytics Tools
# Dashboard (–≥—Ä—É–ø–ø—ã + —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π) –∏ Group Analytics (Year Mix)
# –î—É–±–ª–∏–∫–∞—Ç—ã CSV –†–ê–ó–†–ï–®–ï–ù–´: –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —Ñ–∞–π–ª —Å–∫–æ–ª—å–∫–æ —É–≥–æ–¥–Ω–æ —Ä–∞–∑.

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import io, re, hashlib

# --------------------------- UI CONFIG ---------------------------
st.set_page_config(page_title="YouTube Analytics Tools", layout="wide")
USE_EMOJI = True
ICON_DASH  = "üìä " if USE_EMOJI else ""
ICON_GROUP = "üß© " if USE_EMOJI else ""
ICON_BRAND = "üì∫ " if USE_EMOJI else ""

st.sidebar.markdown(
    f"<div style='font-weight:700;font-size:1.05rem;letter-spacing:.1px;'>{ICON_BRAND}YouTube Analytics Tools</div>",
    unsafe_allow_html=True,
)
st.sidebar.divider()
nav = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", [f"{ICON_DASH}Dashboard", f"{ICON_GROUP}Group Analytics"])
st.sidebar.divider()

# --------------------------- HELPERS: columns / parsing ---------------------------
def _norm(s: str) -> str:
    return str(s).strip().lower()

MAP = {
    "publish_time": ["video publish time","publish time","–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ","–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏","publish date"],
    "views": ["views","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã","–ø—Ä–æ—Å–º—Ç–æ—Ä—ã","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã (views)"],
    "impressions": ["impressions","–ø–æ–∫–∞–∑—ã","–ø–æ–∫–∞–∑—ã (impressions)","–ø–æ–∫–∞–∑—ã –∑–Ω–∞—á–∫–æ–≤","–ø–æ–∫–∞–∑—ã –¥–ª—è –∑–Ω–∞—á–∫–æ–≤"],
    "ctr": ["impressions click-through rate","ctr","ctr (%)","ctr for thumbnails (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤",
            "ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ","ctr –≤–∏–¥–µ–æ"],
    "avd": ["average view duration","avg view duration","—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
            "—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–∏–¥–µ–æ","average view duration (hh:mm:ss)"],
    "title": ["title","–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ","video title","–≤–∏–¥–µ–æ","–Ω–∞–∑–≤–∞–Ω–∏–µ"],
}

def find_col(df: pd.DataFrame, names) -> str | None:
    if isinstance(names, str):
        names = [names]
    by_norm = {_norm(c): c for c in df.columns}
    # —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    for n in names:
        nn = _norm(n)
        if nn in by_norm:
            return by_norm[nn]
    # –ø–æ–¥—Å—Ç—Ä–æ–∫–∏
    for n in names:
        nn = _norm(n)
        for c in df.columns:
            if nn in _norm(c):
                return c
    return None

def detect_columns(df: pd.DataFrame):
    return {k: find_col(df, v) for k, v in MAP.items()}

def to_number(x):
    if x is None:
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "" or s.lower() in {"nan", "none"}:
        return np.nan
    s = s.replace(" ", "").replace("\u202f", "").replace("\xa0", "")
    is_percent = s.endswith("%")
    if is_percent:
        s = s[:-1]
    if "," in s and "." not in s:
        s = s.replace(",", ".")
    try:
        return float(s)
    except Exception:
        return np.nan

def parse_duration_to_seconds(x):
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "":
        return np.nan
    m = re.match(r"^(\d+):(\d{2}):(\d{2})$", s)
    if m:
        h, m_, s_ = map(int, m.groups())
        return h * 3600 + m_ * 60 + s_
    m = re.match(r"^(\d+):(\d{2})$", s)
    if m:
        m_, s_ = map(int, m.groups())
        return m_ * 60 + s_
    try:
        return float(s)
    except Exception:
        return np.nan

def seconds_to_hhmmss(sec):
    if pd.isna(sec):
        return "‚Äî"
    sec = int(round(sec))
    h = sec // 3600
    m = (sec % 3600) // 60
    s = sec % 60
    return f"{h}:{m:02d}:{s:02d}" if h else f"{m}:{s:02d}"

# --------------------------- FILE LOADER ---------------------------
def load_uploaded_file(uploaded_file):
    """
    –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —Å—Ç–∞–±–∏–ª—å–Ω–æ:
    - –µ–¥–∏–Ω—ã–º –±–∞–π—Ç–æ–≤—ã–º –±—É—Ñ–µ—Ä–æ–º (getvalue/read)
    - md5-—Ö—ç—à (—Ç–µ–ø–µ—Ä—å –ª–∏—à—å –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –¥—É–±–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã)
    - –ø—Ä–æ–±—ã –∫–æ–¥–∏—Ä–æ–≤–æ–∫
    """
    raw = uploaded_file.getvalue() if hasattr(uploaded_file, "getvalue") else uploaded_file.read()
    h = hashlib.md5(raw).hexdigest()

    df = None
    for enc in (None, "utf-8-sig", "cp1251"):
        try:
            df = pd.read_csv(io.BytesIO(raw), encoding=enc) if enc else pd.read_csv(io.BytesIO(raw))
            break
        except Exception:
            df = None

    meta = "‚ùå –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV."
    if df is not None and not df.empty:
        df.columns = [c.strip() for c in df.columns]
        meta = f"‚úÖ {uploaded_file.name}: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫."
    return {"name": uploaded_file.name, "hash": h, "df": df, "meta": meta}

# --------------------------- STORAGE ---------------------------
if "groups" not in st.session_state:
    st.session_state["groups"] = []   # [{name: str, files: [{name, hash, df, meta}, ...]}]

def concat_groups(indices):
    frames = []
    for i in indices:
        if 0 <= i < len(st.session_state["groups"]):
            for f in st.session_state["groups"][i]["files"]:
                if f["df"] is not None and not f["df"].empty:
                    frames.append(f["df"])
    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()

def kpis_for_group(group):
    total_impr = 0.0
    total_views = 0.0
    ctr_vals = []
    avd_vals = []
    for f in group["files"]:
        df = f["df"]
        if df is None or df.empty:
            continue
        C = detect_columns(df)
        if C["impressions"] and C["impressions"] in df.columns:
            total_impr += pd.to_numeric(df[C["impressions"]].apply(to_number), errors="coerce").fillna(0).sum()
        if C["views"] and C["views"] in df.columns:
            total_views += pd.to_numeric(df[C["views"]].apply(to_number), errors="coerce").fillna(0).sum()
        if C["ctr"] and C["ctr"] in df.columns:
            ctr_vals += list(df[C["ctr"]].apply(to_number).dropna().values)
        if C["avd"] and C["avd"] in df.columns:
            avd_vals += list(df[C["avd"]].apply(parse_duration_to_seconds).dropna().values)
    avg_ctr = float(np.nanmean(ctr_vals)) if ctr_vals else np.nan
    avg_avd = float(np.nanmean(avd_vals)) if avd_vals else np.nan
    return dict(impressions=int(total_impr), views=int(total_views), ctr=avg_ctr, avd_sec=avg_avd)

# --------------------------- DASHBOARD ---------------------------
if nav.endswith("Dashboard"):
    st.header("Dashboard")

    # --- –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
    with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É –¥–∞–Ω–Ω—ã—Ö", expanded=True):
        group_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)", value=f"Group {len(st.session_state['groups'])+1}")
        files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ CSV", type=["csv"], accept_multiple_files=True, key="add_group_files")
        if st.button("–î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É"):
            if not group_name.strip():
                st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã.")
            elif not files:
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
            else:
                new_files = []
                for uf in files:
                    pack = load_uploaded_file(uf)
                    if pack["df"] is None or pack["df"].empty:
                        continue
                    # –î—É–±–ª–∏–∫–∞—Ç—ã –†–ê–ó–†–ï–®–ï–ù–´ ‚Äî –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å—ë
                    new_files.append(pack)
                if new_files:
                    st.session_state["groups"].append({"name": group_name.strip(), "files": new_files})
                    st.success(f"–ì—Ä—É–ø–ø–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞. –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(new_files)}.")
                    st.rerun()
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∞–π–ª—ã (–≤–æ–∑–º–æ–∂–Ω–æ –ø—É—Å—Ç—ã–µ/–ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã).")

    if not st.session_state["groups"]:
        st.info("–î–æ–±–∞–≤—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É –≤ —Å–∞–π–¥–±–∞—Ä–µ.")
    else:
        # --- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø–∞–º–∏
        st.markdown("### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø–∞–º–∏")
        for gi, g in enumerate(st.session_state["groups"]):
            with st.expander(f"–ì—Ä—É–ø–ø–∞: {g['name']}", expanded=False):
                # –ü–æ–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                new_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ", value=g["name"], key=f"rename_{gi}")
                add_more = st.file_uploader(
                    "–î–æ–±–∞–≤–∏—Ç—å –æ—Ç—á—ë—Ç—ã –≤ —ç—Ç—É –≥—Ä—É–ø–ø—É",
                    type=["csv"], accept_multiple_files=True, key=f"append_files_{gi}"
                )

                # –ï–î–ò–ù–ê–Ø –ö–ù–û–ü–ö–ê –°–û–•–†–ê–ù–ï–ù–ò–Ø
                if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è", key=f"save_group_{gi}"):
                    changed = False

                    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
                    if new_name.strip() and new_name.strip() != g["name"]:
                        g["name"] = new_name.strip()
                        changed = True

                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ (–¥—É–±–ª–∏–∫–∞—Ç—ã —Ä–∞–∑—Ä–µ—à–µ–Ω—ã)
                    if add_more:
                        added = 0
                        for uf in add_more:
                            pack = load_uploaded_file(uf)
                            if pack["df"] is None or pack["df"].empty:
                                continue
                            g["files"].append(pack)
                            added += 1
                        if added:
                            st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {added}.")
                            changed = True

                    if changed:
                        st.rerun()
                    else:
                        st.info("–ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç ‚Äî –Ω–µ—á–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å.")

                # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ + —É–¥–∞–ª–µ–Ω–∏–µ
                st.markdown("**–§–∞–π–ª—ã –≥—Ä—É–ø–ø—ã:**")
                if not g["files"]:
                    st.write("‚Äî –ø–æ–∫–∞ –Ω–µ—Ç —Ñ–∞–π–ª–æ–≤.")
                else:
                    for fi, f in enumerate(g["files"]):
                        c1, c2 = st.columns([4,1])
                        with c1:
                            st.write(f["meta"])
                        with c2:
                            if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"del_file_{gi}_{fi}"):
                                g["files"].pop(fi)
                                st.rerun()

                st.divider()
                # –£–¥–∞–ª–µ–Ω–∏–µ –≥—Ä—É–ø–ø—ã
                if st.button("–£–¥–∞–ª–∏—Ç—å –≥—Ä—É–ø–ø—É", key=f"del_group_{gi}"):
                    st.session_state["groups"].pop(gi)
                    st.rerun()

        st.divider()

        # --- KPI –ø–æ –≥—Ä—É–ø–ø–∞–º
        st.markdown("### –°–≤–æ–¥–∫–∞ –ø–æ –≥—Ä—É–ø–ø–∞–º")
        kpi_rows = []
        for gi, g in enumerate(st.session_state["groups"]):
            kp = kpis_for_group(g)
            st.subheader(f"–ì—Ä—É–ø–ø–∞: {g['name']}")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("–ü–æ–∫–∞–∑—ã (—Å—É–º–º–∞)", f"{kp['impressions']:,}".replace(",", " "))
            c2.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã (—Å—É–º–º–∞)", f"{kp['views']:,}".replace(",", " "))
            c3.metric("–°—Ä–µ–¥–Ω–∏–π CTR –ø–æ –≤–∏–¥–µ–æ", "‚Äî" if np.isnan(kp["ctr"]) else f"{kp['ctr']:.2f}%")
            c4.metric("–°—Ä–µ–¥–Ω–∏–π AVD", seconds_to_hhmmss(kp["avd_sec"]))
            kpi_rows.append({
                "–ì—Ä—É–ø–ø–∞": g["name"],
                "–ü–æ–∫–∞–∑—ã": kp["impressions"],
                "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": kp["views"],
                "CTR, % (—Å—Ä–µ–¥–Ω–µ–µ)": None if np.isnan(kp["ctr"]) else round(kp["ctr"], 2),
                "AVD (—Å—Ä.)": seconds_to_hhmmss(kp["avd_sec"]),
            })
            st.divider()

        if kpi_rows:
            st.markdown("### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø")
            comp_df = pd.DataFrame(kpi_rows)
            st.dataframe(comp_df, use_container_width=True, hide_index=True)

# --------------------------- GROUP ANALYTICS ---------------------------
else:
    st.header("Group Analytics")
    tool = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞", ["–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (Year Mix)"])

    if tool.startswith("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º"):
        st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (Year Mix)")
        source_mode = st.sidebar.radio("–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö", ["–ì—Ä—É–ø–ø—ã –∏–∑ Dashboard", "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã"])

        # –ò—Å—Ç–æ—á–Ω–∏–∫: –≥—Ä—É–ø–ø—ã
        if source_mode == "–ì—Ä—É–ø–ø—ã –∏–∑ Dashboard":
            if not st.session_state["groups"]:
                st.info("–ù–µ—Ç –≥—Ä—É–ø–ø –¥–∞–Ω–Ω—ã—Ö. –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ Dashboard.")
                st.stop()
            names = [g["name"] for g in st.session_state["groups"]]
            selected = st.sidebar.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –≥—Ä—É–ø–ø—ã", names, default=names[:1])
            if not selected:
                st.info("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É.")
                st.stop()
            idxs = [names.index(n) for n in selected]
            df = concat_groups(idxs)

        # –ò—Å—Ç–æ—á–Ω–∏–∫: –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã (—Å –æ–ø—Ü–∏–µ–π —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –≥—Ä—É–ø–ø—É, –¥—É–±–ª–∏–∫–∞—Ç—ã —Ä–∞–∑—Ä–µ—à–µ–Ω—ã)
        else:
            up_files = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)", type=["csv"], accept_multiple_files=True, key="ga_upload")
            df_list = []
            if up_files:
                for uf in up_files:
                    pack = load_uploaded_file(uf)
                    if pack["df"] is not None and not pack["df"].empty:
                        df_list.append(pack["df"])
            if not df_list:
                st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
                st.stop()
            df = pd.concat(df_list, ignore_index=True)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≥—Ä—É–ø–ø—É –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ (–±–µ–∑ –¥–µ–¥—É–ø–∞)
            if st.sidebar.checkbox("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —ç—Ç–∏ —Ñ–∞–π–ª—ã –≤ –≥—Ä—É–ø–ø—É"):
                mode = st.sidebar.radio("–ö—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å", ["–í —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≥—Ä—É–ø–ø—É", "–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é"])
                if mode == "–í —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≥—Ä—É–ø–ø—É":
                    if not st.session_state["groups"]:
                        st.warning("–ù–µ—Ç –≥—Ä—É–ø–ø. –°–æ–∑–¥–∞–π—Ç–µ –Ω–æ–≤—É—é –Ω–∏–∂–µ.")
                    else:
                        names = [g["name"] for g in st.session_state["groups"]]
                        gi = st.sidebar.selectbox("–ì—Ä—É–ø–ø–∞", list(range(len(names))), format_func=lambda i: names[i])
                        if st.sidebar.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å"):
                            added = 0
                            for uf in up_files:
                                pack = load_uploaded_file(uf)
                                if pack["df"] is None or pack["df"].empty:
                                    continue
                                st.session_state["groups"][gi]["files"].append(pack)
                                added += 1
                            if added:
                                st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {added}.")
                                st.rerun()
                            else:
                                st.info("–ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã (–ø—É—Å—Ç—ã–µ/–ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã).")
                else:
                    new_name = st.sidebar.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –≥—Ä—É–ø–ø—ã", value=f"GA Group {len(st.session_state['groups'])+1}")
                    if st.sidebar.button("–°–æ–∑–¥–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å"):
                        new_files = []
                        for uf in up_files:
                            pack = load_uploaded_file(uf)
                            if pack["df"] is None or pack["df"].empty:
                                continue
                            new_files.append(pack)
                        if new_files:
                            st.session_state["groups"].append({"name": new_name.strip() or "New Group", "files": new_files})
                            st.success("–ì—Ä—É–ø–ø–∞ —Å–æ–∑–¥–∞–Ω–∞.")
                            st.rerun()
                        else:
                            st.info("–ù–æ–≤—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã (–ø—É—Å—Ç—ã–µ/–ø–æ–≤—Ä–µ–∂–¥–µ–Ω—ã).")

        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç—Ä–æ–∫ ¬´–ò–¢–û–ì–û¬ª
        try:
            df = df[~df.apply(lambda r: r.astype(str).str.contains("–∏—Ç–æ–≥", case=False).any(), axis=1)]
        except Exception:
            pass

        C = detect_columns(df)
        pub_col = C["publish_time"]
        views_col = C["views"]
        missing = []
        if not (pub_col and pub_col in df.columns):
            missing.append("–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
        if not (views_col and views_col in df.columns):
            missing.append("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã")
        if missing:
            st.error("–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–æ–ª–æ–Ω–æ–∫: " + ", ".join(missing))
            st.stop()

        # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        df[pub_col] = pd.to_datetime(df[pub_col], errors="coerce")
        df = df[df[pub_col].notna()].copy()
        df["_views_num"] = pd.to_numeric(df[views_col].apply(to_number), errors="coerce")
        df["_year"] = df[pub_col].dt.year

        # –ê–≥—Ä–µ–≥–∞—Ü–∏–∏
        views_year = (
            df.groupby("_year", as_index=False)["_views_num"].sum()
              .rename(columns={"_year":"–ì–æ–¥","_views_num":"–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤"})
              .sort_values("–ì–æ–¥")
        )
        count_year = (
            df.groupby("_year", as_index=False).size()
              .rename(columns={"_year":"–ì–æ–¥","size":"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ"})
              .sort_values("–ì–æ–¥")
        )

        if views_year.empty or count_year.empty:
            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø–æ –≥–æ–¥–∞–º.")
            st.stop()

        years_list = sorted(views_year["–ì–æ–¥"].dropna().astype(int).unique())
        default_ref = 2024 if 2024 in years_list else int(max(years_list))
        ref_year = st.selectbox("–û–ø–æ—Ä–Ω—ã–π –≥–æ–¥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏", years_list, index=years_list.index(default_ref))

        # –ì—Ä–∞—Ñ–∏–∫–∏
        c1, c2 = st.columns(2)
        fig1 = px.bar(
            views_year, x="–ì–æ–¥", y="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤",
            text="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤", template="simple_white"
        )
        fig1.update_traces(marker_color="#4e79a7", texttemplate="%{text:,}", textposition="outside")
        fig1.update_layout(
            title="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø–æ –≥–æ–¥–∞–º",
            xaxis_title="–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", yaxis_title="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤",
            showlegend=False, margin=dict(l=10, r=10, t=50, b=10), height=430
        )
        fig1.update_xaxes(type="category", categoryorder="category ascending")
        c1.plotly_chart(fig1, use_container_width=True)

        fig2 = px.bar(
            count_year, x="–ì–æ–¥", y="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ", text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ", template="simple_white"
        )
        fig2.update_traces(marker_color="#4e79a7", texttemplate="%{text}", textposition="outside")
        fig2.update_layout(
            title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ –ø–æ –≥–æ–¥–∞–º",
            xaxis_title="–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏", yaxis_title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ",
            showlegend=False, margin=dict(l=10, r=10, t=50, b=10), height=430
        )
        fig2.update_xaxes(type="category", categoryorder="category ascending")
        c2.plotly_chart(fig2, use_container_width=True)

        # –ê–≤—Ç–æ—Ç–µ–∫—Å—Ç
        st.markdown("### üß† –ê–≤—Ç–æ–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π")
        vy = dict(zip(views_year["–ì–æ–¥"], views_year["–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤"]))
        cy = dict(zip(count_year["–ì–æ–¥"], count_year["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ"]))
        ranking = sorted(vy.items(), key=lambda x: x[1], reverse=True)
        ranking_years = [str(int(y)) for y, _ in ranking[:5]]
        older_sum = sum(v for y, v in vy.items() if y < ref_year)
        ref_sum = vy.get(ref_year, np.nan)
        prev_year = ref_year - 1 if (ref_year - 1) in vy else None
        views_ref = vy.get(ref_year, np.nan)
        views_prev = vy.get(prev_year, np.nan) if prev_year else np.nan
        cnt_ref = cy.get(ref_year, np.nan)
        cnt_prev = cy.get(prev_year, np.nan) if prev_year else np.nan

        def close_enough(a, b, tol=0.12):
            if pd.isna(a) or pd.isna(b):
                return False
            return abs(a - b) / max(abs(b), 1e-9) <= tol

        parts = [f"–û–ø–æ—Ä–Ω–∞—è —Ç–æ—á–∫–∞ ‚Äî **{ref_year}**."]
        if ranking_years:
            parts.append("–õ–∏–¥–∏—Ä—É—é—Ç –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º: **" + " ‚Üí ".join(ranking_years) + "**.")
        if not pd.isna(ref_sum) and older_sum > ref_sum:
            total_pair = older_sum + ref_sum
            share_old = f" (‚âà{older_sum/total_pair*100:.0f}% –æ—Ç ¬´—Å—Ç–∞—Ä—ã–π+{ref_year}¬ª)" if total_pair > 0 else ""
            parts.append(f"**–°—Ç–∞—Ä—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç** (–¥–æ {ref_year}) —Å–æ–±—Ä–∞–ª –±–æ–ª—å—à–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, —á–µ–º {ref_year}-–π –≥–æ–¥{share_old}.")
        frame = [y for y in [2022, 2023, 2024] if y in vy]
        if len(frame) >= 2:
            vals = [vy[y] for y in frame]
            mx = max(vals); mn = min(vals)
            if mx > 0 and (mx - mn) / mx <= 0.15:
                parts.append("–í **2022‚Äì2024** —Å—É–º–º–∞—Ä–Ω—ã–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –¥–µ—Ä–∂–∞–ª–∏—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ (¬±15%).")
        if prev_year and not any(pd.isna(x) for x in [views_ref, views_prev, cnt_ref, cnt_prev]):
            if close_enough(views_ref, views_prev, 0.12) and cnt_ref > cnt_prev:
                times = cnt_ref / max(cnt_prev, 1)
                parts.append(
                    f"–ü—Ä–∏ –±–ª–∏–∑–∫–∏—Ö –ø—Ä–æ—Å–º–æ—Ç—Ä–∞—Ö —É {prev_year} –∏ {ref_year} –≤ {ref_year}-–º –ø–æ–Ω–∞–¥–æ–±–∏–ª–æ—Å—å –±–æ–ª—å—à–µ –≤–∏–¥–µ–æ (‚âà√ó{times:.1f})."
                )

        for s in parts:
            st.markdown("‚Ä¢ " + s)
            # ---------- –ß–∞—Ç —Å n8n ----------
import os, requests, json
import streamlit as st

N8N_CHAT_URL = os.environ.get("N8N_CHAT_URL")  # —Ç—ã —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–∏–ª —Å–µ–∫—Ä–µ—Ç –≤ App settings ‚Üí Secrets

st.divider()
st.subheader("ü§ñ Chat (n8n webhook)")

if not N8N_CHAT_URL:
    st.warning("–°–µ–∫—Ä–µ—Ç N8N_CHAT_URL –Ω–µ –∑–∞–¥–∞–Ω. –ó–∞–¥–∞–π –µ–≥–æ –≤ App settings ‚Üí Secrets –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.")
else:
    # –ü–∞–º—è—Ç—å —á–∞—Ç–∞ –≤ —Å–µ—Å—Å–∏–∏
    if "chat" not in st.session_state:
        st.session_state.chat = []  # —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π: ("user"/"bot", text)

    # –†–∏—Å—É–µ–º –∏—Å—Ç–æ—Ä–∏—é
    for role, text in st.session_state.chat:
        st.chat_message("user" if role == "user" else "assistant").write(text)

    # –í–≤–æ–¥ –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    prompt = st.chat_input("–ù–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å‚Ä¶")
    if prompt:
        st.session_state.chat.append(("user", prompt))
        with st.chat_message("assistant"):
            with st.spinner("–û—Ç–ø—Ä–∞–≤–ª—è—é –≤ n8n‚Ä¶"):
                try:
                    payload = {"prompt": prompt, "meta": {"source": "streamlit", "user": "anon"}}
                    r = requests.post(N8N_CHAT_URL, json=payload, timeout=30)
                    r.raise_for_status()
                    # –ø—Ä–æ–±—É–µ–º JSON, –∏–Ω–∞—á–µ —Ç–µ–∫—Å—Ç
                    if r.headers.get("content-type", "").startswith("application/json"):
                        data = r.json()
                        answer = data.get("answer", json.dumps(data, ensure_ascii=False))
                    else:
                        answer = r.text
                except Exception as e:
                    answer = f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}"
            st.write(answer)
        st.session_state.chat.append(("bot", answer))


# === 1) –î–û–ë–ê–í–¨ / –ü–†–û–í–ï–†–¨ –ò–ú–ü–û–†–¢–´ –í–í–ï–†–•–£ –§–ê–ô–õ–ê ===
import os
import uuid
import requests

# === 2) –î–û–ë–ê–í–¨ –ü–û–°–õ–ï –°–í–û–ï–ô –ù–ê–í–ò–ì–ê–¶–ò–ò –í SIDEBAR ===
# –ë—ã–ª–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä:
# nav = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è", [f"{ICON_DASH}Dashboard", f"{ICON_GROUP}Group Analytics"])
# –ó–∞–º–µ–Ω—è–µ–º –Ω–∞:
nav = st.sidebar.radio(
    "–ù–∞–≤–∏–≥–∞—Ü–∏—è",
    [f"{ICON_DASH}Dashboard", f"{ICON_GROUP}Group Analytics", "ü§ñ Assistant"]
)

# === 3) –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ß–ê–¢–ê ===
def _get_n8n_urls_and_headers():
    """
    –ë–µ—Ä—ë–º URL –∏–∑ —Å–µ–∫—Ä–µ—Ç–∞ –∏–ª–∏ env –∏ –≥–æ—Ç–æ–≤–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∏.
    –ï—Å–ª–∏ –≤ n8n –≤–∫–ª—é—á–µ–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ Bearer —Ç–æ–∫–µ–Ω—É ‚Äî —Ç–æ–∂–µ –ø–æ–¥—Å—Ç–∞–≤–∏–º.
    """
    n8n_url = st.secrets.get("N8N_CHAT_URL") or os.getenv("N8N_CHAT_URL")
    if not n8n_url:
        st.error("–ù–µ –∑–∞–¥–∞–Ω N8N_CHAT_URL –≤ Secrets / –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        st.stop()

    headers = {"Content-Type": "application/json"}
    token = st.secrets.get("N8N_TOKEN") or os.getenv("N8N_TOKEN")
    if token:
        headers["Authorization"] = f"Bearer {token}"
    return n8n_url, headers

def ask_n8n(question: str, history: list[dict] | None = None, user_id: str | None = None) -> dict:
    """
    –î–µ–ª–∞–µ—Ç POST –≤ —Ç–≤–æ–π n8n –≤–µ–±—Ö—É–∫ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON-–æ—Ç–≤–µ—Ç.
    –û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ —Ç–≤–æ–π n8n workflow –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç, –Ω–∞–ø—Ä–∏–º–µ—Ä:
      { "answer": "—Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞", "meta": { ... } }
    """
    n8n_url, headers = _get_n8n_urls_and_headers()

    payload = {
        "question": question,
        "history": history or [],  # –º–æ–∂–Ω–æ –ø—Ä–æ–±—Ä–æ—Å–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –µ—ë –≤ n8n
        "user_id": user_id or str(uuid.uuid4()),
        # –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª—é–±—ã–µ –∫–∞—Å—Ç–æ–º–Ω—ã–µ –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –∂–¥—ë—Ç —Ç–≤–æ–π Prepare node
    }

    try:
        resp = requests.post(n8n_url, json=payload, headers=headers, timeout=60)
        resp.raise_for_status()
        return resp.json() if resp.headers.get("content-type", "").startswith("application/json") else {"answer": resp.text}
    except requests.HTTPError as e:
        return {"answer": f"HTTP error: {e} ‚Äî {getattr(e.response, 'text', '')}"}
    except requests.RequestException as e:
        return {"answer": f"Network error: {e}"}
    except Exception as e:
        return {"answer": f"Unexpected error: {e}"}

def render_chat_page():
    st.title("ü§ñ Assistant")
    st.caption("–ß–∞—Ç –∏–¥—ë—Ç —á–µ—Ä–µ–∑ n8n ‚Üí OpenAI (Message a model).")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é
    if "chat_msgs" not in st.session_state:
        st.session_state.chat_msgs = []

    # –†–∏—Å—É–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    for m in st.session_state.chat_msgs:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    # –ü–æ–ª–µ –≤–≤–æ–¥–∞
    user_text = st.chat_input("–ù–∞–ø–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å‚Ä¶")
    if user_text:
        # 1) –ª–æ–∫–∞–ª—å–Ω–æ –æ—Ç—Ä–∏—Å—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        st.session_state.chat_msgs.append({"role": "user", "content": user_text})
        with st.chat_message("user"):
            st.markdown(user_text)

        # 2) –≤—ã–∑–æ–≤–µ–º n8n
        with st.chat_message("assistant"):
            with st.spinner("–î—É–º–∞—é‚Ä¶"):
                # –ï—Å–ª–∏ –≤ n8n —Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –∏—Å—Ç–æ—Ä–∏—é ‚Äì –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –µ—ë —Ü–µ–ª–∏–∫–æ–º
                # (–∏–ª–∏ —Å–∂–∞—Ç—å –¥–æ –Ω—É–∂–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –≤–Ω—É—Ç—Ä–∏ Prepare Messages)
                n8n_resp = ask_n8n(
                    question=user_text,
                    history=st.session_state.chat_msgs,  # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ [] –µ—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è –Ω–µ –Ω—É–∂–Ω–∞
                    user_id=st.session_state.get("user_id") or str(uuid.uuid4()),
                )
                answer = n8n_resp.get("answer", "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç ü§ñ")
                st.markdown(answer)

        # 3) –¥–æ–∫–∏–Ω–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
        st.session_state.chat_msgs.append({"role": "assistant", "content": answer})

        # –ö–Ω–æ–ø–∫–∞ —Å–±—Ä–æ—Å–∞ —Å–µ—Å—Å–∏–∏ —á–∞—Ç–∞ (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
    cols = st.columns([1,1,6])
    with cols[0]:
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –¥–∏–∞–ª–æ–≥"):
            st.session_state.chat_msgs = []
            st.rerun()

# === 4) –í–ï–¢–ö–ê –†–ï–ù–î–ï–†–ê –ß–ê–¢–ê ===
if nav == "ü§ñ Assistant":
    render_chat_page()
