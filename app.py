import io
import re
from typing import Dict, List, Optional
import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from datetime import datetime

st.set_page_config(page_title="YouTube Analytics Tools", layout="wide")

# ----------------- helpers -----------------
def _num(x):
    if pd.isna(x):
        return np.nan
    try:
        if isinstance(x, str):
            x = x.replace(" ", "").replace(",", ".")
        return float(x)
    except Exception:
        return np.nan

def parse_duration_to_seconds(val) -> Optional[int]:
    if pd.isna(val):
        return None
    s = str(val).strip()
    if s.isdigit():
        return int(s)
    m = re.match(r'(?:(\d+)\s*h)?\s*(?:(\d+)\s*m)?\s*(?:(\d+)\s*s)?', s, re.I)
    if m and any(m.groups()):
        h = int(m.group(1)) if m.group(1) else 0
        mm = int(m.group(2)) if m.group(2) else 0
        ss = int(m.group(3)) if m.group(3) else 0
        return h*3600 + mm*60 + ss
    parts = s.split(":")
    try:
        if len(parts) == 3:
            h, mm, ss = map(int, parts)
            return h*3600 + mm*60 + ss
        elif len(parts) == 2:
            mm, ss = map(int, parts)
            return mm*60 + ss
    except Exception:
        pass
    return None

def seconds_to_hms(x: float) -> str:
    if pd.isna(x):
        return "‚Äî"
    x = int(round(x))
    h = x // 3600
    m = (x % 3600) // 60
    s = x % 60
    return f"{h}:{m:02d}:{s:02d}" if h else f"{m}:{s:02d}"

def detect_delimiter(buf: bytes) -> str:
    head = buf[:4000].decode("utf-8", errors="ignore")
    return ";" if head.count(";") > head.count(",") else ","

COLUMN_ALIASES: Dict[str, str] = {
    "video id": "video_id", "–∏–¥ –≤–∏–¥–µ–æ": "video_id", "id –≤–∏–¥–µ–æ": "video_id", "content id": "video_id",
    "title": "title", "–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ": "title", "name": "title",
    "publish time": "publish_time", "–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ": "publish_time",
    "–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ": "publish_time", "publish date": "publish_time", "date": "date",
    "views": "views", "–ø—Ä–æ—Å–º–æ—Ç—Ä—ã": "views",
    "impressions": "impressions", "–ø–æ–∫–∞–∑—ã": "impressions",
    "ctr": "ctr", "ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ (%)": "ctr", "impressions click-through rate": "ctr",
    "avg view duration": "avd", "average view duration": "avd",
    "—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": "avd",
    "watch time (hours)": "watch_hours", "watch time hours": "watch_hours", "—á–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": "watch_hours",
    "duration": "duration", "–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å": "duration",
    "format": "format", "—Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞": "format",
    "shorts": "shorts", "is shorts": "shorts",
    "estimated revenue": "revenue", "estimated partner revenue": "revenue", "–¥–æ—Ö–æ–¥": "revenue",
}

def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    return df.rename(columns={c: COLUMN_ALIASES.get(str(c).strip().lower(), c) for c in df.columns})

def read_csv_smart(file) -> pd.DataFrame:
    data = file.read()
    delim = detect_delimiter(data)
    df = pd.read_csv(io.BytesIO(data), sep=delim, encoding="utf-8", engine="python")
    df = standardize_columns(df)
    if "views" in df.columns: df["views"] = df["views"].map(_num)
    if "impressions" in df.columns: df["impressions"] = df["impressions"].map(_num)
    if "ctr" in df.columns:
        df["ctr"] = df["ctr"].map(_num)
        if df["ctr"].dropna().max() <= 1.0: df["ctr"] = df["ctr"] * 100
    if "watch_hours" in df.columns: df["watch_hours"] = df["watch_hours"].map(_num)
    if "publish_time" in df.columns: df["publish_time"] = pd.to_datetime(df["publish_time"], errors="coerce")
    if "date" in df.columns: df["date"] = pd.to_datetime(df["date"], errors="coerce")
    if "duration" in df.columns: df["duration_sec"] = df["duration"].apply(parse_duration_to_seconds)
    else: df["duration_sec"] = np.nan

    df["format"] = df.get("format")
    if "shorts" in df.columns:
        df.loc[df["shorts"].astype(str).str.lower().isin(["1","true","–¥–∞","yes"]), "format"] = "vertical"
    df.loc[df["format"].isna() & (df["duration_sec"] <= 60), "format"] = "vertical"
    df["format"] = df["format"].fillna("horizontal")

    if "revenue" in df.columns: df["revenue"] = df["revenue"].map(_num)
    if "video_id" in df.columns: df["video_id"] = df["video_id"].astype(str).str.strip()
    return df

def human_int(x: float) -> str:
    if pd.isna(x): return "‚Äî"
    x = float(x)
    for unit in ["", "K", "M", "B"]:
        if abs(x) < 1000: return f"{x:,.0f}{unit}".replace(",", " ")
        x /= 1000.0
    return f"{x:.1f}T"

def attach_revenue(base_df: pd.DataFrame, revenue_packs: Optional[List[Dict]]) -> pd.DataFrame:
    if not revenue_packs:
        return base_df
    df = base_df.copy()
    df["revenue_ext"] = np.nan
    for pack in revenue_packs:
        r = pack.get("df") if isinstance(pack, dict) else None
        if r is None or not isinstance(r, pd.DataFrame):
            continue
        cols = [c.lower() for c in r.columns]
        if "video_id" in cols and "revenue" in cols:
            r2 = r.rename(columns={r.columns[cols.index("video_id")]: "video_id",
                                   r.columns[cols.index("revenue")]: "revenue"}).copy()
            r2["video_id"] = r2["video_id"].astype(str).str.strip()
            r2["revenue"] = r2["revenue"].map(_num)
            df = df.merge(r2[["video_id","revenue"]], on="video_id", how="left", suffixes=("", "_extjoin"))
            df["revenue_ext"] = df["revenue_ext"].fillna(df["revenue_extjoin"])
            df.drop(columns=[c for c in df.columns if c.endswith("_extjoin")], inplace=True)
        elif "date" in cols and "revenue" in cols:
            r2 = r.rename(columns={r.columns[cols.index("date")]: "date",
                                   r.columns[cols.index("revenue")]: "revenue"}).copy()
            r2["date"] = pd.to_datetime(r2["date"], errors="coerce")
            daily = r2.groupby("date", as_index=False)["revenue"].sum()
            if "publish_time" in df.columns:
                df["pub_date"] = df["publish_time"].dt.floor("d")
                df = df.merge(daily, left_on="pub_date", right_on="date", how="left", suffixes=("", "_rday"))
                df["revenue_ext"] = df["revenue_ext"].fillna(df["revenue_rday"])
                df.drop(columns=["date","pub_date","revenue_rday"], inplace=True, errors="ignore")
    if "revenue" in df.columns:
        df["revenue_final"] = df["revenue"].fillna(df["revenue_ext"])
    else:
        df["revenue_final"] = df["revenue_ext"]
    return df

def summarize_one_file(df: pd.DataFrame, only_format: str="all") -> Dict[str, float]:
    d = df.copy()
    if only_format in ("vertical","horizontal"):
        d = d.loc[d["format"] == only_format]
    return {
        "videos": len(d),
        "views": d["views"].sum(skipna=True) if "views" in d.columns else np.nan,
        "impressions": d["impressions"].sum(skipna=True) if "impressions" in d.columns else np.nan,
        "ctr": d["ctr"].mean(skipna=True) if "ctr" in d.columns else np.nan,
        "avd_sec": d["duration_sec"].mean(skipna=True) if "duration_sec" in d.columns else np.nan,
        "watch_hours": d["watch_hours"].sum(skipna=True) if "watch_hours" in d.columns else np.nan,
        "revenue": d["revenue_final"].sum(skipna=True) if "revenue_final" in d.columns else np.nan,
    }

def combine_files(files: List[Dict], only_format: str="all") -> pd.DataFrame:
    if not files: return pd.DataFrame()
    dfs = []
    for p in files:
        df = p["df"].copy()
        if only_format in ("vertical","horizontal"):
            df = df.loc[df["format"] == only_format]
        df["__file__"] = p["name"]
        dfs.append(df)
    return pd.concat(dfs, ignore_index=True)

# ---- NEW: normalizer of group content ----
def normalize_packs(packs_raw) -> List[Dict]:
    """
    –ü—Ä–∏–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≥—Ä—É–ø–ø—ã –∫ —Å–ø–∏—Å–∫—É —Å–ª–æ–≤–∞—Ä–µ–π {"name": str, "df": DataFrame}.
    –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å.
    """
    norm = []
    if not isinstance(packs_raw, list):
        return norm
    for i, item in enumerate(packs_raw):
        if isinstance(item, dict) and "df" in item and "name" in item and isinstance(item["df"], pd.DataFrame):
            norm.append(item)
        elif isinstance(item, pd.DataFrame):
            norm.append({"name": f"report_{i}.csv", "df": item})
        else:
            # —Å—Ç—Ä–æ–∫–∞/None/–Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue
    return norm

# ----------------- session -----------------
if "groups" not in st.session_state:
    st.session_state.groups: Dict[str, List[Dict]] = {}
if "revenues" not in st.session_state:
    st.session_state.revenues: Dict[str, List[Dict]] = {}

# ----------------- sidebar add group -----------------
st.sidebar.title("üñ•Ô∏è YouTube Analytics Tools")
page = st.sidebar.radio("–ù–∞–≤–∏–≥–∞—Ü–∏—è",
                        ["Dashboard", "Channel Explorer", "Compare Groups", "Manage Groups"], index=0)

with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –≥—Ä—É–ø–ø—É", expanded=True):
    new_group_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)")
    add_files = st.file_uploader("CSV –æ—Ç—á—ë—Ç—ã", type=["csv"], accept_multiple_files=True)
    rev_files = st.file_uploader("CSV —Å –¥–æ—Ö–æ–¥–∞–º–∏ (–æ–ø—Ü.)", type=["csv"], accept_multiple_files=True)
    c1, c2 = st.columns(2)
    with c1:
        if st.button("–î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É"):
            if new_group_name:
                st.session_state.groups.setdefault(new_group_name, [])
                for f in add_files or []:
                    df = read_csv_smart(f)
                    df = attach_revenue(df, st.session_state.revenues.get(new_group_name, []))
                    st.session_state.groups[new_group_name].append({"name": f.name, "df": df})
                if rev_files:
                    st.session_state.revenues.setdefault(new_group_name, [])
                    for rf in rev_files:
                        r_df = read_csv_smart(rf)
                        st.session_state.revenues[new_group_name].append({"name": rf.name, "df": r_df})
                st.success("–ì—Ä—É–ø–ø–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞/–æ–±–Ω–æ–≤–ª–µ–Ω–∞")
            else:
                st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã")
    with c2:
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã"):
            st.session_state.groups = {}
            st.session_state.revenues = {}
            st.experimental_rerun()

st.sidebar.markdown("### –í–∞—à–∏ –≥—Ä—É–ø–ø—ã:")
if not st.session_state.groups:
    st.sidebar.info("–ü–æ–∫–∞ –Ω–µ—Ç –≥—Ä—É–ø–ø")
else:
    for g in st.session_state.groups.keys():
        st.sidebar.write(f"‚Ä¢ **{g}** ({len(st.session_state.groups[g])} –æ—Ç—á.)")

# ----------------- pages -----------------
if page == "Dashboard":
    st.title("Dashboard")
    if not st.session_state.groups:
        st.info("–î–æ–±–∞–≤—å –≥—Ä—É–ø–ø—É –≤ –ª–µ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
        st.stop()
    gname = st.selectbox("–ì—Ä—É–ø–ø–∞", list(st.session_state.groups.keys()))
    files_raw = st.session_state.groups.get(gname, [])
    files = normalize_packs(files_raw)
    rev_packs = st.session_state.revenues.get(gname, [])

    if not files:
        st.warning("–í –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤.")
        st.stop()

    fmt = st.radio("–§–æ—Ä–º–∞—Ç", ["all","horizontal","vertical"], horizontal=True)
    # —Ä–µ-attach revenue –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    files = [{"name": p["name"], "df": attach_revenue(p["df"], rev_packs)} for p in files]

    combine_toggle = st.toggle("–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ –æ—Ç—á—ë—Ç—ã –¥–ª—è –æ–±—â–µ–π –¥–∏–∞–≥—Ä–∞–º–º—ã", value=False)

    st.subheader("–°–≤–æ–¥–∫–∞ –ø–æ –∫–∞–∂–¥–æ–º—É –æ—Ç—á—ë—Ç—É")
    rows = []
    for p in files:
        s = summarize_one_file(p["df"], only_format=fmt)
        rows.append({"–û—Ç—á—ë—Ç": p["name"], "–í–∏–¥–µ–æ": s["videos"], "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": s["views"],
                     "–ü–æ–∫–∞–∑—ã": s["impressions"], "CTR, %": s["ctr"],
                     "AVD": seconds_to_hms(s["avd_sec"]), "–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞": s["watch_hours"],
                     "–î–æ—Ö–æ–¥": s["revenue"]})
    seg_df = pd.DataFrame(rows)
    if "–î–æ—Ö–æ–¥" in seg_df and seg_df["–î–æ—Ö–æ–¥"].notna().sum() == 0:
        seg_df.drop(columns=["–î–æ—Ö–æ–¥"], inplace=True)
    st.dataframe(seg_df.style.format({"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã":"{:,.0f}","–ü–æ–∫–∞–∑—ã":"{:,.0f}",
                                      "CTR, %":"{:.2f}","–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞":"{:,.1f}"}).hide(axis="index"),
                 use_container_width=True, height=300)

    if not seg_df.empty and "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã" in seg_df:
        st.plotly_chart(px.bar(seg_df, x="–û—Ç—á—ë—Ç", y="–ü—Ä–æ—Å–º–æ—Ç—Ä—ã",
                               title="–ü—Ä–æ—Å–º–æ—Ç—Ä—ã –ø–æ –æ—Ç—á—ë—Ç–∞–º (—Å —É—á—ë—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞)"),
                        use_container_width=True)

    st.divider()
    if combine_toggle:
        comb = combine_files(files, only_format=fmt)
        if comb.empty:
            st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—â–µ–π –¥–∏–∞–≥—Ä–∞–º–º—ã.")
        else:
            st.plotly_chart(px.histogram(comb, x="views", color="__file__", nbins=30,
                                         title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ (–≤—Å–µ —Ñ–∞–π–ª—ã)"),
                            use_container_width=True)
            if {"title","views"}.issubset(comb.columns):
                top10 = comb.sort_values("views", ascending=False).head(10)[["title","views","__file__"]]
                st.dataframe(top10.rename(columns={"title":"–ù–∞–∑–≤–∞–Ω–∏–µ","views":"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","__file__":"–û—Ç—á—ë—Ç"}),
                             use_container_width=True)

elif page == "Channel Explorer":
    st.title("Channel Explorer")
    if not st.session_state.groups:
        st.info("–î–æ–±–∞–≤—å –≥—Ä—É–ø–ø—É.")
        st.stop()
    gname = st.selectbox("–ì—Ä—É–ø–ø–∞", list(st.session_state.groups.keys()), key="expl_g")
    files = normalize_packs(st.session_state.groups.get(gname, []))
    rev_packs = st.session_state.revenues.get(gname, [])

    if not files:
        st.warning("–í —ç—Ç–æ–π –≥—Ä—É–ø–ø–µ –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤.")
        st.stop()

    file_names = [p["name"] for p in files]
    fname = st.selectbox("–û—Ç—á—ë—Ç", file_names)
    pack = files[file_names.index(fname)] if file_names else None
    if not (isinstance(pack, dict) and "df" in pack):
        st.error("–ù–µ–≤–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á—ë—Ç–∞ –≤ –≥—Ä—É–ø–ø–µ (–æ–∂–∏–¥–∞–ª—Å—è —Å–ª–æ–≤–∞—Ä—å —Å 'df'). –£–¥–∞–ª–∏—Ç–µ –∏ –¥–æ–±–∞–≤—å—Ç–µ –æ—Ç—á—ë—Ç –∑–∞–Ω–æ–≤–æ.")
        st.stop()

    df = attach_revenue(pack["df"], rev_packs)
    fmt = st.radio("–§–æ—Ä–º–∞—Ç", ["all","horizontal","vertical"], horizontal=True, key="expl_fmt")
    if fmt in ("horizontal","vertical"):
        df = df.loc[df["format"] == fmt]

    st.caption(f"–°—Ç—Ä–æ–∫: {len(df)}")

    metrics = [m for m in ["views","impressions","ctr","watch_hours","revenue_final"] if m in df.columns]
    if not metrics:
        st.warning("–ú–µ—Ç—Ä–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        st.stop()

    m = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞", metrics, index=0)
    chart_type = st.selectbox("–¢–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞", ["Bar","Scatter","Histogram"], index=0)

    xcol = "title" if "title" in df.columns else df.columns[0]
    if chart_type == "Bar":
        fig = px.bar(df.nlargest(30, m), x=xcol, y=m, title=f"Top-30 –ø–æ {m}")
        fig.update_layout(xaxis_title="", yaxis_title=m)
        st.plotly_chart(fig, use_container_width=True)
    elif chart_type == "Scatter":
        ycand = [i for i in ["impressions","ctr","watch_hours","revenue_final"] if i in df.columns and i != m]
        yaxis = st.selectbox("–û—Å—å Y", ycand) if ycand else m
        st.plotly_chart(px.scatter(df, x=m, y=yaxis, hover_data=[xcol], title=f"{m} vs {yaxis}"),
                        use_container_width=True)
    else:
        st.plotly_chart(px.histogram(df, x=m, nbins=40, title=f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {m}"),
                        use_container_width=True)

    st.divider()
    show_cols = [c for c in ["title","views","impressions","ctr","watch_hours","revenue_final","format"] if c in df.columns]
    st.dataframe(df[show_cols].rename(columns={
        "title":"–ù–∞–∑–≤–∞–Ω–∏–µ","views":"–ü—Ä–æ—Å–º–æ—Ç—Ä—ã","impressions":"–ü–æ–∫–∞–∑—ã","ctr":"CTR, %","watch_hours":"–ß–∞—Å—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
        "revenue_final":"–î–æ—Ö–æ–¥","format":"–§–æ—Ä–º–∞—Ç"
    }), use_container_width=True)

elif page == "Compare Groups":
    st.title("Compare Groups")
    if len(st.session_state.groups) < 2:
        st.info("–ù—É–∂–Ω—ã –º–∏–Ω–∏–º—É–º –¥–≤–µ –≥—Ä—É–ø–ø—ã.")
        st.stop()

    g_list = list(st.session_state.groups.keys())
    a = st.selectbox("–ì—Ä—É–ø–ø–∞ A", g_list, key="cmp_a")
    b = st.selectbox("–ì—Ä—É–ø–ø–∞ B", [x for x in g_list if x != a], key="cmp_b")
    fmt = st.radio("–§–æ—Ä–º–∞—Ç", ["all","horizontal","vertical"], horizontal=True, key="cmp_fmt")

    def sum_group(gname: str) -> Dict[str, float]:
        files = normalize_packs(st.session_state.groups.get(gname, []))
        rev = st.session_state.revenues.get(gname, [])
        if st.toggle(f"–û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ñ–∞–π–ª—ã –¥–ª—è {gname}", key=f"merge_{gname}", value=True):
            comb = combine_files(files, only_format=fmt)
            comb = attach_revenue(comb, rev) if not comb.empty else comb
            return summarize_one_file(comb, only_format="all")
        else:
            acc = []
            for p in files:
                d = attach_revenue(p["df"], rev)
                acc.append(summarize_one_file(d, only_format=fmt))
            if not acc: return {}
            dfm = pd.DataFrame(acc).mean(numeric_only=True).to_dict()
            dfm["videos"] = np.mean([x["videos"] for x in acc]) if acc else np.nan
            return dfm

    sA, sB = sum_group(a), sum_group(b)
    colA, colB = st.columns(2)
    with colA:
        st.markdown(f"### {a}")
        st.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", human_int(sA.get("views", np.nan)))
        st.metric("–ü–æ–∫–∞–∑—ã", human_int(sA.get("impressions", np.nan)))
        st.metric("CTR, %", f"{sA.get('ctr', np.nan):.2f}" if not pd.isna(sA.get("ctr", np.nan)) else "‚Äî")
        st.metric("AVD", seconds_to_hms(sA.get("avd_sec", np.nan)))
        if not pd.isna(sA.get("revenue", np.nan)): st.metric("–î–æ—Ö–æ–¥", human_int(sA.get("revenue", np.nan)))
    with colB:
        st.markdown(f"### {b}")
        st.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã", human_int(sB.get("views", np.nan)))
        st.metric("–ü–æ–∫–∞–∑—ã", human_int(sB.get("impressions", np.nan)))
        st.metric("CTR, %", f"{sB.get('ctr', np.nan):.2f}" if not pd.isna(sB.get("ctr", np.nan)) else "‚Äî")
        st.metric("AVD", seconds_to_hms(sB.get("avd_sec", np.nan)))
        if not pd.isna(sB.get("revenue", np.nan)): st.metric("–î–æ—Ö–æ–¥", human_int(sB.get("revenue", np.nan)))

elif page == "Manage Groups":
    st.title("Manage Groups")
    if not st.session_state.groups:
        st.info("–ù–µ—Ç –≥—Ä—É–ø–ø")
        st.stop()
    gname = st.selectbox("–ì—Ä—É–ø–ø–∞", list(st.session_state.groups.keys()), key="mgmt_g")
    packs = normalize_packs(st.session_state.groups.get(gname, []))
    st.write(f"–í–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(packs)}")

    for i, pack in enumerate(list(packs)):
        with st.expander(f"–û—Ç—á—ë—Ç: {pack['name']}", expanded=False):
            st.write(f"–°—Ç—Ä–æ–∫: {len(pack['df'])}")
            c1, c2 = st.columns([1,1])
            with c1:
                if st.button("–£–¥–∞–ª–∏—Ç—å —ç—Ç–æ—Ç –æ—Ç—á—ë—Ç", key=f"del_{gname}_{i}"):
                    # —É–¥–∞–ª–∏—Ç—å –∏—Å—Ö–æ–¥–Ω–æ –∏–∑ raw —Å–ø–∏—Å–∫–∞ (—á—Ç–æ–±—ã –Ω–µ —Ä–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏—Ç—å—Å—è)
                    raw = st.session_state.groups[gname]
                    # –∏—â–µ–º –ø–æ –∏–º–µ–Ω–∏ –∏ —Ä–∞–∑–º–µ—Ä—É
                    for j, item in enumerate(raw):
                        if isinstance(item, dict) and item.get("name")==pack["name"]:
                            st.session_state.groups[gname].pop(j); break
                    st.experimental_rerun()
            with c2:
                st.download_button("–°–∫–∞—á–∞—Ç—å CSV", data=pack["df"].to_csv(index=False).encode("utf-8"),
                                   file_name=f"{pack['name']}_normalized.csv", mime="text/csv")

    if st.button("–£–¥–∞–ª–∏—Ç—å –≤—Å—é –≥—Ä—É–ø–ø—É"):
        st.session_state.groups.pop(gname, None)
        st.session_state.revenues.pop(gname, None)
        st.experimental_rerun()
