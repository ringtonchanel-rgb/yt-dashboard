# app.py ‚Äî Sidebar Navigation
# DASHBOARD: –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥—Ä—É–ø–ø (–∫–∞–Ω–∞–ª–æ–≤), –º–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–æ–≤, –∞–≤—Ç–æ–º–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫ –∏ KPI
# GROUP ANALYTICS: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import io
import re

# ===== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ =====
USE_EMOJI = True
ICON_DASH  = "üìä " if USE_EMOJI else ""
ICON_GROUP = "üß© " if USE_EMOJI else ""
ICON_BRAND = "üì∫ " if USE_EMOJI else ""

st.set_page_config(page_title="YouTube Analytics Tools", layout="wide")

# ---------------- Sidebar (–ù–ê–í–ò–ì–ê–¶–ò–Ø) ----------------
st.sidebar.markdown(
    f"<div style='font-weight:700;font-size:1.05rem;letter-spacing:.1px;'>{ICON_BRAND}YouTube Analytics Tools</div>",
    unsafe_allow_html=True,
)
st.sidebar.divider()

nav = st.sidebar.radio(
    "–ù–∞–≤–∏–≥–∞—Ü–∏—è",
    options=[f"{ICON_DASH}Dashboard", f"{ICON_GROUP}Group Analytics"],
    label_visibility="visible",
)

st.sidebar.divider()

# ======================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò: –ê–≤—Ç–æ–º–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫/–ø–∞—Ä—Å–∏–Ω–≥ –∑–Ω–∞—á–µ–Ω–∏–π
# ======================================================================

def _norm(s: str) -> str:
    return str(s).strip().lower()

# –í–æ–∑–º–æ–∂–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –≤ —Ä–∞–∑–Ω—ã—Ö –æ—Ç—á—ë—Ç–∞—Ö (ru/en)
MAP = {
    "publish_time": [
        "video publish time","publish time","–≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤–∏–¥–µ–æ","–¥–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏","publish date"
    ],
    "views": ["views","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã","–ø—Ä–æ—Å–º—Ç–æ—Ä—ã","–ø—Ä–æ—Å–º–æ—Ç—Ä—ã (views)"],
    "impressions": [
        "impressions","–ø–æ–∫–∞–∑—ã","–ø–æ–∫–∞–∑—ã (impressions)","–ø–æ–∫–∞–∑—ã –∑–Ω–∞—á–∫–æ–≤","–ø–æ–∫–∞–∑—ã –¥–ª—è –∑–Ω–∞—á–∫–æ–≤"
    ],
    "ctr": [
        "impressions click-through rate","ctr","ctr (%)",
        "ctr for thumbnails (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ (%)",
        "ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ (%)","ctr –¥–ª—è –∑–Ω–∞—á–∫–æ–≤ –≤–∏–¥–µ–æ","ctr –≤–∏–¥–µ–æ"
    ],
    "avd": [
        "average view duration",
        "avg view duration",
        "—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
        "—Å—Ä–µ–¥–Ω—è—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –≤–∏–¥–µ–æ",
        "average view duration (hh:mm:ss)"
    ],
    "title": ["title","–Ω–∞–∑–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ","video title","–≤–∏–¥–µ–æ","–Ω–∞–∑–≤–∞–Ω–∏–µ"],
}

def find_col(df: pd.DataFrame, names) -> str | None:
    """–ò—â–µ–º –∫–æ–ª–æ–Ω–∫—É: —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∏–º–µ–Ω–∏, –∑–∞—Ç–µ–º –ø–æ–¥—Å—Ç—Ä–æ–∫–∞."""
    if isinstance(names, str):
        names = [names]
    by_norm = {_norm(c): c for c in df.columns}
    for n in names:
        nn = _norm(n)
        if nn in by_norm:
            return by_norm[nn]
    for n in names:
        nn = _norm(n)
        for c in df.columns:
            if nn in _norm(c):
                return c
    return None

def detect_columns(df: pd.DataFrame):
    return {k: find_col(df, v) for k, v in MAP.items()}

def to_number(x):
    """–ü–∞—Ä—Å–∏–º '12 345', '5,6%', '5.6%', '1 234' -> float. –í–æ–∑–≤—Ä–∞—â–∞–µ–º NaN –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å."""
    if x is None:
        return np.nan
    if isinstance(x, (int, float, np.number)):
        return float(x)
    s = str(x).strip()
    if s == "" or s.lower() in {"none","nan"}:
        return np.nan
    # —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã, —É–∑–∫–∏–µ –ø—Ä–æ–±–µ–ª—ã, –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ (–∫—Ä–æ–º–µ –∑–Ω–∞–∫–æ–≤ . , % :)
    s = s.replace(" ", "").replace("\u202f", "").replace("\xa0", "")
    # –ø—Ä–æ—Ü–µ–Ω—Ç
    is_percent = s.endswith("%")
    if is_percent:
        s = s[:-1]
    # –∑–∞–º–µ–Ω–∏—Ç—å –∑–∞–ø—è—Ç—É—é –Ω–∞ —Ç–æ—á–∫—É, –µ—Å–ª–∏ –Ω–µ—Ç —Ç–æ—á–∫–∏
    if "," in s and "." not in s:
        s = s.replace(",", ".")
    try:
        val = float(s)
        return val if not is_percent else val  # CTR –¥–∞–ª–µ–µ —Å–∞–º –ø—Ä–∏–≤–µ–¥—ë–º –∫ %
    except Exception:
        return np.nan

def parse_duration_to_seconds(x):
    """–ü–∞—Ä—Å–∏–º AVD: '0:01:47'/'2:45'/'1:12:05' -> —Å–µ–∫. –ï—Å–ª–∏ —á–∏—Å–ª–æ ‚Äî —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —É–∂–µ —Å–µ–∫—É–Ω–¥—ã."""
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return np.nan
    if isinstance(x, (int, float, np.number)):
        # –∏–Ω–æ–≥–¥–∞ –≤ –æ—Ç—á—ë—Ç–∞—Ö AVD –º–æ–≥—É—Ç –±—ã—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        return float(x)
    s = str(x).strip()
    if s == "":
        return np.nan
    # –§–æ—Ä–º–∞—Ç—ã: hh:mm:ss –∏–ª–∏ mm:ss
    m = re.match(r"^(\d+):(\d{2}):(\d{2})$", s)
    if m:
        h, m_, s_ = map(int, m.groups())
        return h*3600 + m_*60 + s_
    m = re.match(r"^(\d+):(\d{2})$", s)
    if m:
        m_, s_ = map(int, m.groups())
        return m_*60 + s_
    # –ï—Å–ª–∏ –ø—Ä–∏–ª–µ—Ç–µ–ª–æ —Å—Ç—Ä–∞–Ω–Ω–æ–µ ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º —á–∏—Å–ª–æ–º
    try:
        return float(s)
    except Exception:
        return np.nan

def seconds_to_hhmmss(sec):
    if pd.isna(sec):
        return "‚Äî"
    sec = int(round(sec))
    h = sec // 3600
    m = (sec % 3600) // 60
    s = sec % 60
    return f"{h}:{m:02d}:{s:02d}" if h else f"{m}:{s:02d}"

def read_csv_safely(uploaded_file) -> pd.DataFrame | None:
    """–ü—ã—Ç–∞–µ–º—Å—è —á–∏—Ç–∞—Ç—å CSV —Å BOM/–±–µ–∑ –Ω–µ–≥–æ, fallback –Ω–∞ cp1251/utf-8."""
    try:
        return pd.read_csv(uploaded_file)
    except Exception:
        try:
            if hasattr(uploaded_file, "getvalue"):
                data = uploaded_file.getvalue()
            else:
                data = uploaded_file.read()
            return pd.read_csv(io.BytesIO(data), encoding="utf-8-sig")
        except Exception:
            try:
                return pd.read_csv(io.BytesIO(data), encoding="cp1251")
            except Exception:
                return None

# ======================================================================
# DASHBOARD
# ======================================================================

if nav.endswith("Dashboard"):
    st.header("Dashboard")

    # –•—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞–±–æ—Ä–æ–≤ (–≥—Ä—É–ø–ø) –≤ —Å–µ—Å—Å–∏–∏
    if "groups" not in st.session_state:
        st.session_state["groups"] = []  # [{name:str, dfs:[pd.DataFrame,..], meta:[]}, ...]

    with st.sidebar.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É –¥–∞–Ω–Ω—ã—Ö", expanded=True):
        group_name = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã (–∫–∞–Ω–∞–ª–∞)", value=f"Group {len(st.session_state['groups'])+1}")
        files = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ç—á–µ—Ç–æ–≤ CSV",
            type=["csv"],
            accept_multiple_files=True,
            key="dashboard_files",
            help="–ú–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ—Ç—á—ë—Ç—ã —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∏–∑ YouTube Studio.",
        )
        add_btn = st.button("–î–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É")

        if add_btn:
            if not group_name.strip():
                st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã.")
            elif not files:
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω CSV.")
            else:
                dfs = []
                metas = []
                for f in files:
                    df = read_csv_safely(f)
                    if df is None or df.empty:
                        metas.append(f"‚ùå {f.name}: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV –∏–ª–∏ –æ–Ω –ø—É—Å—Ç.")
                        continue
                    df.columns = [c.strip() for c in df.columns]
                    dfs.append(df)
                    metas.append(f"‚úÖ {f.name}: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫.")
                if dfs:
                    st.session_state["groups"].append({"name": group_name.strip(), "dfs": dfs, "meta": metas})
                    st.success(f"–ì—Ä—É–ø–ø–∞ ¬´{group_name}¬ª –¥–æ–±–∞–≤–ª–µ–Ω–∞ ({len(dfs)} —Ñ–∞–π–ª(–∞)).")
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≥—Ä—É–ø–ø—É ‚Äî –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.")

    if st.session_state["groups"]:
        col_clear, col_cnt = st.columns([1,3])
        with col_clear:
            if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ –≥—Ä—É–ø–ø—ã"):
                st.session_state["groups"].clear()
                st.experimental_rerun()
        with col_cnt:
            st.write(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ –≥—Ä—É–ø–ø: **{len(st.session_state['groups'])}**")

        st.divider()

        # --- –ü–æ–¥—Å—á—ë—Ç KPI –ø–æ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø–µ ---
        kpi_rows = []   # –¥–ª—è –æ–±—â–µ–π —Ç–∞–±–ª–∏—Ü—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        for g in st.session_state["groups"]:
            name = g["name"]
            dfs  = g["dfs"]

            total_impr = 0.0
            total_views = 0.0
            ctr_values = []  # —Å—Ä–µ–¥–Ω—è—è –ø–æ –≤–∏–¥–µ–æ (–ø—Ä–æ—Å—Ç–∞—è)
            avd_vals_sec = []

            # –ø—Ä–æ–±–µ–∂–∏–º—Å—è –ø–æ –≤—Å–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –æ—Ç—á—ë—Ç–∞–º –≥—Ä—É–ø–ø—ã
            for df in dfs:
                C = detect_columns(df)

                # –ò–º–ø—Ä–µ—Å—Å–∏–∏ –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã ‚Äî —Å—É–º–º–æ–π
                if C["impressions"] and C["impressions"] in df.columns:
                    impr = pd.to_numeric(df[C["impressions"]].apply(to_number), errors="coerce").fillna(0)
                    total_impr += float(impr.sum())

                if C["views"] and C["views"] in df.columns:
                    views = pd.to_numeric(df[C["views"]].apply(to_number), errors="coerce").fillna(0)
                    total_views += float(views.sum())

                # CTR ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—è–º
                if C["ctr"] and C["ctr"] in df.columns:
                    ctr_col = df[C["ctr"]].apply(to_number)  # 5.6 -> 5.6 (%)
                    # –∏–Ω–æ–≥–¥–∞ –≤ –æ—Ç—á—ë—Ç–∞—Ö CTR –≤ –¥–æ–ª—è—Ö (0.056); –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ø—Ä–∞–≤–∏—Ç—å –µ—Å–ª–∏ < 1 –∏ –Ω–µ –≤—Å–µ –Ω—É–ª–∏
                    # –Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ ‚Äî –Ω–µ –±—É–¥–µ–º –º–µ–Ω—è—Ç—å, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑—å–º—ë–º –∫–∞–∫ –µ—Å—Ç—å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                    ctr_values.extend(list(ctr_col.dropna().values))

                # AVD ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤–∏–¥–µ–æ (–ø–µ—Ä–µ–≤–æ–¥ –≤ —Å–µ–∫—É–Ω–¥—ã)
                if C["avd"] and C["avd"] in df.columns:
                    avd_sec = df[C["avd"]].apply(parse_duration_to_seconds)
                    avd_vals_sec.extend(list(avd_sec.dropna().values))

            # –∞–≥—Ä–µ–≥–∞—Ç—ã
            avg_ctr = float(np.nanmean(ctr_values)) if ctr_values else np.nan
            avg_avd_sec = float(np.nanmean(avd_vals_sec)) if avd_vals_sec else np.nan

            # --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ä—Ç–æ—á–µ–∫ KPI ---
            st.subheader(f"–ì—Ä—É–ø–ø–∞: {name}")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("–ü–æ–∫–∞–∑—ã (—Å—É–º–º–∞)", f"{int(total_impr):,}".replace(",", " "))
            c2.metric("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã (—Å—É–º–º–∞)", f"{int(total_views):,}".replace(",", " "))

            ctr_txt = "‚Äî" if np.isnan(avg_ctr) else f"{avg_ctr:.2f}%"
            avd_txt = seconds_to_hhmmss(avg_avd_sec)
            c3.metric("–°—Ä–µ–¥–Ω–∏–π CTR –ø–æ –≤–∏–¥–µ–æ", ctr_txt)
            c4.metric("–°—Ä–µ–¥–Ω–∏–π AVD", avd_txt)

            # —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–ª—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
            kpi_rows.append({
                "–ì—Ä—É–ø–ø–∞": name,
                "–ü–æ–∫–∞–∑—ã": int(total_impr),
                "–ü—Ä–æ—Å–º–æ—Ç—Ä—ã": int(total_views),
                "CTR, % (—Å—Ä–µ–¥–Ω–µ–µ)": None if np.isnan(avg_ctr) else round(avg_ctr, 2),
                "AVD (—Å—Ä.)": avd_txt
            })

            # –ø–æ–∫–∞–∑–∞—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ —Ñ–∞–π–ª–∞–º
            with st.expander(f"–§–∞–π–ª—ã –Ω–∞–±–æ—Ä–∞ ¬´{name}¬ª"):
                for m in g["meta"]:
                    st.write(m)

            st.divider()

        # --- –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–æ –≤—Å–µ–º –≥—Ä—É–ø–ø–∞–º ---
        if kpi_rows:
            st.markdown("### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥—Ä—É–ø–ø")
            comp_df = pd.DataFrame(kpi_rows)
            st.dataframe(comp_df, use_container_width=True, hide_index=True)

    else:
        st.info("–î–æ–±–∞–≤—å—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –≥—Ä—É–ø–ø—É –¥–∞–Ω–Ω—ã—Ö –≤ —Å–∞–π–¥–±–∞—Ä–µ, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å KPI.")

# ======================================================================
# GROUP ANALYTICS ‚Äî –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (Year Mix)
# ======================================================================

else:
    st.header("Group Analytics")
    tool = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞", ["–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (Year Mix)"])

    # ---------------------- YEAR MIX ----------------------
    if tool.startswith("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º"):
        st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≥–æ–¥–∞–º (Year Mix)")

        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        st.sidebar.markdown("### –î–∞–Ω–Ω—ã–µ")
        file = st.sidebar.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–∑ YouTube Studio", type=["csv"], key="upload_yearmix"
        )
        show_table = st.sidebar.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É —Å —Ü–∏—Ñ—Ä–∞–º–∏", value=False)

        if not file:
            st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV ‚Äî –ø–æ—Å—Ç—Ä–æ—é –¥–≤–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –∏ –∞–≤—Ç–æ–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ –≥–æ–¥–∞–º.")
            st.stop()

        df = read_csv_safely(file)
        if df is None or df.empty:
            st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å CSV.")
            st.stop()

        df.columns = [c.strip() for c in df.columns]
        # —É–±—Ä–∞—Ç—å ¬´–ò–¢–û–ì–û¬ª
        try:
            df = df[~df.apply(lambda r: r.astype(str).str.contains("–∏—Ç–æ–≥", case=False).any(), axis=1)]
        except Exception:
            pass

        C = detect_columns(df)
        pub_col  = C["publish_time"]
        views_col = C["views"]

        missing = []
        if not (pub_col and pub_col in df.columns): missing.append("–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏")
        if not (views_col and views_col in df.columns): missing.append("–ü—Ä–æ—Å–º–æ—Ç—Ä—ã")
        if missing:
            st.error("–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ –≤ —Ñ–∞–π–ª–µ: " + ", ".join(missing))
            st.stop()

        # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
        df[pub_col] = pd.to_datetime(df[pub_col], errors="coerce")
        df = df[df[pub_col].notna()].copy()
        df["_views_num"] = pd.to_numeric(df[views_col].apply(to_number), errors="coerce")
        df["_year"] = df[pub_col].dt.year

        # –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
        views_year = (
            df.groupby("_year", as_index=False)["_views_num"]
              .sum()
              .rename(columns={"_year": "–ì–æ–¥", "_views_num": "–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤"})
              .sort_values("–ì–æ–¥")
        )
        count_year = (
            df.groupby("_year", as_index=False)
              .size()
              .rename(columns={"_year": "–ì–æ–¥", "size": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ"})
              .sort_values("–ì–æ–¥")
        )

        if views_year.empty or count_year.empty:
            st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –ø–æ –≥–æ–¥–∞–º.")
            st.stop()

        # –û–ø–æ—Ä–Ω—ã–π –≥–æ–¥
        years_list = sorted(views_year["–ì–æ–¥"].dropna().astype(int).unique())
        default_ref = 2024 if 2024 in years_list else int(max(years_list))
        ref_year = st.selectbox("–û–ø–æ—Ä–Ω—ã–π –≥–æ–¥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏", years_list,
                                index=years_list.index(default_ref))

        # --- –ì–†–ê–§–ò–ö–ò ---
        c1, c2 = st.columns(2)

        fig1 = px.bar(
            views_year, x="–ì–æ–¥", y="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤",
            text="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤", template="simple_white"
        )
        fig1.update_traces(marker_color="#4e79a7", texttemplate="%{text:,}", textposition="outside")
        fig1.update_layout(
            title="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –ø–æ –≥–æ–¥–∞–º",
            xaxis_title="–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏",
            yaxis_title="–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤",
            showlegend=False, margin=dict(l=10, r=10, t=50, b=10), height=430
        )
        fig1.update_xaxes(type="category", categoryorder="category ascending")
        c1.plotly_chart(fig1, use_container_width=True)

        fig2 = px.bar(
            count_year, x="–ì–æ–¥", y="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ", text="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ", template="simple_white"
        )
        fig2.update_traces(marker_color="#4e79a7", texttemplate="%{text}", textposition="outside")
        fig2.update_layout(
            title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ –ø–æ –≥–æ–¥–∞–º",
            xaxis_title="–ì–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏",
            yaxis_title="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ",
            showlegend=False, margin=dict(l=10, r=10, t=50, b=10), height=430
        )
        fig2.update_xaxes(type="category", categoryorder="category ascending")
        c2.plotly_chart(fig2, use_container_width=True)

        # –¢–∞–±–ª–∏—Ü–∞ –ø–æ –∂–µ–ª–∞–Ω–∏—é
        if show_table:
            st.markdown("### –¢–∞–±–ª–∏—Ü–∞")
            tbl = pd.merge(views_year, count_year, on="–ì–æ–¥", how="outer").sort_values("–ì–æ–¥")
            st.dataframe(tbl, use_container_width=True)

        # --- –ê–≤—Ç–æ—Ç–µ–∫—Å—Ç ---
        st.markdown("### üß† –ê–≤—Ç–æ–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø–æ –¥–∞–Ω–Ω—ã–º")
        vy = dict(zip(views_year["–ì–æ–¥"], views_year["–°—É–º–º–∞—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤"]))
        cy = dict(zip(count_year["–ì–æ–¥"], count_year["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ"]))
        ranking = sorted(vy.items(), key=lambda x: x[1], reverse=True)
        ranking_years = [str(int(y)) for y,_ in ranking[:5]]

        older_sum = sum(v for y, v in vy.items() if y < ref_year)
        ref_sum   = vy.get(ref_year, np.nan)
        prev_year = ref_year - 1 if (ref_year - 1) in vy else None
        views_ref = vy.get(ref_year, np.nan)
        views_prev = vy.get(prev_year, np.nan) if prev_year else np.nan
        cnt_ref = cy.get(ref_year, np.nan)
        cnt_prev = cy.get(prev_year, np.nan) if prev_year else np.nan

        def close_enough(a, b, tol=0.12):
            if pd.isna(a) or pd.isna(b): return False
            base = max(abs(b), 1e-9)
            return abs(a - b) / base <= tol

        parts = []
        parts.append(f"–û–ø–æ—Ä–Ω–∞—è —Ç–æ—á–∫–∞ ‚Äî **{ref_year}**. –ù–∏–∂–µ ‚Äî —Ä–∞—Å–∫–ª–∞–¥ –ø–æ –≥–æ–¥–∞–º: –≥–¥–µ –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ –∏ —Å–∫–æ–ª—å–∫–æ –≤–∏–¥–µ–æ –≤—ã—à–ª–æ.")
        if ranking_years:
            parts.append("–õ–∏–¥–∏—Ä—É—é—Ç –ø–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º: **" + " ‚Üí ".join(ranking_years) + "**.")

        if not pd.isna(ref_sum) and older_sum > ref_sum:
            total_pair = older_sum + ref_sum
            share_old = f" (‚âà{older_sum/total_pair*100:.0f}% –æ—Ç ¬´—Å—Ç–∞—Ä—ã–π+{ref_year}¬ª)" if total_pair>0 else ""
            parts.append(f"**–°—Ç–∞—Ä—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç** (–¥–æ {ref_year}) —Å–æ–±—Ä–∞–ª –±–æ–ª—å—à–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤, —á–µ–º {ref_year}-–π –≥–æ–¥{share_old}.")

        frame = [y for y in [2022, 2023, 2024] if y in vy]
        if len(frame) >= 2:
            vals = [vy[y] for y in frame]
            mx, mn = max(vals), min(vals)
            if mx > 0 and (mx - mn) / mx <= 0.15:
                parts.append("–í **2022‚Äì2024** —Å—É–º–º–∞—Ä–Ω—ã–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –¥–µ—Ä–∂–∞–ª–∏—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ –æ–¥–Ω–æ–º —É—Ä–æ–≤–Ω–µ (¬±15%).")

        if prev_year and not any(pd.isna(x) for x in [views_ref, views_prev, cnt_ref, cnt_prev]):
            if close_enough(views_ref, views_prev, tol=0.12) and cnt_ref > cnt_prev:
                times = cnt_ref / max(cnt_prev, 1)
                parts.append(
                    f"–ü—Ä–∏ –ø–æ—Ö–æ–∂–µ–º —É—Ä–æ–≤–Ω–µ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤ —É {prev_year} –∏ {ref_year} "
                    f"–≤ {ref_year}-–º –ø–æ–Ω–∞–¥–æ–±–∏–ª–æ—Å—å –±–æ–ª—å—à–µ –≤–∏–¥–µ–æ (‚âà√ó{times:.1f}), —á—Ç–æ–±—ã —É–¥–µ—Ä–∂–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç."
                )

        if parts:
            for s in parts:
                st.markdown("‚Ä¢ " + s)
        else:
            st.write("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ ‚Äî –∑–∞–≥—Ä—É–∑–∏—Ç–µ –æ—Ç—á—ë—Ç —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≥–æ–¥–∞–º–∏.")
